<!doctype html>



  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta property="wb:webmaster" content="83391d5c1d7bc020" />








<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="丁洁的男朋友,csuncle,William,王立敏,会打代码的扫地王大爷,wlmnzf,中科院信工所,IIE,CAS" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="Secure Chip @ IIE CAS,I am interested in AI,WEB">
<meta property="og:type" content="website">
<meta property="og:title" content="会打代码的扫地王大爷">
<meta property="og:url" content="http://csuncle.com/index.html">
<meta property="og:site_name" content="会打代码的扫地王大爷">
<meta property="og:description" content="Secure Chip @ IIE CAS,I am interested in AI,WEB">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="会打代码的扫地王大爷">
<meta name="twitter:description" content="Secure Chip @ IIE CAS,I am interested in AI,WEB">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://csuncle.com/"/>





  <title>会打代码的扫地王大爷</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  





  <!-- hexo-inject:begin --><!-- hexo-inject:end --><script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?6a885c4fa76edbbfd2bea3f856135042";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>











  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">会打代码的扫地王大爷</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">CS Uncle</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://csuncle.com/2018/08/03/梅森旋转安全性分析及改进/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="William Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="会打代码的扫地王大爷">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/03/梅森旋转安全性分析及改进/" itemprop="url">梅森旋转算法安全性分析及改进</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-03T09:30:08+08:00">
                2018-08-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Cryptology/" itemprop="url" rel="index">
                    <span itemprop="name">密码学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p style="text-align: center;"><br>梅森旋转算法安全性分析及改进<br>======================<br></p>

<p style="text-align: center;">王立敏<sup>1</sup>,丁洁<sup>2</sup></p>


<p style="text-align: center;"><sup>1</sup>中国科学院信息工程研究所 第五实验室 北京 中国100093</p>

<p style="text-align: center;"><sup>2</sup>中国科学院信息工程研究所 第五实验室 北京 中国100093</p>

<p><strong>摘要</strong><br>梅森旋转算法是目前最流行的伪随机数发生器算法之一。梅森旋转算法存在许多缺点，例如当生成的伪随机数数量庞大时可预测以及无法通过部分统计测试。为了更好地深入了解和分析梅森旋转算法的安全性，本文将使用NIST<br>800-22文档中提到的统计测试等方法来对其生成的伪随机数进行静态的质量评估，并通过伪代码对该算法进行理论安全分析。由于梅森旋转算法生成伪随机数的速度十分快，而且开发者和研究人员们已经开发了许多梅森旋转算法的改进版本，甚至密码学安全的版本，因此当需要伪随机数时，选用梅森旋转算法作为伪随机数生成器是合理的。</p>
<p>关键词 <strong>梅森旋转算法，MT19937标准，统计测试，安全性分析</strong></p>
<p style="text-align: center;">The Analysis And Improvement Of Mersenne Twister</p>

<p style="text-align: center;">Wang Limin<sup>1</sup>, Ding Jie<sup>2</sup></p>

<p style="text-align: center;"><sup>1</sup>Institute of Information Engineering, Chinese Academy of Sciences, Beijing 100093, China</p><br><p style="text-align: center;"><sup>2</sup>Institute of Information Engineering, Chinese Academy of Sciences, Beijing 100093, China</p>

<p><strong>Abstract</strong> Mersenne Twister is one of the most useful pseudo random number generator algorithms. There are many shortcomings in Mersenne Twister. For example, it would be predictable and could not pass some of statistical tests when the algorithm generates plenty of pseudo random number generator algorithms. To analyze the security of algorithm, the statistical tests mentioned in NIST 800-22 would be used to evaluate the quality of Mersenne Twister and the pseudocode would be used to analyze the security of the algorithm. Mersenne Twister is very fast, and the developers and researchers have developed the improved versions of this algorithm, even the cryptographically secure version. For these reasons, choosing Mersenne Twister as the alternative pseudo random number generator is reasonable.</p>
<p><strong>Key words</strong> Mersenne Twister, MT19937, statistical test, the analysis of security</p>
<h4 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a><strong>1</strong> 前言</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;随机数在许多领域中都有着大量应用，例如密码学，游戏，数学统计。随机数主要分两类，分别是确定性随机数和非确定性随机数。非确定性随机数也可称为真随机数（True Random Number Generator, TRNG），主要来源于不可预测的物理或者化学熵源，例如电路噪声。真随机数发生器产生的随机数质量十分高，是最理想的随机数来源，但是由于产生的速度太慢，无法满足目前的信息的传输速度，因此目前确定性随机数依然被广泛使用。确定性随机数发生器也称作伪随机数发生器（Pseudorandom Number Generator，PRNG）,它一般是一个随机数生成算法，由于算法是固定的，因此生成的随机数存在许多诸如可预测，质量不高的缺点。因此在使用一个伪随机数发生器之前对其进行评估是十分有必要的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;梅森旋转是目前应用十分广泛的伪随机数生成器算法之一，已经集成在C++等编程语言的标准库中。梅森旋转生成的随机数能通过常见的静态统计测试，并且生成速度十分快，但是它依然存在许多缺点，例如当随机数数量足够时可预测。本文主要对该方法进行质量评估和安全性分析，并且提出一些改进意见。</p>
<h4 id="2-梅森旋转"><a href="#2-梅森旋转" class="headerlink" title="2 梅森旋转"></a><strong>2</strong> 梅森旋转</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MT19937以及MT19937-64标准分别实现了梅森旋转的32位以及64位算法，由于这两者只是参数不同，因此为方便起见，只实现和讨论MT19937标准。MT19937标准采用的梅森素数为219937<br>-1，因此它可生成的随机数范围为[0, 219937 -1]。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;梅森旋转算法实际使用的是旋转的广义反馈移位寄存器（Twisted Generalized Feedback Shift Register,GFSR）[2]，它主要分初始化，旋转生成随机数以及Xorshift后期处理三个步骤。由于MT19937的梅森算法中生成的随机数为32位，因此算法需要624个32位长的状态。在初始化阶段，算法的工作是将我们获得的随机种子经处理填充到所有的624个状态中</p>
<table>
<thead>
<tr>
<th>算法1：初始化</th>
</tr>
</thead>
<tbody>
<tr>
<td>输入: 一个随机种子<em>seed</em></td>
</tr>
</tbody>
</table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mt[0] = seed </span><br><span class="line">a=1812433253  </span><br><span class="line">FOR i FROM 1 TO 623 </span><br><span class="line">  &#123; </span><br><span class="line">     mt[i] = f * (mt[i-1] XOR (mt[i-1] &gt;&gt; 30)) + i    </span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MT19937规定了算法1中的f值为1812433253 ，算法将输入的随机种子赋值给第0个状态，剩余的623个状态则用前一状态值的一系列操作进行赋值更新。当执行完这一算法后，全部的624个状态已经填充完毕，之后梅森算法便可以不断地生成伪随机数。</p>
<table>
<thead>
<tr>
<th>算法2：旋转生成随机数</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">lower_mask = (1 &lt;&lt; 31) - 1, </span><br><span class="line">upper_mask = (1 &lt;&lt; 31)</span><br><span class="line">a = 0x9908B0DF</span><br><span class="line">FOR i FROM 0 TO 623</span><br><span class="line">  &#123;</span><br><span class="line">    x = (mt[i] AND upper_mask) +(mt[(i+1) MOD 32] AND lower_mask)</span><br><span class="line">    xA = x &gt;&gt; 1</span><br><span class="line">    IF (x MOD 2) != 0</span><br><span class="line">    &#123;</span><br><span class="line">      xA = xA XOR a</span><br><span class="line">    &#125;</span><br><span class="line">    mt[i] = mt[(i + 397) MOD 624] XOR xA</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MT19937标准中定义a的值为0x9908B0DF，如算2所示，这部分是进行旋转操作。每生成624个伪随机数后，将执行一次算法2，重新更新624个状态，为生成下一批624个伪随机数做准备。</p>
<table>
<thead>
<tr>
<th>算法3:Xorshift后期处理</th>
</tr>
</thead>
<tbody>
<tr>
<td>输出：生成的伪随机数y</td>
</tr>
</tbody>
</table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">b = 0x9d2c5680 </span><br><span class="line">c = 0xefc60000 </span><br><span class="line">y = mt[i] </span><br><span class="line">y = y XOR (y &gt;&gt; 11) </span><br><span class="line">y = y XOR ((y &lt;&lt; 7) AND b) </span><br><span class="line">y = y XOR ((y &lt;&lt; 15) AND c) </span><br><span class="line">y = y XOR (y &gt;&gt; 18)</span><br></pre></td></tr></table></figure>
<p>每个状态都需要经过Xorshift操作[3]以后才能成为最终输出的伪随机数，由于其中几乎都是移位，因此对CPU来说是十分快的。</p>
<h4 id="3-伪随机数发生器的评估"><a href="#3-伪随机数发生器的评估" class="headerlink" title="3 伪随机数发生器的评估"></a><strong>3</strong> 伪随机数发生器的评估</h4><p>正如前言部分所述，伪随机数发生器的评估是十分有必要的。伪随机数的质量和安全性一般有如下4个评判标准:</p>
<ol>
<li><p>随机数应该有很好的统计属性。例如各态遍历性</p>
</li>
<li><p>不能根据随机数的子序列合理推出其之前或者之后的随机数序列。并且子序列不能提高推出其之前和之后的伪随机序列的可能性。</p>
</li>
<li><p>不能根据内部状态合理推出其之前的内部状态。同样的也不能通过内部状态提高推出其之前的内部状态的可能性。</p>
</li>
<li><p>不能根据内部状态合理推出其之后的内部状态。也不能通过内部状态提高推出其之后的内部状态。</p>
</li>
</ol>
<h4 id="梅森旋转伪随机数的质量评估"><a href="#梅森旋转伪随机数的质量评估" class="headerlink" title="梅森旋转伪随机数的质量评估"></a>梅森旋转伪随机数的质量评估</h4><h6 id="4-1-NIST-800-22测试"><a href="#4-1-NIST-800-22测试" class="headerlink" title="4.1 NIST 800-22测试"></a>4.1 NIST 800-22测试</h6><p><img src="/uploads/梅森旋转安全性分析及改进/f71b3e0010ed24b848ba2860ab7d23f2.png" alt="图1 NIST 800-22随机数测试"></p>
<p style="text-align: center;">图1 NIST 800-22随机数测试</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NIST 800-22文档中提到了许多静态测试[4]，并且提供了测试程序NIST STS-2.1.2。David Johnston认为STS程序存在许多问题，例如经常奔溃，并且给出错误的测试结果，因此他修正了这些错误，并且给出了修正后的程序[5]。本测试采用了该自动化测试程序，在Summary一栏中左侧为测试名称，右侧为测试的统计参数P值，如图可见该梅森旋转算法可以通过文档中提到的所有静态测试。</p>
<h6 id="4-2-PractRand测试"><a href="#4-2-PractRand测试" class="headerlink" title="4.2 PractRand测试"></a><strong>4.2</strong> PractRand测试</h6><p><img src="/uploads/梅森旋转安全性分析及改进/ca660b0cad783b2adf8904c1670f940d.png" alt="图2 PractRand随机数测试"></p>
<p style="text-align: center;">图2 PractRand随机数测试</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PractRand也是目前常采用的测试程序。由图2所示，我们可以看到当随机数输出大小为128G时可以满足常见的静态统计测试，但是当输出随机数的数量达到256G时，BRANK测试无法通过。</p>
<h6 id="4-3-安全性分析"><a href="#4-3-安全性分析" class="headerlink" title="4.3 安全性分析"></a>4.3 安全性分析</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第三部分的算法3将状态进行移位和亦或，最终输出为伪随机数，但是这一过程是可逆的。逆过程的具体证明和分析方法可参看oupo和plusletool的博客[6,7]。</p>
<table>
<thead>
<tr>
<th>算法4: 算法3的逆过程</th>
</tr>
</thead>
<tbody>
<tr>
<td>输出：梅森旋转的中间状态value</td>
</tr>
</tbody>
</table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">value = y </span><br><span class="line">value = value XOR (value &gt;&gt; 18)</span><br><span class="line">value = value XOR (value &lt;&lt; 15) AND 0xefc60000</span><br><span class="line">value = value </span><br><span class="line">       XOR ((value &lt;&lt; 7) &amp; 0x9d2c5680) </span><br><span class="line">       XOR ((value &lt;&lt; 14) &amp; 0x94284000) </span><br><span class="line">       XOR ((value &lt;&lt; 21) &amp; 0x14200000) </span><br><span class="line">       XOR ((value &lt;&lt; 28) &amp; 0x10000000) </span><br><span class="line">value =value </span><br><span class="line">       XOR (value &gt;&gt; 11) </span><br><span class="line">       XOR (value &gt;&gt; 22)</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;算法4描述了如何由伪随机数逆向恢复到梅森旋转算法的状态，因此若我们有624个梅森旋转算法生成的伪随机数，则我们可以由算法4恢复得到624个中间状态。再通过算法2和算法3即可得到接下来的伪随机数了。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是由算法2可知，在进行旋转的时候，需要用到第i个状态，第i+1个状态以及第i+397个状态。因此如果敌手所得到的伪随机数量或者状态不足，则不能恢复所有的624个状态，便也不能继续预测接下来的伪随机数。而且算法2中的旋转操作会直接覆盖之前的内部状态，而且算法中跟mask进行与操作以及右移操作使得它无法再逆向推导出之前的状态，因此所幸的是即使敌手获取到足够量的伪随机数，也无法推出之前的伪随机数。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;梅森旋转算法可以满足常见应用的随机数需求，但是对于加密过程中所需的伪随机数，还是需要使用密码学安全的伪随机数（Cryptographically<br>Secure Pseudo-Random Number<br>Generator，CSPRNG），例如改进版的梅森旋转算法CryptMT。</p>
<h4 id="5-梅森旋转的改进方案"><a href="#5-梅森旋转的改进方案" class="headerlink" title="5 梅森旋转的改进方案"></a><strong>5</strong> 梅森旋转的改进方案</h4><h6 id="5-1-Hash输出"><a href="#5-1-Hash输出" class="headerlink" title="5.1 Hash输出"></a><strong>5.1</strong> Hash输出</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于梅森旋转算法可逆，我们可以通过泄露的伪随机数逆向推算出其内部状态，因此若将最终输出再进行Hash处理，如图3所示，即可使其生成的伪随机数不可逆，这样便可一定程度上提高梅森旋转算法的安全性。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Hash算法不可逆，并且可以被用来生成伪随机数[8]，生成的随机数也具有很好的安全性。此外，SHA-3之所以拥有安全，不可逆等良好的特性，是因为采用了海绵结构，而且目前已经存在基于海绵结构的伪随机数生成器了[9,10]。综上所述，Hash算法可以用于生成质量较高的伪随机数，而且不可逆，若想要更灵活方便地移植使用，则也可以直接使用海绵结构。因此改进方案中采用Hash对梅森算法的输出做最后的处理使其不可逆是合理的。</p>
<p><img src="/uploads/梅森旋转安全性分析及改进/Hash.svg" alt="图3 经过Hash的梅森算法"></p>
<p style="text-align: center;">图3 经过Hash的梅森算法</p>

<h6 id="5-2-间隔输出"><a href="#5-2-间隔输出" class="headerlink" title="5.2 间隔输出"></a><strong>5.2</strong> 间隔输出</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由算法2可知，当梅森算法更新当前第i个状态时必须要用到第i+1个状态以及第i+397个状态。因此如图4所示假设将这些状态每隔一个进行处理输出为伪随机数，则即使敌手获取到大量的间隔伪随机数，并且将他们逆向恢复为算法的内部状态，也无法得到完整的624个状态。若没有完整的624个状态，则也无法继续预测生成接下去的伪随机数。</p>
<p><img src="/uploads/梅森旋转安全性分析及改进/output.svg" alt="图4 间隔输出的梅森算法"></p>
<p style="text-align: center;">图4 间隔输出的梅森算法</p>

<h4 id="6-结论"><a href="#6-结论" class="headerlink" title="6 结论"></a><strong>6</strong> 结论</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据第3部分所描述的4个评估标准可知梅森旋转算法并不完美。它依然无法通过其中的小部分统计测试，例如当生成的伪随机数达到256G时，无法通过BRANK测试。当敌手可以获得超过624个伪随机数时，可以通过逆向推导出其内部状态来预测其接下来生成的伪随机数。不过所幸的是由于其更新内部状态时的操作不可逆，使得它无法推导出已经生成过的伪随机数。对于第四个评估标准，事实上包括梅森旋转在内的确定性的伪随机数发生器都无法满足，因为算法固定，因此只要获取到内部状态，就一定可以推算出之后的伪随机数。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;梅森旋转算法虽然存在许多的缺点，比如当获取到的伪随机数数量足够多时是可以预测的，并且无法通过一些静态统计测试。但是由于它的许多操作都是基于移位的，因此速度更快一些。并且近些年来，许多开发者和研究人员都为改进梅森旋转算法做出了许多努力，诞生了许多更优秀的基于梅森旋转算法的随机数生成器，例如CryptMT，MTGP。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此在通用的软件上使用改进版的梅森旋转算法，以及在加密时使用密码学安全的梅森旋转算法（CryptMT）是十分合理的。</p>
<p><a href="https://github.com/wlmnzf/MT" target="_blank" rel="noopener">代码请看这里</a></p>
<h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p>[1] 徐恒. 确定性随机数产生器安全性分析及改进[D]. 上海交通大学, 2009.</p>
<p>[2] MATSUMOTO M, KURITA Y. Twisted GFSR generators[J]. ACM Transactions on<br>Modeling and Computer Simulation, 1992, 2(3): 179–194.</p>
<p>[3] MARSAGLIA G, OTHERS. Xorshift rngs[J]. Journal of Statistical Software,<br>2003, 8(14): 1–6.</p>
<p>[4] NIST S. 800-22[J]. A Statistical Test Suite for Random and Pseudorandom<br>Number Generators for Cryptographic Applications, 2000, 120.</p>
<p>[5] JOHNSTON D. sp800_22_tests: A python implementation of the SP800-22 Rev 1a<br>PRNG test suite[M]. 2018.</p>
<p>[6] PLUSLETOOL. メルセンヌ・ツイスタのtemperingの逆関数に関する考察[EB/OL]. Plus<br>Le Blog, 1414154296. (1414154296)[2018-07-15].<br><a href="http://plusletool.hatenablog.jp/entry/2014/10/24/213816" target="_blank" rel="noopener">http://plusletool.hatenablog.jp/entry/2014/10/24/213816</a>.</p>
<p>[7] 2014-10-16[EB/OL]. oupoの日記, [2018-07-15].<br><a href="http://d.hatena.ne.jp/oupo/20141016" target="_blank" rel="noopener">http://d.hatena.ne.jp/oupo/20141016</a>.</p>
<p>[8] BOLDYREVA A, KUMAR V. A New Pseudorandom Generator from Collision-Resistant<br>Hash Functions[G]//DUNKELMAN O. Topics in Cryptology – CT-RSA 2012. Berlin,<br>Heidelberg: Springer Berlin Heidelberg, 2012, 7178: 187–202.</p>
<p>[9] BERTONI G, DAEMEN J, PEETERS M等. Sponge-Based Pseudo-Random Number<br>Generators[G]//MANGARD S, STANDAERT F-X. Cryptographic Hardware and Embedded<br>Systems, CHES 2010. Berlin, Heidelberg: Springer Berlin Heidelberg, 2010, 6225:<br>33–47.</p>
<p>[10] BERTONI G, DAEMEN J, PEETERS M等. Duplexing the Sponge: Single-Pass<br>Authenticated Encryption and Other Applications[G]//MIRI A, VAUDENAY S. Selected<br>Areas in Cryptography</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://csuncle.com/2018/08/02/基于无保护AES算法的CPA攻击/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="William Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="会打代码的扫地王大爷">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/02/基于无保护AES算法的CPA攻击/" itemprop="url">基于无保护AES芯片的 CPA攻击</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-02T19:30:08+08:00">
                2018-08-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Cryptology/" itemprop="url" rel="index">
                    <span itemprop="name">密码学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p style="text-align: center;"><br>基于无保护AES芯片的 CPA攻击<br>===========================<br></p>


<p style="text-align: center;">王立敏<sup>1</sup>,丁洁<sup>2</sup> </p>


<p style="text-align: center;"><sup>1</sup>中国科学院信息工程研究所 第五实验室 北京 中国 100093</p>

<p style="text-align: center;"><sup>2</sup> 中国科学院信息工程研究所 第五实验室 北京 中国 100093</p>

<p><strong>摘要</strong> 高级加密标准（Advanced Encryption Standard，AES）是最常用的加密算法之一。为了提升实际应用中加解密操作的速度，或者在小型芯片上完成加密工作，AES通常被集成在加密芯片中。这使得其容易遭受侧信道攻击，尤其是能量分析攻击。本文中将采用相关能量分析（Correlation Power Analysis，CPA）对AES的能量迹和字节替换环节之间的关系进行统计分析来猜测其对应的密钥。其结果表明对于普通的无保护AES芯片，CPA攻击十分有效。</p>
<p>关键词 <strong>侧信道攻击，AES，密码芯片，相关能量分析，能量迹</strong></p>
<p style="text-align: center;">The CPA Attack For Unprotected AES Chips</p>

<p style="text-align: center;">Wang Limin<sup>1</sup>, Ding jie<sup>2</sup></p>

<p style="text-align: center;"><sup>1</sup> Institute of Information Engineering, Chinese Academy of Sciences, Beijing<br>100093, China  </p><br><p style="text-align: center;"><sup>2</sup> Institute of Information Engineering, Chinese Academy of Sciences, Beijing<br>100093, China</p>

<p><strong>Abstract</strong> Advanced Encryption Standard is one of the most commonly used encryption algorithms. In order to improve the speed of encrypted and decrypted operations or encrypt data on chips , the independent AES chip is used for encryption, which makes the chip vulnerable to Side-Channel Attack, especially to Power Analysis. This paper will guess the key of the AES by analyzing the correlation between power trace and SubBytes operation. This experiment shows that CPA attack can help crack secret keys more efficiently.</p>
<p><strong>Key words</strong> Side-Channel Attack, AES, Cipher Chip, Correlation,Power Analysis,Power Trace</p>
<h4 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a><strong>1</strong> 引言</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;侧信道分析技术在硬件安全领域中应用十分广泛。其中较为常见的一种是能量分析，它主要包括三种分析方法，简单能量分析（Simple Power Analysis, SPA），差分能量分析(Differential Power Analysis,DPA)以及相关能量分析(Correlation Power Analysis, CPA)。SPA和DPA最初由Paul Kocher, Joshua Jae, 和 Benjamin Jun 在1999年提出[1]。SPA利用的是密码芯片在进行不同的指令操作时所消耗的能量也不同这一特性，例如AES芯片在执行10轮操作时，它的10个能量消耗峰值将会十分明显。而DPA则更加复杂，它将测出来的能量迹分为几类，并计算它们均值的差，若假设的密钥是正确的，则会出现一个能量波峰，否则差值会在0附近波动。DPA是十分有效的能量攻击方法，但是它依然存在诸如幽灵峰值的问题，而本试验中给出的能量迹又足够多，因此为了提高破译密钥的正确性，本文将采用CPA来对AES进行攻击。CPA由E.Brier提出，是从DPA改进而来，它采用的是汉明重量模型[2]。</p>
<h4 id="2-AES介绍"><a href="#2-AES介绍" class="headerlink" title="2 AES介绍"></a><strong>2</strong> AES介绍</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AES在安全性不低于三重数据加密算法（Triple Data Encryption Algorithm，TDEA，也叫3DES）的同时，运算速度还比它快，因此被采用来替代原先的数据加密标准（Data Encryption Standard，DES），它具有很好的抗差分密码分析和线性密码分析的能力。AES根据密钥的长度的不同有三种不同的版本分别为AES-128，AES-192以及AES-256。本文只讨论利用CPA攻击无保护的AES-128算法，如算法1所示。</p>
<table>
<thead>
<tr>
<th>算法1：无保护的AES-128算法</th>
</tr>
</thead>
<tbody>
<tr>
<td>输入：明文X[0-15],轮密钥RoundKey[0-10] 输出：密文X[0-15]</td>
</tr>
</tbody>
</table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">for r = 0;r ≤ 8;r++ do</span><br><span class="line">     X = X ⊕ RoundKey[r]; /*加轮密钥*/</span><br><span class="line">     </span><br><span class="line">     for i = 0; i≤15; i++ do</span><br><span class="line">       Xi = SubBytes(Xi); /*字节替换*/</span><br><span class="line">     end</span><br><span class="line"></span><br><span class="line">     X = ShiftRows(X); /*行变换*/</span><br><span class="line">     X = *MixColumns*(X); /*列混淆*/</span><br><span class="line"></span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">X = X⊕*RoundKey*[9]; /*最后一轮*/</span><br><span class="line"></span><br><span class="line">for I = 0; i≤15; i++ do</span><br><span class="line">    Xi = SubBytes(Xi);</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">X = ShiftRows（X）</span><br><span class="line">X = X⊕RoundKey[10] /\*获取密文\*/</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AES-128算法需要经过10轮的操作，除了最后一轮之外，前9轮都包括加轮密钥，字节替换，行变换，列混淆这四个步骤，而第十轮则少一个列混淆。这里的11个128位的轮密钥是原始的128位密钥经过密钥扩展得到的。</p>
<h6 id="2-1-密钥扩展"><a href="#2-1-密钥扩展" class="headerlink" title="2.1 密钥扩展"></a><strong>2.1</strong> 密钥扩展</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;密钥扩展是将最初始的128位密钥扩展成11个轮密钥，方便每一轮中的操作。假设有这样一个128位的密钥，如图1所示。然后按每4字节为一列排列成图2所示的阵列。</p>
<p><img src="/uploads/基于无保护AES算法的CPA攻击/key-line.svg" alt="图1 给定的 AES密钥"></p>
<p style="text-align: center;">图1 给定的 AES密钥</p>


<p><img src="/uploads/基于无保护AES算法的CPA攻击/key-table.svg" alt="图2 密钥的排布"></p>
<p style="text-align: center;">图2 密钥的排布</p>


<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;图2中每一列分配一个标记wi，第一列为w0，第二列为w1，以此类推。每一个轮密钥的第一列生成方式都较为复杂，这里以生成第5列（w4）为例。</p>
<p><img src="/uploads/基于无保护AES算法的CPA攻击/leftShift.svg" alt="图3 w3左移一位"></p>
<p style="text-align: center;">图3 w3左移一位</p>


<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图3所示，当将最初的密钥排列完毕以后，需要将最后一列进行循环左移。并且左移后的每个元素都要经过S-BOX的字节替换处理，图四表示了这一过程。关于S-BOX字节替换的详细描述可参看2.3部分。</p>
<p><img src="/uploads/基于无保护AES算法的CPA攻击/key_xbox.svg" alt="图4 左移后经过S-BOX进行字节替换"></p>
<p style="text-align: center;">图4 左移后经过S-BOX进行字节替换</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设正在生成第i列密钥，这里是第5列，即为w4。由于此处是第二个轮密钥的第一列，则经过字节替换后的结果，需要与wi-4即w0以及rcon[i/4-1]即rcon[0]进行异或才能最终得出w4。其中rcon是如图6所示的10列数字。</p>
<p><img src="/uploads/基于无保护AES算法的CPA攻击/firstcolumn.svg" alt="图5 轮密钥第一列生成"></p>
<p style="text-align: center;">图5 轮密钥第一列生成</p>


<p><img src="/uploads/基于无保护AES算法的CPA攻击/rcon.svg" alt="图6 RCON数组"></p>
<p style="text-align: center;">图6 RCON数组</p>


<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;只有轮密钥的第一列需要按照上述方法生成，接下来的三列则通过图7所示的方法，通过将wi-1以及wi-4异或来求得，例如这里轮密钥第二列w5，则是通过w4和w1异或得来的。</p>
<p><img src="/uploads/基于无保护AES算法的CPA攻击/nextColumn.svg" alt="图7 轮密钥第二列生成"></p>
<p style="text-align: center;">图7 轮密钥第二列生成</p>


<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之后的每一个轮密钥都将按照上述方法进行计算得出，轮密钥第一列wi=SubByte（LeftShift（wi-1））⊕wi-4⊕rcon[i/4-1],而第二，三，四列的计算规则为wi=wi-1⊕wi-4。图8即为新生成的轮密钥，可以很明显看出轮密钥0就是最开始输入的密钥，通常对AES的能量分析，都只分析第一轮，这一轮的轮密钥加操作使用的是轮密钥0，即原始输入的密钥。因此在进行CPA攻击时不需要经过密钥扩展这一步。</p>
<p><img src="/uploads/基于无保护AES算法的CPA攻击/allround.svg" alt="图8 新生成的轮密钥"></p>
<p style="text-align: center;">图8 新生成的轮密钥</p>


<h6 id="2-2-加轮密钥"><a href="#2-2-加轮密钥" class="headerlink" title="2.2 加轮密钥"></a><strong>2.2</strong> 加轮密钥</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AES经过密钥扩展得到轮密钥之后，将进行10轮操作，在每一轮操作中都需要加轮密钥。首先需要将明文和轮密钥按4字节为一列排成4列，分别命名为P0-P15和C0-C15,然后将明文和密文，按字节进行异或，即P0⊕C0-P15⊕C15。得到的最终结果可用于后续的字节替换。</p>
<p><img src="/uploads/基于无保护AES算法的CPA攻击/add.svg" alt="图9 轮密钥加"></p>
<p style="text-align: center;">图9 轮密钥加</p>


<h6 id="2-3-字节替换"><a href="#2-3-字节替换" class="headerlink" title="2.3 字节替换"></a><strong>2.3</strong> 字节替换</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;字节替换一般使用的是Rijndael S-box[3],它将需要替换的字节的高四位作为横坐标，低四位作为纵坐标从S-BOX中选中对应的字节作为替代值。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图10，待替代字节为0x01,则横坐标为高四位0x0,纵坐标为低四位0x1，从S-BOX中找到对应坐标的值0x7c，然后将其替换，图10展示S-BOX的替换过程，其中的S-BOX只是完整表格的一部分。</p>
<p><img src="/uploads/基于无保护AES算法的CPA攻击/sbox.svg" alt="图10 S-BOX替换"></p>
<p style="text-align: center;">图10 S-BOX替换</p>


<h4 id="3-CPA攻击"><a href="#3-CPA攻击" class="headerlink" title="3 CPA攻击"></a><strong>3</strong> CPA攻击</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CPA攻击主要采用汉明重量模型。计算汉明重量与对应能量迹之间的相关系数，若相关系数越大，则说明他们之间的相关性越强，若数据中某一猜测密钥对应的相关系数相比于其他相关系数要大的多，就可以说明这一猜测密钥是正确的。</p>
<h6 id="3-1-汉明重量"><a href="#3-1-汉明重量" class="headerlink" title="3.1 汉明重量"></a><strong>3.1</strong> 汉明重量</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;汉明重量可以表示一个二进制字符串中1的个数。已经有论文通过实验证明了输出结果的汉明重量与能量消耗之间有明确的关系，能量消耗随着汉明重量的增大而增大，而且有较为明确的界限，经过计算，它们的相关系数甚至能够达到0.9919[4]。这也说明CPA使用汉明重量模型是合理的。</p>
<h6 id="3-2-CPA攻击方法"><a href="#3-2-CPA攻击方法" class="headerlink" title="3.2 CPA攻击方法"></a><strong>3.2</strong> CPA攻击方法</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于字节替换占用了总能量消耗的大部分[5]，因此在CPA攻击时可以只考虑S-BOX的输出与能量迹之间的关系。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本文将密钥分成16个子密钥分别破解，每一子密钥为一个字节。首先考虑第一个子密钥GuessKey的破解，这里需要将其从0遍历到255，然后每遍历一个值，就参照AES的一轮加密过程，将其与明文pt进行异或，异或之后再经过S-BOX的字节替换即可得到用于求解汉明重量的输入字符串input，如算法2第6行所示。值得注意的是AES加密需要对原始密钥进行密钥扩展，将一个原始密钥扩展成11个轮密钥，但是如算法2第4行所示，这里轮秘钥并不是密钥扩展得到的，而是直接对原始密钥进行了异或。这是因为，从本文2.1部分密钥扩展的过程可以看出，第一个轮密钥就是原始密钥本身，而且此处我们也只需要考虑AES的第一轮能量消耗和汉明重量之间的关系即可，因此在这里进行AES第一轮操作时可以不用进行密钥扩展而直接使用原始密钥。而后将输入字符串input的汉明重量求出，存在数组中，并求出他们与能量迹的Pearson相关系数。于是便可以得到横坐标为256个GuessKey，纵坐标为相关系数的统计图（请参看附件文件夹中的图），若遍历到的密钥不正确，则相关系数的波动幅度并不大，而当猜测的密钥正确时，对应的相关系数将会是一个明显的波峰。</p>
<table>
<thead>
<tr>
<th>算法2：CPA攻击算法</th>
</tr>
</thead>
<tbody>
<tr>
<td>输入：能量迹traces，明文pt 输出：密钥keys</td>
</tr>
</tbody>
</table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">for i = 0; i&lt;16 ;i++ do</span><br><span class="line">    for GuessKey=0;GuessKey&lt;256;GuessKey++ do</span><br><span class="line">       for j = 0;j&lt;TraceCnt;j++ do</span><br><span class="line">             input=pt[j][i]⊕GuessKey;</span><br><span class="line">             input=SubBytes(input);</span><br><span class="line">             hws[j]=HammingWeight(input);</span><br><span class="line">       end</span><br><span class="line"></span><br><span class="line">       for j = 0;j&lt;PointsCnt;j++ do</span><br><span class="line">             pccs[j]=PCC(Trans(traces)[j],hws);</span><br><span class="line">              /*PCC为求Pearson相关系数*/</span><br><span class="line">              /*Trans为矩阵转置*/</span><br><span class="line">       end</span><br><span class="line"></span><br><span class="line">       CPA[GuessKey]=Max(pccs)</span><br><span class="line">     end</span><br><span class="line"></span><br><span class="line">     keys[i]=Argmax(CPA)</span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<h4 id="4-结论"><a href="#4-结论" class="headerlink" title="4 结论"></a><strong>4</strong> 结论</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本次实验所得到的能量迹数据为第36组，攻击源代码可以参看source目录，先通过ReadFile.py读取实验数据,并将其转为攻击代码需要的格式。再执行CPA.py进行攻击，执行过程中通过matplolt画图，可以很清晰地看出相关系数峰值，这些图可以在附件文件夹中看到。最终测算出来的密钥为0x77 70 26 8a 51 bf a9 b2 2f 6f 40 69 c3 95 db 5b。使用source目录下的AES代码[6]加密明文，并将得到的密文与给定的密文进行对比，可确定其为正确的密钥。因此可以认为本攻击手段采用CPA攻击是合理的。</p>
<p><a href="https://github.com/wlmnzf/CPA" target="_blank" rel="noopener">代码在此处下载</a></p>
<h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p>[1] KOCHER P, JAFFE J, JUN B. Differential power analysis[C]//Annual<br>International Cryptology Conference. Springer, 1999: 388–397.</p>
<p>[2] BRIER E, CLAVIER C, OLIVIER F. Correlation Power Analysis with a Leakage<br>Model[G]//JOYE M, QUISQUATER J-J. Cryptographic Hardware and Embedded Systems -<br>CHES 2004. Berlin, Heidelberg: Springer Berlin Heidelberg, 2004, 3156: 16–29.</p>
<p>[3] DAEMEN J. The Rijndael Block Cipher[J]. : 45.</p>
<p>[4] LO O, BUCHANAN W J, CARSON D. Power analysis attacks on the AES-128 S-box<br>using differential power analysis (DPA) and correlation power analysis (CPA)[J].<br>Journal of Cyber Security Technology, 2017, 1(2): 88–107.</p>
<p>[5] MORIOKA S, SATOH A. An Optimized S-Box Circuit Architecture for Low Power<br>AES Design[G]//KALISKI B S, KOÇ çetin K, PAAR C. Cryptographic Hardware and<br>Embedded Systems - CHES 2002. Berlin, Heidelberg: Springer Berlin Heidelberg,<br>2003, 2523: 172–186.</p>
<p>[6] Skycker/AES: Rijndael cipher algorithm[EB/OL]. [2018-07-31].<br><a href="https://github.com/Skycker/AES" target="_blank" rel="noopener">https://github.com/Skycker/AES</a>.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://csuncle.com/2018/02/11/Meltdown &  Spectre原理简要梳理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="William Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="会打代码的扫地王大爷">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/02/11/Meltdown &  Spectre原理简要梳理/" itemprop="url">Meltdown &  Spectre原理简要梳理</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-02-11T09:43:13+08:00">
                2018-02-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/vulnerability-analysis/" itemprop="url" rel="index">
                    <span itemprop="name">vulnerability analysis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spectre以及meltdown漏洞是前段时间，十分热门的两个漏洞，它们之所以广受重视，是因为它们根据的是体系结构的设计漏洞，而非针对某个系统或者某个软件，因此它几乎可以遍及大多数近代的CPU。</p>
<p>这里主要有三个漏洞:</p>
<ul>
<li>Variant 1: bounds check bypass (CVE-2017-5753)【绕过边界检查】</li>
<li>Variant 2: branch target injection (CVE-2017-5715)【分支目标注入】</li>
<li>Variant 3: rogue data cache load (CVE-2017-5754)【恶意数据缓存载入】<br>Spectre 主要利用前两个漏洞进行攻击，而meltdown则主要利用第三个漏洞进行攻击。</li>
</ul>
<h4 id="一、内存映射"><a href="#一、内存映射" class="headerlink" title="一、内存映射"></a>一、内存映射</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Linux和Windows的内存映射方法是不同的，在linux中，虚拟空间地址有4G，0~3G为用户空间，3~4G为内核空间<br><img src="/uploads/Meltdown_Spectre原理简要梳理/1.jpg" alt="虚拟空间"></p>
<p>其中内核空间都相同，准确的讲是每个进程共享同一个内核空间<br><img src="/uploads/Meltdown_Spectre原理简要梳理/2.jpg" alt="虚拟内存"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Linux在启动时会初始化一个进程，然后通过fork()生成子进程，Linux的fork机制会把父进程的页表和堆栈等一模一样地复制一份，然后在运行时，子进程通过缺页异常等操作来改变用户空间，如果内核空间部分也改变了，则只修改初始化进程的内核空间，其它子进程访问该页时，再通过缺页中断将这部分内容从父进程更新过来。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一般来讲，当进程进行系统调用进入内核态的时候，它应该能够访问整个地址空间的，但是在这里只能访问自己的1G的地址空间，于是我们需要通过地址的映射，来使他可以访问整个空间，内核空间分为：ZONE_DMA（内存开始的16MB） 、ZONE_NORMAL（16MB~896MB）、ZONE_HIGHMEM（896MB ~ 结束）三个区域，其中0~896M是直接映射的，其余部分会进行非线性映射。</p>
<p><img src="/uploads/Meltdown_Spectre原理简要梳理/3.jpg" alt="这里写图片描述"></p>
<h4 id="二、Tomasulo算法"><a href="#二、Tomasulo算法" class="headerlink" title="二、Tomasulo算法"></a>二、Tomasulo算法</h4><p><img src="/uploads/Meltdown_Spectre原理简要梳理/4.png" alt="tomasylo"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;原始的Tomasulo算法是为了寄存器重命名以便消除指令的数据相关，数据一到就可以执行指令。</p>
<ol>
<li>指令首先存在于指令队列之中。</li>
<li>指令一条一条地从队列中取出来，进行译码，然后放到对应的操作保留站中，比如加法指令放到加法保留站中。乘法指令放到乘除法保留站中。Vj和Vk中是用来存储源操作数的（已经就绪的源操作数值取自于浮点寄存器），若源操作数还没有准备好，则通过Qj和Qk指向操作数的保留站号，等到被指向的保留站中的操作计算出了结果，则结果可以通过结果总线传回到保留站中需要的指令，然后将其Qj和Qk中的值改为0（表示已经准备好）。</li>
<li>当Qj和Qk都为0时，那一条指令就可以送到乘/除器中执行。</li>
</ol>
<h4 id="三、乱序执行"><a href="#三、乱序执行" class="headerlink" title="三、乱序执行"></a>三、乱序执行</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最早期 CPU都是顺序执行的，前一条指令未执行完毕，则后一条指令必须等待着，就像我们烧水，必须洗茶壶，烧水，洗茶杯，倒水必须按照顺序来做，但是事实上烧水和洗茶杯可以同时执行，其实有很多指令也是如此，调整它们的顺序可以加快程序执行的速度</p>
<p>可能会造成乱序执行的原因：</p>
<ol>
<li>编译器为了优化而实现指令重排（静态调度）</li>
<li>CPU实现指令的多发射，以及并行执行，并为了优化实现指令的重排（动态调度）</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;程序的乱序执行并不意味着在所有步骤中，指令的顺序都是混乱的，事实上，指令在发射时和提交时依然是顺序的，只是在执行的过程中会打乱顺序。</p>
<p>为了支持乱序执行<br><img src="/uploads/Meltdown_Spectre原理简要梳理/5.png" alt="带有ROB的Tomasulo算法"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们在Tomasulo  算法中加入了ROB来使得提交结果的时候能够按照顺序提交，执行的结暂时存放于ROB而不直接写入寄存器堆，然后再按顺序提交数据。从而可以不出问题。</p>
<p>本次的漏洞就是利用了这一特性来实现的</p>
<h4 id="四、分支预测"><a href="#四、分支预测" class="headerlink" title="四、分支预测"></a>四、分支预测</h4><p>由于在指令中存在许多跳转和分支，为了提前访问分支中的代码以解决时间，我们加入了分支预测功能</p>
<h6 id="静态分支"><a href="#静态分支" class="headerlink" title="静态分支"></a>静态分支</h6><p>对于所有的跳转指令，我们都预测执行跳转或者执行不跳转，则称其为静态跳转</p>
<h6 id="动态分支"><a href="#动态分支" class="headerlink" title="动态分支"></a>动态分支</h6><p>动态分支将会通过历史跳转信息来预测下一次分支应该选择跳转还是选择不跳转。在intel设计中有一个称为BTB(Branch Target Buffer)的部件，当我们执行分支指令时，会将执行结果和分支指令地址记录在其中，当下次取址时，查询其中的记录，若存在，则根据历史执行记录进行预测是否跳转。</p>
<p>若不存在此记录，我们将会使用静态分支预测器，我们一般将向上跳转的分支指令看作循环，对于循环我们倾向于接受跳转，而对于向下跳转，我们倾向于不跳转。</p>
<h4 id="五、Meltdown攻击"><a href="#五、Meltdown攻击" class="headerlink" title="五、Meltdown攻击"></a>五、Meltdown攻击</h4><p><img src="/uploads/Meltdown_Spectre原理简要梳理/6.png" alt="这里写图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在第一行，我们引发了一个异常，若程序按照顺序执行，第三行的access将不会被执行，但是由于程序是乱序执行的，因此在异常引发之前，第三行的access将被执行，但是执行结果存在ROB中不会被提交，当异常触发以后，第三行的执行结果将被撤销掉，从计算机外部看来第三行的access就跟从未被执行过一样，但是事实上它只是在后期被撤销了，这会带来一个小问题，就是在执行过程中，刚才读取的数据已经被存储到高速缓存中。</p>
<p>我们可以通过侧信道攻击来确认刚才访问的数据是什么。</p>
<p><img src="/uploads/Meltdown_Spectre原理简要梳理/7.png" alt="这里写图片描述"><br>这段代码揭示了攻击的关键部分<br>首先我们将访问内核地址并取内容到寄存器内，<br>若这一举动可以触发异常，则对应的寄存器清零，若异常未处理，则应用程序将会被终止，并且取出的值将会存入应用程序核心转储的寄存器中。我们要做的就是通过第5行将相应的寄存器清零，从而可以判断这是一个错误的值。然后再次重试，直到遇到一个不为0的值，然后将秘密的值作为地址，去做读取操作，以便cache记录到这个地址，实现侧信道攻击。</p>
<h4 id="六、Spectre"><a href="#六、Spectre" class="headerlink" title="六、Spectre"></a>六、Spectre</h4><p><img src="/uploads/Meltdown_Spectre原理简要梳理/8.png" alt="这里写图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spectre主要利用了分支预测和乱序执行的漏洞实现的，如图所示的代码，看起来十分地正常，若x小于array1的长度的时候，循环顺利执行。但是我们假设这里有一个存储密码的变量地址为secret，并且令a=secret-array1，于是我们可以使用array1[a]来表示secret的值。当多次执行循环的时候，我们的x满足循环条件，则我们的分支预测模块会认为下一个循环也满足循环条件而去预执行这个循环，若此时我们将a的值赋值给x，则分支预测模块预测本次循环为执行（其实并不会执行），CPU会预执行这个循环体，然后将我们存储密码的secret值取出来，并将其作为地址去访问array2，但是最终发现循环不应该被执行，于是刚才取出来的值将会被作废。但是我们的这个secret值的地址已经被存入到缓存中去。我们最终可以将array2读取一遍，若读取某个地址的时候，访问的时间特别短，则说明这个地址就是那个被存入缓存的地址（即我们的密码值）。</p>
<h4 id="七、参考"><a href="#七、参考" class="headerlink" title="七、参考"></a>七、参考</h4><p><a href="https://googleprojectzero.blogspot.co.at/2018/01/reading-privileged-memory-with-side.html" target="_blank" rel="noopener">https://googleprojectzero.blogspot.co.at/2018/01/reading-privileged-memory-with-side.html</a></p>
<p><a href="https://lwn.net/Articles/738975/" target="_blank" rel="noopener">https://lwn.net/Articles/738975/</a></p>
<p><a href="http://lib.csdn.net/article/linux/29085" target="_blank" rel="noopener">http://lib.csdn.net/article/linux/29085</a></p>
<p><a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=1272" target="_blank" rel="noopener">https://bugs.chromium.org/p/project-zero/issues/detail?id=1272</a></p>
<p><a href="http://blog.csdn.net/yiyeguzhou100/article/details/72875122" target="_blank" rel="noopener">http://blog.csdn.net/yiyeguzhou100/article/details/72875122</a></p>
<p><a href="https://bbs.pediy.com/thread-61327.htm" target="_blank" rel="noopener">https://bbs.pediy.com/thread-61327.htm</a></p>
<p><a href="http://blog.csdn.net/muxiqingyang/article/details/6686738" target="_blank" rel="noopener">http://blog.csdn.net/muxiqingyang/article/details/6686738</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://csuncle.com/2017/10/20/【论文阅读】Shakti-T-A-RISC-V-Processor-with-Light-Weight-Security-Extensions/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="William Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="会打代码的扫地王大爷">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/20/【论文阅读】Shakti-T-A-RISC-V-Processor-with-Light-Weight-Security-Extensions/" itemprop="url">【论文阅读】Shakti-T: A RISC-V Processor with Light Weight Security Extensions</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-10-20T15:24:49+08:00">
                2017-10-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper/" itemprop="url" rel="index">
                    <span itemprop="name">Paper</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于计算核芯和电子商务的兴起，有必要在硬件层面保护我们的数据安全，目前面临的主要威胁是来自内存的攻击，包括时间和空间上两方面的侵入，团队制造出了一个名为Shakti-T的轻量级安全扩展芯片来解决这些问题，本处理器仅使用194个LUTs以及2197个触发器。</p>
<h4 id="二、攻击类型"><a href="#二、攻击类型" class="headerlink" title="二、攻击类型"></a>二、攻击类型</h4><p>刚刚提到了基于内存的攻击</p>
<pre><code>1. 基于空间上的攻击 -指针访问了它不允许被访问的地方。
   比较著名的例子有buffer-overflow，blaster-worm以及用于DDoS的slammer worm,安卓的Root也是利用了这个原理.
2. 基于时间上的攻击 -指针访问了已经被释放的地方。
</code></pre><h4 id="三、解决方案"><a href="#三、解决方案" class="headerlink" title="三、解决方案"></a>三、解决方案</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前人对这两个问题提出了许多解决方案，为了解决问题一，有人提出了Lock and Key的方案，或者</p>
<pre><code>- Stack Canaries,
- Encryption of The Code Pointer,
- Rearranging argument locations,
- 以及the Address Space Layout Randomization(ASLR)
</code></pre><p>等方法，而对于问题二，也有人提出富指针的方案，其中ASLR是抵御ROP(Return Oriented Programming)问题最好的方法，但是它依然存在一些问题，攻击者可以通过改变控制流的方法来绕过它们的检查。同时富指针方案也存在着高开销，缺乏稳定性等问题，即便有硬件层面的解决方案，当多个指针同时存在时也会失效。</p>
<h4 id="四、富指针（Fat-Pointer）"><a href="#四、富指针（Fat-Pointer）" class="headerlink" title="四、富指针（Fat-Pointer）"></a>四、富指针（Fat-Pointer）</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所谓富指针就是指，在原先指针的数据结构上再加上基地址和限长两个元素，每次为指针分配一个地址空间的时候，都会自动写入这块地址的起始位置和长度，而每次访问指针时，都会检查是否越界，以此来防止指针在释放后再次读取的问题.但是传统的方法有一个十分遗憾的问题，假如存在{P1，P2…..Pn}n个指针，它们同时指向同一个空间，当释放其中一个以后，由于是各存一份，访问其它指针依然会认为是正常访问，但实际上已经出现了空间上的攻击。</p>
<h4 id="五、提出的方案"><a href="#五、提出的方案" class="headerlink" title="五、提出的方案"></a>五、提出的方案</h4><p> 我们使用的是基于硬件的富指针:</p>
<ol>
<li>基地址和边界统一存放于一个PLM（Pointer Limits Memory），而PLM的地址存于PLBR寄存器</li>
<li>每一个指针对应一个ptr_id</li>
<li>每次调用指针时使用ptr_id调取对应的基地址和边界，<br><img src="/uploads/A_RISC-V_Processor_with_Light_Weight_Security_Extensions/1.png" alt="表格"></li>
</ol>
<p>我们使用如图表格来作为缓存，</p>
<ol>
<li>其中左边的GPR（General Purpose Register）分两个部分一个是Tag bits，用于标记是数据还是指针，另一部分是寄存器的数值。</li>
<li>右边的BnBIndex和BnBLookUp包含在一个名为BnBCache的寄存器中，BnBIndex中的index表示BnBLookUp的位置，有效位V的值若为1，则表示可以从BnBLookUp中取到值，若为0，则说明需要从内存中去取所需的信息，当BnBLookUp中的信息被更新时，BnBindex中的信息也会被同步更新。BnBLookUp中的有效位V为1则表示它目前可用，为0则表示它可能被释放了。当BnBLookUp中的空间不足，则用LRU(最近最少使用)算法进行替换。</li>
</ol>
<h4 id="六、副作用及解决方案"><a href="#六、副作用及解决方案" class="headerlink" title="六、副作用及解决方案"></a>六、副作用及解决方案</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比如有的时候调用函数，某个寄存器被push了，若此时正好这个寄存器被替换出去，但是当数据再次被pop的时候那个寄存器已经是无效的了。于是需要新设计一个BnBStack（Base and Bound Stack）用于专门存放暂时被push的指针ptr_id.</p>
<h4 id="七、结果"><a href="#七、结果" class="headerlink" title="七、结果"></a>七、结果</h4><ol>
<li>安全性：还是同样的问题，此处有（P1，P2….Pn）n个指针，若它们指向同一个地址，其中一个释放以后，BnBLookUp中有效位被置0，其它指针再访问它时，就可以得知它是无效的消息。</li>
<li>节约内存 :（P1，P2….Pn）n个指针,若他们指向同一个地址，则需要存n个ptr_id和1个base，一个bound，共n+2个空间。但传统的方法，每一个指针都需要存一份，则需要2n个空间。但如果这些指针分别指向不同的空间，则本方案更耗费一些空间。</li>
</ol>
<div style="color:white"><br><span>William</span><br><span>会打代码的扫地王大爷</span><br><span>wlmnzf</span><br><span>中科院信工所</span><br><span>IIE</span><br><span>CAS</span><br><span>csuncle</span><br><span>丁洁的男朋友</span><br><span>丁洁的人</span><br><span>王立敏</span><br></div>


          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://csuncle.com/2017/08/08/Windows-linux子系统-入门到GUI/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="William Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="会打代码的扫地王大爷">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/08/Windows-linux子系统-入门到GUI/" itemprop="url">Windows linux子系统--入门到GUI</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-08T23:21:35+08:00">
                2017-08-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/WSL/" itemprop="url" rel="index">
                    <span itemprop="name">WSL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="一、安装"><a href="#一、安装" class="headerlink" title="一、安装"></a>一、安装</h2><h4 id="1-1、组件安装"><a href="#1-1、组件安装" class="headerlink" title="1.1、组件安装"></a>1.1、组件安装</h4><p>Windows 10中默认并没有安装子系统组件，我们需要安装它</p>
<blockquote>
<p>控制面板-&gt;程序-&gt;程序与功能-&gt;启用和关闭Windows功能-&gt;勾选适用于Linux的Windows子系统Beta，确定即可安装。</p>
</blockquote>
<h4 id="1-2、开发者权限开启"><a href="#1-2、开发者权限开启" class="headerlink" title="1.2、开发者权限开启"></a>1.2、开发者权限开启</h4><blockquote>
<p>设置-&gt;更新和安全-&gt;针对开发人员-&gt;选中 开发人员模式</p>
</blockquote>
<h4 id="1-3、安装"><a href="#1-3、安装" class="headerlink" title="1.3、安装"></a>1.3、安装</h4><p>打开 命令提示符，输入bash进行安装，但是比较慢，建议挂载 V P N进行下载。</p>
<h2 id="二、常见功能使用"><a href="#二、常见功能使用" class="headerlink" title="二、常见功能使用"></a>二、常见功能使用</h2><blockquote>
<p>Tips:如果你的Windows是正式版的，并没有通过快速更新到Windows秋季创意者版本，那么你的ubuntu版本是14.04版本的。</p>
</blockquote>
<h4 id="2-1、更换源"><a href="#2-1、更换源" class="headerlink" title="2.1、更换源"></a>2.1、更换源</h4><p>此处采用@littlemonsters的方法，将其更换为阿里云的源，否则不仅速度慢，而且有些源中的软件包版本实在是低下，会有很多问题比如Nodjs安装。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak #备份</span><br><span class="line">sudo vim /etc/apt/sources.list #修改</span><br></pre></td></tr></table></figure></p>
<p>将阿里云的源复制进去<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update #更新列表</span><br></pre></td></tr></table></figure>
<h4 id="2-2、常见使用方法"><a href="#2-2、常见使用方法" class="headerlink" title="2.2、常见使用方法"></a>2.2、常见使用方法</h4><h5 id="2-2-1-启动"><a href="#2-2-1-启动" class="headerlink" title="2.2.1.启动"></a>2.2.1.启动</h5><p>使用<code>bash</code>即可在当前目录启动linux</p>
<h5 id="2-2-2-重装"><a href="#2-2-2-重装" class="headerlink" title="2.2.2.重装"></a>2.2.2.重装</h5><p>有的时候linux被我们玩坏了，大环境结果全乱掉了，最好的办法就是重装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lxrun /uninstall    卸载linux子系统</span><br><span class="line">lxrun /install        安装linux子系统</span><br></pre></td></tr></table></figure>
<h2 id="三、显示GUI"><a href="#三、显示GUI" class="headerlink" title="三、显示GUI"></a>三、显示GUI</h2><h5 id="我们只有一个命令行，看起来就像连接服务器的shell，那万一我们需要运行我们的桌面窗口程序呢？国外大神们当然已经折腾除了方法。"><a href="#我们只有一个命令行，看起来就像连接服务器的shell，那万一我们需要运行我们的桌面窗口程序呢？国外大神们当然已经折腾除了方法。" class="headerlink" title="我们只有一个命令行，看起来就像连接服务器的shell，那万一我们需要运行我们的桌面窗口程序呢？国外大神们当然已经折腾除了方法。"></a>我们只有一个命令行，看起来就像连接服务器的shell，那万一我们需要运行我们的桌面窗口程序呢？国外大神们当然已经折腾除了方法。</h5><h4 id="3-1、安装VcXsrv"><a href="#3-1、安装VcXsrv" class="headerlink" title="3.1、安装VcXsrv"></a>3.1、安装VcXsrv</h4><blockquote>
<p>下载地址:<a href="https://sourceforge.net/projects/vcxsrv/" target="_blank" rel="noopener">https://sourceforge.net/projects/vcxsrv/</a></p>
</blockquote>
<p>安装以后会有两个程序，分别是XLaunch和VcXsrv，它们可以用来远程访问linux。所以其实在这里就是利用它们来访问命令行内的linux。</p>
<h4 id="3-2、Linux内安装桌面"><a href="#3-2、Linux内安装桌面" class="headerlink" title="3.2、Linux内安装桌面"></a>3.2、Linux内安装桌面</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install ubuntu-desktop</span><br><span class="line">sudo apt-get install unity</span><br><span class="line">sudo apt-get install compizconfig-settings-manager</span><br></pre></td></tr></table></figure>
<p>接着配置显示方式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br><span class="line">sudo vim .bashrc</span><br><span class="line">把export DISPLAY=:0.0复制进去</span><br></pre></td></tr></table></figure></p>
<h4 id="3-3、配置compiz"><a href="#3-3、配置compiz" class="headerlink" title="3.3、配置compiz"></a>3.3、配置compiz</h4><ol>
<li><p>打开刚才安装的XLaunch</p>
</li>
<li><p>命令行输入<code>sudo ccsm</code>进入显示界面，这里和后面的打开compiz建议用管理员权限，理论上不加管理员也可以，但是本人在使用过程中出了不少奇怪的问题。</p>
</li>
<li><p>如图所示勾选上需要安装的插件<br><img src="/uploads/Windows-linux子系统入门到GUI/1.png" alt="这里写图片描述"></p>
</li>
</ol>
<p><img src="/uploads/Windows-linux子系统入门到GUI/2.png" alt="这里写图片描述"><br><img src="/uploads/Windows-linux子系统入门到GUI/3.png" alt="这里写图片描述"></p>
<p>   点击close关闭即可。</p>
<h5 id="PS：如果遇到配置选项无法保存的情况，可尝试以下方法"><a href="#PS：如果遇到配置选项无法保存的情况，可尝试以下方法" class="headerlink" title="PS：如果遇到配置选项无法保存的情况，可尝试以下方法"></a>PS：如果遇到配置选项无法保存的情况，可尝试以下方法</h5><ol>
<li><p>安装compizconfig-backend-gconf</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install compizconfig-backend-gconf</span><br></pre></td></tr></table></figure>
</li>
<li><p>进入CCSM-&gt;Preferences,将Backend改为Gsettings Configuration Backend，并且勾选Enable Intergration into the desktop environment </p>
</li>
<li><p>勾选插件，如果遇到冲突，则把冲突的插件关闭即可（确保上图的几个插件勾选，别的可以关闭，即可）</p>
</li>
</ol>
<h4 id="3-4、开启桌面"><a href="#3-4、开启桌面" class="headerlink" title="3.4、开启桌面"></a>3.4、开启桌面</h4><p>输入<code>sudo compiz</code> 不出意外的话即可在XLaunch上看到桌面的真正面目了。<br><img src="/uploads/Windows-linux子系统入门到GUI/4.png" alt="这里写图片描述"></p>
<p>这里如果不用sudo,在我这里就是不加载插件，也没有任何报错提示，就是这么吓人。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://csuncle.com/2017/07/03/机器学习之梯度下降法数学推导-分类/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="William Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="会打代码的扫地王大爷">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/03/机器学习之梯度下降法数学推导-分类/" itemprop="url">机器学习之梯度下降法数学推导--分类</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-07-03T02:28:47+08:00">
                2017-07-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MachineLearning/" itemprop="url" rel="index">
                    <span itemprop="name">MachineLearning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>PS:本文中的log等同于我们国内的ln</p>
</blockquote>
<h3 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;之前那一文中提到了一般的梯度上升的公式推导，但是在《机器学习实战》一书中，实现的是分类方法，因此，虽然最终的结果相似，但是其实本质有很大的不同。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;一般来讲我们把实物分成两类，因此我们需要将结果映射到两个结果(是或非)，因为一般的阶跃函数在求导之类的问题上会变得相当复杂，因此我们用一个更加圆滑的sigmoid函数来映射，所有输入到这个函数的实数都会被转化到0-1之间，它的公式为 $ g(z)=\frac{1}{1+e^{-z}} $ </p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;同时它对应的图像如图所示:<br><img src="/uploads/机器学习之梯度下降法数学推导--分类/1.png" alt="sigmoid"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;于是我们可以将得到的结果进行四舍五入，分类成0或1</p>
<h3 id="Logistic-回归"><a href="#Logistic-回归" class="headerlink" title="Logistic 回归"></a>Logistic 回归</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;这里的意思是，将我们的分类边界线作模型，进行拟合，并以此来分类。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp; 我们假设经过sigmoid函数处理过的结果为 $h_{\Theta}(x)$ ,因为是在0-1之间，因此可以看做是概率，另外，我们可以假设，分类到0或者1的概率。</p>
<p>$$<br>P(y=1|x;\theta)=h_{\theta}(x)  \\<br>P(y=0|x;\theta)=1-h_{\theta}(x)    \tag{1}<br>$$</p>
<p>将以上两个概率公式整合一下成为一个概率公式，</p>
<p>$$<br>p(y|x;\theta)=(h_\theta(x))^y(1-h_\theta(x))^{1-y}   \tag{2} \\<br>$$</p>
<h3 id="梯度上升解决回归问题"><a href="#梯度上升解决回归问题" class="headerlink" title="梯度上升解决回归问题"></a>梯度上升解决回归问题</h3><h4 id="1-最大似然估计"><a href="#1-最大似然估计" class="headerlink" title="1. 最大似然估计"></a>1. 最大似然估计</h4><p>&nbsp;&nbsp;&nbsp;&nbsp; 这里我们使用最大似然估计法，这个在大学的高等数学中应该都有学习过，就不在赘述。这里假设我们有m个训练集。</p>
<p>$$<br>L( \theta )=\prod_{i=1}^{m}p(y^{(i)}|x^{(i)};\theta)=\prod_{i=1}^{m}(h_\theta(x^{(i)}))^{y^{(i)}}(1-h_\theta(x^{(i)}))^{1-{y^{(i)}}}      \tag{3}<br>$$</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp; 为了求导方便，我们一般会将似然函数L加上log函数，因为log函数是递增函数，因此不影响似然函数求最值。<br>这里会用到一个log函数的性质 $log a^b=b log a$ ，推导得：</p>
<p>$$<br>l(\theta)=logL(\theta)=\sum_{i=1}^my^{(i)}logh(x^{(i)})+(1-y^{(i)})log(1-h(x^{(i)}))    \tag{4}<br>$$</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp; 将l函数对$\theta$求导</p>
<p>$$<br>\frac{\partial}{\partial\theta_j }l(\theta)=(y\frac{1}{h_\theta (x)}-(1-y)\frac{1}{1-h_\theta (x)})\frac{\partial}{\partial\theta_j}h_\theta x           \tag{5}<br>$$</p>
<h4 id="2-sigmoid函数求导"><a href="#2-sigmoid函数求导" class="headerlink" title="2. sigmoid函数求导"></a>2. sigmoid函数求导</h4><p>$$<br>\begin{equation}<br>\begin{split}<br>&amp;h’(x)=\frac{d}{dx}\frac{1}{1+e^{-x}}\\<br>&amp;=\frac{1}{(1+e^{-x})^2} (e^{-x})\\<br>&amp;=\frac{1}{(1+e^{-x})}(1-\frac{1}{(1+e^{-x})})\\<br>&amp;=h(x)(1-h(x))<br>\end{split}<br>\end{equation}         \tag{6}<br>$$</p>
<h4 id="3-似然估计后续"><a href="#3-似然估计后续" class="headerlink" title="3.  似然估计后续"></a>3.  似然估计后续</h4><p>&nbsp;&nbsp;&nbsp;&nbsp; 从上一篇文章，或者从《机器学习实战》chapter5 中可得sigmoid函数h(x)的输入函数是$w=\theta^Tx$,将其代入公式(4)，得到</p>
<p>$$<br>\begin{equation}<br>\begin{split}<br>&amp;l’(\theta)=(y\frac{1}{h(\theta^Tx)}-(1-y)\frac{1}{1-h{(\theta^Tx)}}) \frac{\partial}{\partial\theta_j}h(\theta^Tx)\\<br>&amp;=(\frac{1}{h(\theta^Tx)}-(1-y)\frac{1}{1-h(\theta^Tx)})h(\theta^Tx)(1-h(\theta^Tx)\frac{\partial}{\partial_j}\theta^Tx)\\<br>&amp;=(y(1-h(\theta^Tx))-(1-y)h(\theta^T x))x_j\\<br>&amp;=(y-h_\theta(x))x_j<br>\end{split}<br>\end{equation}         \tag{7}<br>$$</p>
<div style="color:white"><br><span>William</span><br><span>会打代码的扫地王大爷</span><br><span>wlmnzf</span><br><span>中科院信工所</span><br><span>IIE</span><br><span>CAS</span><br><span>csuncle</span><br><span>丁洁的男朋友</span><br><span>丁洁的人</span><br><span>王立敏</span><br></div>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://csuncle.com/2017/06/13/机器学习之梯度下降法数学推导--回归/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="William Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="会打代码的扫地王大爷">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/13/机器学习之梯度下降法数学推导--回归/" itemprop="url">机器学习之梯度下降法数学推导--回归</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-13T16:00:43+08:00">
                2017-06-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MachineLearning/" itemprop="url" rel="index">
                    <span itemprop="name">MachineLearning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;本来对数学没什么感觉的，但是停摆了一年复习考研，于是开始对数学有些感觉了，之前看到《机器学习实战》中第五章中梯度上升法，使用了一个它所谓的十分简单的推导，一直好奇怎么个简单法，于是重新学习机器学习的相关算法，这次将主推数学推导。</p>
<h4 id="有监督回归算法"><a href="#有监督回归算法" class="headerlink" title="有监督回归算法"></a>有监督回归算法</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;在机器学习中，多元线性回归模型是经常使用的模型，比如在吴恩达《斯坦福机器学习》中的例子，我们需要根据已有的房价信息预测当前房子的房价，于是我们收集到一些房价数据。</p>
<p><img src="/uploads/机器学习之梯度下降法数学推导--回归/1.png" alt="房价信息"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;再将它们画在二维坐标上，它们就以离散的点分布在平面上，如下所示<br><img src="/uploads/机器学习之梯度下降法数学推导--回归/2.png" alt="房价分布情况"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;我们希望能根据这些已知的点来预测我们想知道的房子的房价，因此我们需要找到一条规律，也就是一条大致经过这些点的线性模型，在数学上我们通常称之为拟合，而这个拟合的过程，我们称之为回归。</p>
<p><img src="/uploads/机器学习之梯度下降法数学推导--回归/3.png" alt="拟合结果"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;假设我们建立的模型是一元一次的，将得到这样的拟合结果，于是我们可以x轴上的房屋面积，找到对应的房屋价格。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;有监督的学习算法，可以理解成我们训练模型的时候每一个输入都是有标准答案的，我们通过预测值跟标准答案的比对，不断修改模型的参数才能最终实现较好地的拟合结果。</p>
<h4 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;最小二乘法是我们经常使用的拟合算法，它通过最小化误差的平方和寻找数据的最佳函数匹配。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;以我们《机器学习实战》第五章作例子，我们假设的模型为z，于是函数即可设为</p>
<p>$$<br>\begin{equation}<br>z=w0+w_1x_1+w2x2+w3x3+….+w_nx_n\\=w_0x_0+w_1x_1+w2x2+w3x3+….+w_nx_n (x0=1)  \tag{1}<br>\end{equation}<br>$$</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这种写法也可以表示为向量的写法:</p>
<p>$$<br>z=w^Tx=<br>\begin{bmatrix}<br>w_0&amp;w_1&amp;…&amp;w_n<br>\end{bmatrix}<br>\begin{bmatrix}<br>x_0\\<br>x_1\\<br>…\\<br>x_n\\<br>\end{bmatrix} \tag{2}<br>$$</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;同样的道理，我们也可以这样子表示</p>
<p>$$<br>z=x^Tw=<br>\begin{bmatrix}<br>x_0&amp;x_1&amp;…&amp;x_n<br>\end{bmatrix}<br>\begin{bmatrix}<br>w_0\\<br>w_1\\<br>…\\<br>w_n\\<br>\end{bmatrix} \tag{3}<br>$$</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;刚才我们也提到了，最小二乘法拟合的原理是最小化误差的平方和，我们将这个平方和称为损失函数，跟我们平时常用的方差类似，当这个损失函数越小，我们的模型就越能跟离散的点匹配起来:</p>
<p>$$<br>f(w)=\frac{1}{2} \sum_{i=1}^m(z_w( x_i) -y_j   )^2    \tag{4}<br>$$</p>
<p>其中的y表示我们给出的标准的特征 $<br>\begin{bmatrix}<br>y_0\\<br>y_1\\<br>…\\<br>y_m\\<br>\end{bmatrix}<br>$</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;因为梯度上升算法是用来计算函数的最大值的，而梯度下降算法则是计算函数最小值的。而我们的损失函数自然是越小越好，我们需要求得一个系数来使得f(w)最小，可是使用梯度上升法是用于求最大值的，因此为了用上梯度上升算法，我们最终应该在f(w)前加上负号。假设:</p>
<p>$$<br>J(w)=-f(w) \tag{5}<br>$$</p>
<p>接下来我们开始利用矩阵来推算我们的数学公式，因为原始的公式用来做迭代计算会很不方便，因此我们需要一个等价的公式来让我们的算法更加高效，就例如《机器学习实战》chapter5中的那样。假设我们的输入为X,我们有m组训练数据，每个数据有n个特征。则:</p>
<p>$$<br>\begin{equation}<br>X=<br>        \begin{bmatrix}<br>        x_{11}&amp;x_{12}&amp;…&amp;x_{1n}\\<br>        x_{21}&amp;x_{22}&amp;…&amp;x_{2n}\\<br>        …&amp;…&amp;…&amp;…\\<br>        x_{m1}&amp;x_{m2}&amp;…&amp;x_{mn}\<br>        \end{bmatrix}<br>        =<br>        \begin{bmatrix}<br>        x_1^{T}\\<br>        x_2 ^{T}\\<br>        …\\<br>        x_m\\<br>        \end{bmatrix}   \tag{6}<br>     \end{equation}<br>$$</p>
<p>于是通过（3）可以推出</p>
<p>$$<br>Xw=<br>\begin{bmatrix}<br>x_1^T\\<br>x_2^T\\<br>…\\<br>x_m^T\\<br>\end{bmatrix}<br>w=<br>\begin{bmatrix}<br>x_1^Tw\\<br>x_2^Tw\\<br>…\\<br>x_m^Tw\\<br>\end{bmatrix}=<br>\begin{bmatrix}<br>z_w(x_1)\\<br>z_w(x_2)\\<br>…\\<br>z_w(x_m)\\<br>\end{bmatrix} \tag{7}<br>$$</p>
<p>$$<br>Xw-\overrightarrow{y}=<br>\begin{bmatrix}<br>x_1^Tw\\<br>x_2^Tw\\<br>…\\<br>x_m^Tw\\<br>\end{bmatrix}-<br>\begin{bmatrix}<br>y_1\\<br>y_2\\<br>…\\<br>y_m\\<br>\end{bmatrix}=<br>\begin{bmatrix}<br>z_w(x_1)-y_1\\<br>z_w(x_2)-y_2\\<br>…\\<br>z_w(x_m)-y_m<br>\end{bmatrix} \tag{8}<br>$$</p>
<p>由矩阵内积可得</p>
<p>$$<br>\because z^Tz=\sum_i^nz_i^2  \tag{9}<br>$$</p>
<p>$$<br>\therefore \frac{1}{2}(Xw-\overrightarrow{y})^T(Xw-\overrightarrow{y})= \frac{1}{2}\sum_{i=1}^n(z_w(x_i)-y_i)^2=f(w)   \tag{10}<br>$$</p>
<p>则梯度为</p>
<p>$$<br>\begin{equation}<br>\begin{split}<br>&amp;\nabla_wf(w)=\nabla_w\frac{1}{2}(Xw-\overrightarrow{y})^T(Xw-\overrightarrow{y})\\<br>&amp;=\frac{1}{2}\nabla_w(w^TX^TXw-w^TX^T\overrightarrow{y}-\overrightarrow{y}^TXw+\overrightarrow{y}^T\overrightarrow{y})\\<br>&amp;=\frac{1}{2}\nabla_wtr(w^TX^TXw-w^TX^T\overrightarrow{y}-\overrightarrow{y}^TXw+\overrightarrow{y}^T\overrightarrow{y}) \\<br>&amp;=\frac{1}{2}\nabla_w(trw^TX^TXw-2tr\overrightarrow{y}^TXw) \\<br>&amp;=\frac{1}{2}(X^TXw+X^TXw-2X^T\overrightarrow{y})\\<br>&amp;=X^TXw-X^T\overrightarrow{y}=X^T(Xw-\overrightarrow{y})\\\\<br>&amp;=&gt;J(w)=-f(w)=X^T(\overrightarrow{y}-Xw)<br>\end{split}<br>\end{equation}    \tag{11}<br>$$</p>
<p>说明：<br>第二步：类似于括号展开<br>第三步:实数的迹等于它本身<br>第四步:因为 $\overrightarrow{y}^T\overrightarrow{y}$ 不含w，因此它对w求导为0.并且利用了公式  $trA=trA^T$ 进行简化。<br>第五步:利用公式 $\nabla_{A^T}trABA^TC=B^TA^TC^T+BA^TC$ ,令 $A^T=w,B=B^T=X^TX,C=I$ ,利用公式转化即可得到。</p>
<p>最后再回到《机器学习实战》中，P78,代码清单5-1②的部分。<br>dataMatrix=X;<br>weights=w;<br>labelMat=y;<br>把等号右边的用左边的变量代入，不过很遗憾，还是有些区别的，在《机器学习实战》一书中，还有sigmoid这一函数，查阅了一些资料，发现其实还是有些区别的，将于下一篇博文中阐明。</p>
<h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><blockquote>
<p>吴恩达《机器学习》notes1<br>周志华《机器学习》chapter3 线性模型</p>
</blockquote>
<h5 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h5><blockquote>
<p><a href="http://csuncle.com/2017/06/13/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E3%80%8B-chapter5%E6%A2%AF%E5%BA%A6%E4%B8%8A%E5%8D%87%E7%AE%97%E6%B3%95-%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/">http://csuncle.com/2017/06/13/《机器学习实战》-chapter5梯度上升算法-数学推导/</a></p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://csuncle.com/2017/06/13/基于tensorflow的MNIST手写数字识别（三）-神经网络篇/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="William Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="会打代码的扫地王大爷">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/13/基于tensorflow的MNIST手写数字识别（三）-神经网络篇/" itemprop="url">基于tensorflow的MNIST手写数字识别（三）--神经网络篇</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-13T15:08:13+08:00">
                2017-06-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MachineLearning/" itemprop="url" rel="index">
                    <span itemprop="name">MachineLearning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="想想还是要说点什么"><a href="#想想还是要说点什么" class="headerlink" title="想想还是要说点什么"></a>想想还是要说点什么</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;抱歉啊，第三篇姗姗来迟，确实是因为我懒，而不是忙什么的，所以这次再加点料，以表示我的歉意。废话不多说，我就直接开始讲了。</p>
<h3 id="加入神经网络的意义"><a href="#加入神经网络的意义" class="headerlink" title="加入神经网络的意义"></a>加入神经网络的意义</h3><ul>
<li>&nbsp;&nbsp;&nbsp;&nbsp;前面也讲到了，使用普通的训练方法，也可以进行识别，但是识别的精度不够高，因此我们需要对其进行提升，其实MNIST官方提供了很多的组合方法以及测试精度，并做成了表格供我们选用，谷歌官方为了保证教学的简单性，所以用了最简单的卷积神经网络来提升这个的识别精度，原理是通过强化它的特征（比如轮廓等），其实我也刚学，所以能看懂就说明它确实比较简单。<ul>
<li>&nbsp;&nbsp;&nbsp;&nbsp;我的代码都是在0.7版本的tensorflow上实现的，建议看一下前两篇文章先。</li>
</ul>
</li>
</ul>
<h3 id="流程和步骤"><a href="#流程和步骤" class="headerlink" title="流程和步骤"></a>流程和步骤</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;其实流程跟前面的差不多,只是在softmax前进行了卷积神经网络的操作，所也就不仔细提出了，这里只说卷积神经网络的部分。<br>        如第一篇文章所说，我们的卷积神经网络的，过程是卷积-&gt;池化-&gt;全连接.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 卷积函数</span><br><span class="line"># convolution</span><br><span class="line">def conv2d(x, W):</span><br><span class="line">    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&apos;SAME&apos;)</span><br><span class="line">#这里tensorflow自己带了conv2d函数做卷积，然而我们自定义了个函数，用于指定步长为1，边缘处理为直接复制过来</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"># pooling</span><br><span class="line">def max_pool_2x2(x):</span><br><span class="line">    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&apos;SAME&apos;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None)</p>
</blockquote>
<blockquote>
<p>Computes a 2-D convolution given 4-D input and filter tensors.</p>
</blockquote>
<blockquote>
<p>Given an input tensor of shape [batch, in_height, in_width, in_channels] and a filter / kernel tensor of shape [filter_height, filter_width, in_channels, out_channels], this op performs the following:</p>
</blockquote>
<blockquote>
<p>Flattens the filter to a 2-D matrix with shape [filter_height <em> filter_width </em> in_channels, output_channels].</p>
</blockquote>
<p>Extracts image patches from the the input tensor to form a virtual tensor of shape [batch, out_height, out_width, filter_height <em> filter_width </em> in_channels].</p>
<blockquote>
</blockquote>
<p>For each patch, right-multiplies the filter matrix and the image patch vector.<br>In detail,</p>
<blockquote>
<p>output[b, i, j, k] =<br>    sum_{di, dj, q} input[b, strides[1] <em> i + di, strides[2] </em> j + dj, q] *<br>                    filter[di, dj, q, k]</p>
</blockquote>
<p>Must have strides[0] = strides[3] = 1. For the most common case of the same horizontal and vertices strides, strides = [1, stride, stride, 1].</p>
<blockquote>
<p>Args:</p>
</blockquote>
<blockquote>
<p>input: A Tensor. Must be one of the following types: float32, float64.</p>
</blockquote>
<blockquote>
<p>filter: A Tensor. Must have the same type as input.</p>
</blockquote>
<blockquote>
<p>strides: A list of ints. 1-D of length 4. The stride of the sliding window for each dimension of input.</p>
</blockquote>
<blockquote>
<p>padding: A string from: “SAME”, “VALID”. The type of padding algorithm to use.</p>
</blockquote>
<blockquote>
<p>use_cudnn_on_gpu: An optional bool. Defaults to True.</p>
</blockquote>
<blockquote>
<p>name: A name for the operation (optional).</p>
</blockquote>
<blockquote>
<p>Returns:</p>
</blockquote>
<blockquote>
<p>A Tensor. Has the same type as input.</p>
</blockquote>
<p>#### </p>
<blockquote>
<p>tf.nn.max_pool(value, ksize, strides, padding, name=None)</p>
</blockquote>
<blockquote>
<p>Performs the max pooling on the input.</p>
</blockquote>
<blockquote>
<p>Args:</p>
</blockquote>
<blockquote>
<p>value: A 4-D Tensor with shape [batch, height, width, channels] and type float32, float64, qint8, quint8, qint32.</p>
</blockquote>
<blockquote>
<p>ksize: A list of ints that has length &gt;= 4. The size of the window for each dimension of the input tensor.</p>
</blockquote>
<blockquote>
<p>strides: A list of ints that has length &gt;= 4. The stride of the sliding window for each dimension of the input tensor.</p>
</blockquote>
<blockquote>
<p>padding: A string, either ‘VALID’ or ‘SAME’. The padding algorithm.</p>
</blockquote>
<blockquote>
<p>name: Optional name for the operation.</p>
</blockquote>
<blockquote>
<p>Returns:</p>
</blockquote>
<blockquote>
<p>A Tensor with the same type as value. The max pooled output tensor.</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">初始化权重和偏置值矩阵，值是空的，需要后期训练。</span><br><span class="line"></span><br><span class="line">def weight_variable(shape):</span><br><span class="line">    initial = tf.truncated_normal(shape, stddev=0.1)</span><br><span class="line">    return tf.Variable(initial)</span><br><span class="line"></span><br><span class="line">def bias_variable(shape):</span><br><span class="line">    initial = tf.constant(0.1, shape = shape)</span><br><span class="line">    # print(tf.Variable(initial).eval())</span><br><span class="line">    return tf.Variable(initial)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#这是做了两次卷积和池化</span><br><span class="line">h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)</span><br><span class="line">h_pool1 = max_pool_2x2(h_conv1)</span><br><span class="line"></span><br><span class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2) + b_conv2)</span><br><span class="line">h_pool2 = max_pool_2x2(h_conv2)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">这里是做了全连接，还用了relu激活函数（RELU在下面会提到）</span><br><span class="line">h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])</span><br><span class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fc1) + b_fc1)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#为了防止过拟合化，这里用dropout来关闭一些连接（DROP下面会提到）</span><br><span class="line">h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</span><br></pre></td></tr></table></figure>
<p>然后得到的结果再跟之前的一样，使用softmax等方法训练即可得到参数。</p>
<h3 id="RELU激活函数"><a href="#RELU激活函数" class="headerlink" title="RELU激活函数"></a>RELU激活函数</h3><p>激活函数有很多种，最常用的是以下三种</p>
<h5 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h5><blockquote>
<p>将数据映射到0-1范围内</p>
<h4 id="公式如下"><a href="#公式如下" class="headerlink" title="公式如下"></a>公式如下</h4><p> <img src="/uploads/基于tensorflow的MNIST手写数字识别三/1.png" alt="这里写图片描述"></p>
<p> ####函数图像如下<br><img src="/uploads/基于tensorflow的MNIST手写数字识别三/2.png" alt="函数图像"></p>
</blockquote>
<h4 id="Tanh"><a href="#Tanh" class="headerlink" title="Tanh"></a>Tanh</h4><blockquote>
<p>将数据映射到-1-1的范围内</p>
<h4 id="公式如下-1"><a href="#公式如下-1" class="headerlink" title="公式如下"></a>公式如下</h4><p><img src="/uploads/基于tensorflow的MNIST手写数字识别三/3.png" alt="这里写图片描述"></p>
<p>函数图像如下<br><img src="/uploads/基于tensorflow的MNIST手写数字识别三/4.png" alt="这里写图片描述"></p>
</blockquote>
<h4 id="RELU"><a href="#RELU" class="headerlink" title="RELU"></a>RELU</h4><blockquote>
<p>小于0的值就变成0，大于0的等于它本身</p>
<h4 id="函数图像"><a href="#函数图像" class="headerlink" title="函数图像"></a>函数图像</h4><p><img src="/uploads/基于tensorflow的MNIST手写数字识别三/5.png" alt="这里写图片描述"></p>
</blockquote>
<p>具体的参考这个<a href="http://blog.csdn.net/u012526120/article/details/49149317" target="_blank" rel="noopener">http://blog.csdn.net/u012526120/article/details/49149317</a></p>
<p>###dropout的作用</p>
<blockquote>
<ul>
<li><p>以前学习数学我们常用到一种方法，叫做待定系数法，就是给定2次函数上的几个点，然后求得2次函数的参数。</p>
</li>
<li><p>一样的道理，我们这里用格式训练集训练，最后训练得到参数，其实就是在求得一个模型（函数），使得它能跟原始数据的曲线进行拟合（说白了，就是假装原始数据都在我们计算出来的函数上）</p>
</li>
<li><p>但是这样不行啊，因为我们还需要对未知数据进行预测啊，如果原始的数据点都在（或者大多数都在）函数上了（这就是过拟合），那会被很多训练数据误导的，所以其实只要一个大致的趋势函数就可以了</p>
</li>
<li><p>所以Dropout函数就是用来，减少某些点的全连接（可以理解为把一些点去掉了），来防止过拟合</p>
</li>
</ul>
</blockquote>
<p>具体的看这个<a href="http://www.cnblogs.com/tornadomeet/p/3258122.html" target="_blank" rel="noopener">http://www.cnblogs.com/tornadomeet/p/3258122.html</a></p>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><blockquote>
<ul>
<li>水完了，看代码吧，注释上有写一些变量的维度，大家可以一步步地看过去，计算过去</li>
<li><a href="https://github.com/wlmnzf/tensorflow-train/blob/master/mnist/cnn_mnist.py" target="_blank" rel="noopener">https://github.com/wlmnzf/tensorflow-train/blob/master/mnist/cnn_mnist.py</a></li>
</ul>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://csuncle.com/2017/06/13/基于tensorflow的MNIST手写数字识别（二）-入门篇/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="William Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="会打代码的扫地王大爷">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/13/基于tensorflow的MNIST手写数字识别（二）-入门篇/" itemprop="url">基于tensorflow的MNIST手写数字识别（二）--入门篇</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-13T15:07:32+08:00">
                2017-06-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MachineLearning/" itemprop="url" rel="index">
                    <span itemprop="name">MachineLearning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="一、本文的意义"><a href="#一、本文的意义" class="headerlink" title="一、本文的意义"></a>一、本文的意义</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;因为谷歌官方其实已经写了MNIST入门和深入两篇教程了，那我写这些文章又是为什么呢，只是抄袭？那倒并不是，更准确的说应该是笔记吧，然后用更通俗的语言来解释，并且补充更多，官方文章中没有详细展开的一些知识点，不过建议与官方文章结合着阅读。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;另外是代码部分的改动，官方的demo只提供了验证精确度，我将它改造成了能输入并预测输出结果的代码也就是说是一个从准备待测图片到最终是别的一个完整demo</p>
<blockquote>
<p>中文版本：MNIST机器学习入门<br><a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_beginners.html" target="_blank" rel="noopener">http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_beginners.html</a></p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;需要识别的图片放到test_num里，然后运行mnist_softmax.py就好了</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;demo截图如下，会将放进去的图片预测，然后输出结果，代码说明请看github的readme（最底下）</p>
<p><img src="/uploads/基于tensorflow的MNIST手写字识别二/1.png" alt="这里写图片描述"></p>
<h4 id="二、MNIST简介"><a href="#二、MNIST简介" class="headerlink" title="二、MNIST简介"></a>二、MNIST简介</h4><blockquote>
<p>官网：<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">http://yann.lecun.com/exdb/mnist/</a></p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这个MNIST数据库是一个手写数字的数据库，它提供了六万的训练集和一万的测试集。<br>它的图片是被规范处理过的，是一张被放在中间部位的28px*28px的灰度图</p>
<blockquote>
<p>总共4个文件:\<br>train-images-idx3-ubyte: training set images \<br>train-labels-idx1-ubyte: training set labels \<br>t10k-images-idx3-ubyte:  test set images \<br>t10k-labels-idx1-ubyte:  test set labels\</p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;图片都被转成二进制放到了文件里面，<br>所以，每一个文件头部几个字节都记录着这些图片的信息，然后才是储存的图片信息</p>
<blockquote>
<p>TRAINING SET LABEL FILE (train-labels-idx1-ubyte):</p>
</blockquote>
<figure class="highlight plain"><figcaption><span>[type]          [value]         [description] </span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">0000     32 bit integer  0x00000801(2049) magic number (MSB first) </span><br><span class="line">0004     32 bit integer  60000            number of items </span><br><span class="line">0008     unsigned byte   ??               label </span><br><span class="line">0009     unsigned byte   ??               label </span><br><span class="line">........ </span><br><span class="line">xxxx     unsigned byte   ??               label</span><br></pre></td></tr></table></figure>
<p>The labels values are 0 to 9.</p>
<blockquote>
<p>TRAINING SET IMAGE FILE (train-images-idx3-ubyte):</p>
</blockquote>
<figure class="highlight plain"><figcaption><span>[type]          [value]          [description] </span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0000     32 bit integer  0x00000803(2051) magic number </span><br><span class="line">0004     32 bit integer  60000            number of images </span><br><span class="line">0008     32 bit integer  28               number of rows </span><br><span class="line">0012     32 bit integer  28               number of columns </span><br><span class="line">0016     unsigned byte   ??               pixel </span><br><span class="line">0017     unsigned byte   ??               pixel </span><br><span class="line">........ </span><br><span class="line">xxxx     unsigned byte   ??               pixel</span><br></pre></td></tr></table></figure>
<p>每个像素被转成了0-255,0代表着白色，255代表着黑色。</p>
<blockquote>
<p>TEST SET LABEL FILE (t10k-labels-idx1-ubyte):</p>
</blockquote>
<figure class="highlight plain"><figcaption><span>[type]          [value]          [description] </span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">0000     32 bit integer  0x00000801(2049) magic number (MSB first) </span><br><span class="line">0004     32 bit integer  10000            number of items </span><br><span class="line">0008     unsigned byte   ??               label </span><br><span class="line">0009     unsigned byte   ??               label </span><br><span class="line">........ </span><br><span class="line">xxxx     unsigned byte   ??               label</span><br></pre></td></tr></table></figure>
<p>The labels values are 0 to 9.</p>
<blockquote>
<p>TEST SET IMAGE FILE (t10k-images-idx3-ubyte):</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[offset] [type]          [value]          [description] </span><br><span class="line">0000     32 bit integer  0x00000803(2051) magic number </span><br><span class="line">0004     32 bit integer  10000            number of images </span><br><span class="line">0008     32 bit integer  28               number of rows </span><br><span class="line">0012     32 bit integer  28               number of columns </span><br><span class="line">0016     unsigned byte   ??               pixel </span><br><span class="line">0017     unsigned byte   ??               pixel </span><br><span class="line">........ </span><br><span class="line">xxxx     unsigned byte   ??               pixel</span><br></pre></td></tr></table></figure>
<p>每个像素被转成了0-255,0代表着白色，255代表着黑色。</p>
<h4 id="三、tensorflow手写数字识别的大致步骤"><a href="#三、tensorflow手写数字识别的大致步骤" class="headerlink" title="三、tensorflow手写数字识别的大致步骤"></a>三、tensorflow手写数字识别的大致步骤</h4><ol>
<li>将要识别的图片转为灰度图，并且转化为28*28矩阵（单通道，每个像素范围0-255，0为黑色，255为白色，这一点与MNIST中的正好相反）</li>
<li>将28*28的矩阵转换成1维矩阵（也就是把第2,3,4,5….行矩阵纷纷接入到第一行的后面）</li>
<li>用一个1*10的向量代表标签，也就是这个数字到底是几，举个例子e数字1对应的矩阵就是[0,1,0,0,0,0,0,0,0,0]</li>
<li>softmax回归预测图片是哪个数字的概率</li>
<li>用交叉熵和梯度下降法训练参数</li>
</ol>
<h4 id="四、过程讲解"><a href="#四、过程讲解" class="headerlink" title="四、过程讲解"></a>四、过程讲解</h4><h5 id="4-1-准备要识别的图片"><a href="#4-1-准备要识别的图片" class="headerlink" title="4.1 准备要识别的图片"></a>4.1 准备要识别的图片</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;这个部分其实是比较重要的，因为如果处理不得当可能并不一定会有很好的结果，所以按照mnist的标准规范需要将待测图片转为28×28且文字居中的灰度图（其实彩色的也可以，不过就是最后代码需要改一下），目前介绍两种获得待测图片的方法：</p>
<ol>
<li>自己用ps或者真的手写一些数字</li>
<li>将MNIST数据库中的二进制转化成图片，然后用来做测试<pre><code>ps:图片解析  点击进入
</code></pre></li>
</ol>
<h5 id="4-2-将待测图片转换为矩阵"><a href="#4-2-将待测图片转换为矩阵" class="headerlink" title="4.2 将待测图片转换为矩阵"></a>4.2 将待测图片转换为矩阵</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;如图所示，根据黑色部分的浓淡将其转化成微一个浮点数的数组，（白色0,黑色1）</p>
<p><img src="/uploads/基于tensorflow的MNIST手写字识别二/2.png" alt=""></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;看到这里，如果你跟我一样不熟悉python，是不是开始方了，没事，其实python很厉害，自带的PIL图片库一句话就可以搞定</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img=array(Image.open(filename))         //打开然后就被numpy转化了</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;如果是彩色的图片，则需要先将它这样子转换一下（我当初并不知道可以转化，傻不垃圾地自己写了一个转化，所以python还是好好学习啊）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Lim  = img=array(im.convert(&quot;L&quot;))</span><br></pre></td></tr></table></figure></p>
<h5 id="4-3将矩阵转化为一维矩阵-以及标签的介绍"><a href="#4-3将矩阵转化为一维矩阵-以及标签的介绍" class="headerlink" title="4.3将矩阵转化为一维矩阵,以及标签的介绍"></a>4.3将矩阵转化为一维矩阵,以及标签的介绍</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;转化为一维的矩阵其实并不难，用python的reshape就能搞定，还是要讲一下标签的表示方法，这个曾经令队友疑惑不久，直到我把这个数组打印出来</p>
<h5 id="4-3-1标签的来历–有监督学习-和-无监督学习"><a href="#4-3-1标签的来历–有监督学习-和-无监督学习" class="headerlink" title="4.3.1标签的来历–有监督学习 和 无监督学习"></a>4.3.1标签的来历–有监督学习 和 无监督学习</h5><blockquote>
<p>监督学习：利用一组已知类别的样本调整分类器的参数，使其达到所要求性能的过程，也称为监督训练或有教师学习</p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp; 举个例子，MNIST自带了训练图片和训练标签，每张图片都有一个对应的标签，比如这张图片是1，标签也就是1,用他们训练程序，之后程序也就能识别测试集中的图片了，比如给定一张2的图片，它能预测出他是2</p>
<blockquote>
<p>无监督学习：其中很重要的一类叫聚类</p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp; 举个例子，如果MNIST中只有训练图片，没有标签，我们的程序能够根据图片的不同特征，将他们分类，但是并不知道他们具体是几，这个其实就是“聚类”</p>
<h6 id="4-3-2-标签的表示"><a href="#4-3-2-标签的表示" class="headerlink" title="4.3.2 标签的表示"></a>4.3.2 标签的表示</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;在这里标签的表示方式有些特殊，它也是使用了一个一维数组，而不是单纯的数字，上面也说了，他是一个一位数组，0表示方法[1,0,0,0,0,0,0,0,0,0],1表示[0,1,0,0,0,0,0,0,0,0],………， 主要原因其实是这样的，因为softmax回归处理后会生成一个1*10的数组，数组[0,0]的数字表示预测的这张图片是0的概率，[0,1]则表示这张图片表示是1的概率……以此类推，这个数组表示的就是这张图片是哪个数字的概率（已经归一化），因此，实际上，概率最大的那个数字就是我们所预测的值。两者对应来看，标准的标签就是表示图片对应数字的概率为100%，而表示其它数字的概率为0，举个例子，0表示[1,0,0,0,0,0,0,0,0,0]，可以理解为它表示0的概率为1，而表示别的数字的概率为0.</p>
<h4 id="4-4-softmax回归"><a href="#4-4-softmax回归" class="headerlink" title="4.4 softmax回归"></a>4.4 softmax回归</h4><p> &nbsp;&nbsp;&nbsp;&nbsp;这是一个分类器，可以认为是Logistic回归的扩展，Logistic大家应该都听说过，就是生物学上的S型曲线，它只能分两类，用0和1表示，这个用来表示答题对错之类只有两种状态的问题时足够了，但是像这里的MNIST要把它分成10类，就必须用softmax来进行分类了。  </p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;P(y=0)=p0,P(y=1)=p1,p(y=2)=p2……P(y=9)=p9.这些表示预测为数字i的概率，（跟上面标签的格式正好对应起来了）,它们的和为1，即 ∑(pi)=1。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp; tensorflow实现了这个函数，我们直接调用这个softmax函数即可，对于原理，可以参考下面的引文，这里只说一下我们这个MNIST demo要用softmax做什么。</p>
<p>  （注：每一个神经元都可以接收来自网络中其他神经元的一个或多个输入信号，神经元与神经元之间都对应着连接权值，所有的输入加权和决定该神经元是处于激活还是抑制状态。感知器网络的输出只能取值0或1，不具备可导性。而基于敏感度的训练算法要求其输出函数必须处处可导，于是引入了常见的S型可导函数，即在每个神经元的输出之前先经过S型激活函数的处理。）</p>
<h4 id="4-5-交叉熵"><a href="#4-5-交叉熵" class="headerlink" title="4.5 交叉熵"></a>4.5 交叉熵</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;通俗一点就是，方差大家都知道吧，用它可以衡量预测值和实际值的相差程度，交叉熵其实也是一样的作用，那为什么不用方差呢，因为看sigmoid函数的图像就会发现，它的两侧几乎就是平的，导致它的方差在大部分情况下很小，这样在训练参数的时候收敛地就会很慢，交叉熵就是用来解决这个问题的，它的公式是 <img src="/uploads/基于tensorflow的MNIST手写字识别二/3.png" alt="">,其中，y 是我们预测的概率分布, y’ 是实际的分布。</p>
<h4 id="4-6-梯度下降"><a href="#4-6-梯度下降" class="headerlink" title="4.6 梯度下降"></a>4.6 梯度下降</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;上面那步也说了，有个交叉熵，根据大伙对方差的理解，值越小，自然就越好，因此我们也要训练使得交叉熵最小的参数，这里梯度下降法就派上用场了，这个解释见上一篇系列文章吧，什么叫训练参数呢，可以想象一下，我们先用实际的值在二位坐标上画一条线，然后我们希望我们预测出来的那些值要尽可能地贴近这条线，我们假设生成我们这条线的公式ax+ax^2+bx^3+…..，我们需要生成这些系数，要求得这些系数，我们就需要各种点代入，然后才能求出，所以其实训练参数跟求参数是个类似的过程。</p>
<h4 id="4-7-预测"><a href="#4-7-预测" class="headerlink" title="4.7 预测"></a>4.7 预测</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;训练结束以后我们就可以用这个模型去预测新的图片了，就像我们已经求出来了方程，以后只要随意输入一个x，就能求出对应的y。</p>
<h4 id="5-代码"><a href="#5-代码" class="headerlink" title="5 代码"></a>5 代码</h4><p><a href="https://github.com/wlmnzf/tensorflow-train/tree/master/mnist" target="_blank" rel="noopener">https://github.com/wlmnzf/tensorflow-train/tree/master/mnist</a></p>
<h3 id="6-参考文章"><a href="#6-参考文章" class="headerlink" title="6 参考文章"></a>6 参考文章</h3><p><span style="font-family:Microsoft YaHei;font-size:18px;"><a href="http://blog.csdn.net/acdreamers/article/details/44663305" target="_blank" rel="noopener">http://blog.csdn.net/acdreamers/article/details/44663305</a>   softmax回归</span></p>
<p><span style="font-family:Microsoft YaHei;font-size:18px;"><a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_beginners.html" target="_blank" rel="noopener">http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_beginners.html</a>    MNIST学习入门<br></span></p>
<p><span style="font-family:Microsoft YaHei;font-size:18px;"><a href="http://blog.csdn.net/u012162613/article/details/44239919" target="_blank" rel="noopener">http://blog.csdn.net/u012162613/article/details/44239919</a>   交叉熵代价函数</span></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://csuncle.com/2017/06/13/基于tensorflow的MNIST手写字识别（一）-白话卷积神经网络模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="William Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="会打代码的扫地王大爷">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/13/基于tensorflow的MNIST手写字识别（一）-白话卷积神经网络模型/" itemprop="url">基于tensorflow的MNIST手写字识别（一）--白话卷积神经网络模型</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-13T15:06:36+08:00">
                2017-06-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MachineLearning/" itemprop="url" rel="index">
                    <span itemprop="name">MachineLearning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="一、卷积神经网络模型知识要点卷积卷积"><a href="#一、卷积神经网络模型知识要点卷积卷积" class="headerlink" title="一、卷积神经网络模型知识要点卷积卷积"></a>一、卷积神经网络模型知识要点卷积卷积</h4><ol>
<li>卷积</li>
<li>池化</li>
<li>全连接</li>
<li>梯度下降法</li>
<li>softmax</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;本次就是用最简单的方法给大家讲解这些概念，因为具体的各种论文网上都有，连推导都有，所以本文主要就是给大家做个铺垫，如有错误请指正，相互学习共同进步。</p>
<h4 id="二、卷积神经网络讲解"><a href="#二、卷积神经网络讲解" class="headerlink" title="二、卷积神经网络讲解"></a>二、卷积神经网络讲解</h4><pre><code>##### 2.1卷积神经网络作用
</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp; 大家应该知道大名鼎鼎的傅里叶变换，即一个波形，可以有不同的正弦函数和余弦函数进行叠加完成，卷积神经网络也是一样，可以认为一张图片是由各种不同特征的图片叠加而成的，所以它的作用是用来提取特定的特征，举个例子，比如给定一张图片，然后我只想提取它的轮廓，于是就需要卷积神经网络。</p>
<p><img src="/uploads/基于tensorflow的MNIST手写字识别一/1.png" alt=""></p>
<h5 id="2-2卷积神经网络模型"><a href="#2-2卷积神经网络模型" class="headerlink" title="2.2卷积神经网络模型"></a>2.2卷积神经网络模型</h5><p><img src="/uploads/基于tensorflow的MNIST手写字识别一/2.jpg" alt="">          </p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;如图是大名鼎鼎的LeNet-5（识别数字的卷积网络），效果和论文在此，这里拿出来只是为了说明一下卷积神经网络的模型，就像图中那样，经过多次，卷积，池化（又叫子采样），然后全连接，就完工了。</p>
<h4 id="2-3-卷积"><a href="#2-3-卷积" class="headerlink" title="2.3 卷积"></a>2.3 卷积</h4><p><img src="/uploads/基于tensorflow的MNIST手写字识别一/3.gif" alt=""></p>
<h5 id="2-3-1-卷积的原理"><a href="#2-3-1-卷积的原理" class="headerlink" title="2.3.1 卷积的原理"></a>2.3.1 卷积的原理</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;其实卷积很好理解，左侧绿色的部分的5<em>5矩阵其实一般就是我们输入的图片的灰度值（可以想象成一张5px</em>5px的黑白照片，然后把黑白照片上的每一个点转化成矩阵上的每一个元素），然后上面的黄色部分矩阵就是我们的过滤器，用来提取特征，（其实应该叫滤波器或者卷积核），让卷积核在输入矩阵上进行从左到右，从上到下滑动，然后每一次滑动，两个矩阵对应位置的元素相乘然后求和，就是右边那个矩阵的一个元素。</p>
<h5 id="2-3-2-滑动的步长-stride"><a href="#2-3-2-滑动的步长-stride" class="headerlink" title="2.3.2 滑动的步长-stride"></a>2.3.2 滑动的步长-stride</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;上面那张图片从左到右，每次滑动的时候只移动一格，但是其实它一次滑动多格，这就是步长</p>
<h5 id="2-3-3-卷积的边界处理-padding"><a href="#2-3-3-卷积的边界处理-padding" class="headerlink" title="2.3.3 卷积的边界处理-padding"></a>2.3.3 卷积的边界处理-padding</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，卷积后的矩阵只有3*3，比原来的图片要小了，因为边界没有了，所以要考虑这个边界的问题，网上说卷积的边界处理有两种方式：</p>
<ol>
<li>丢掉边界，也就是就按右边那个缩小的矩阵来。</li>
<li>复制边界，也就是把左边的最外层原封不动地复制过去</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;但是在看matlab代码和tensorflow代码的时候发现并不是那么简单的事情。</p>
<p>matlab中conv2这个“padding”参数可以设为三个值FULL，SAME，VALID</p>
<p>tensorflow中conv2d的”padding”参数可以设为两个值SAME，VALID</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;它们对边界是这样处理的，对输入的矩阵，包裹n层0，然后再按照上面所说的卷积方法进行卷积，这个n怎么求呢，</p>
<blockquote>
<p>FULL: edge_row = kernel_row - 1;   edge_cols = kernel_cols - 1; </p>
</blockquote>
<blockquote>
<p>SAME: edge_row = (kernel_row - 1) / 2;   edge_cols = (kernel_cols - 1) / 2; </p>
</blockquote>
<blockquote>
<p>VALID:edge_row = edge_cols = 0;  </p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;edge_row就是边的行数，kernel_row就是卷积核的行数，所以上面讲的其实就是VALID模式</p>
<h5 id="2-3-4-卷积与神经网络"><a href="#2-3-4-卷积与神经网络" class="headerlink" title="2.3.4 卷积与神经网络"></a>2.3.4 卷积与神经网络</h5><p><img src="/uploads/基于tensorflow的MNIST手写字识别一/4.png" alt=""></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;右下角就是卷积的数学公式，矩阵的对应元素相乘求和，然后加上一个偏置值</p>
<h4 id="2-4-池化"><a href="#2-4-池化" class="headerlink" title="2.4 池化"></a>2.4 池化</h4><p><img src="/uploads/基于tensorflow的MNIST手写字识别一/5.gif" alt=""></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;池化分为两种，一种是最大池化，在选中区域中找最大的值作为抽样后的值，另一种是平均值池化，把选中的区域中的平均值作为抽样后的值，这样做的，原因是为了后面全连接的时候减少连接数</p>
<h4 id="2-5-全连接"><a href="#2-5-全连接" class="headerlink" title="2.5 全连接"></a>2.5 全连接</h4><p><img src="/uploads/基于tensorflow的MNIST手写字识别一/6.png" alt=""></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;左边的是没有没有进行卷积的全连接，假设图片是1000<em>1000的，然后用1M的神经元去感知，最后需要10^12个权值作为参数，右边是经过卷积过的，每个圆点是一个神经元，因此只是用一个卷积核的话，其实只要100</em>10^6，数量级就大大减少，而且因为提取的就是所需的特征，所以在加快训练速度的时候对结果并不会产生过大的影响，甚至更为精确。</p>
<h4 id="2-6-梯度下降法"><a href="#2-6-梯度下降法" class="headerlink" title="2.6 梯度下降法"></a>2.6 梯度下降法</h4><p><img src="/uploads/基于tensorflow的MNIST手写字识别一/7.png" alt=""><br>&nbsp;&nbsp;&nbsp;&nbsp;可能很多人会问，那个卷积核是怎么得出来的呢，其实它是被各种训练集训练出来的，利用梯度下降法使得我们的参数到达最优解。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;梯度下降法可以这样子理解，假设我们正在下山，要使得下山的路径达到最短，于是我们每走一步之前就判断一下四面八方从哪个方向跨出这一步会最短，不过学过算法的人应该都知道，有个问题就是，我们当前走的这一步是当前位置最短的，但是真正从山上到山下最短路径可能并不路过这一步。也就是说这是个局部最优解，而不是全局最优解，我们得到的路径并不一定是最短的，但是也足够优秀，原因就是，得到最优解费时费力，性价比并不高。这一个知识点还是建议大家伙去看一下斯坦福Andrew Ng的《机器学习》，然后就能理解上面所说的权值参数要少的意义了。</p>
<h4 id="2-7最后-softmax"><a href="#2-7最后-softmax" class="headerlink" title="2.7最后 softmax"></a>2.7最后 softmax</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;softmax是分类用的，说直白一点就是归一化，因为这个店最好跟例子结合起来，所以暂时不多说，感兴趣的可以去网上找，也可以关注后面的系列文章。</p>
<h4 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;其实感觉讲的并不深入，因此还是希望各位能自己去仔细钻研一下，这里给各位一些基础吧，读起论文和数学公式来会更轻松一些。</p>
<h4 id="四、参考"><a href="#四、参考" class="headerlink" title="四、参考"></a>四、参考</h4><blockquote>
<p>神经网络介绍<br><a href="http://ufldl.stanford.edu/wiki/index.php/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" target="_blank" rel="noopener">http://ufldl.stanford.edu/wiki/index.php/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C</a></p>
</blockquote>
<blockquote>
<p>技术向：一文读懂卷积神经网络CNN<br><a href="http://www.cnblogs.com/nsnow/p/4562308.html" target="_blank" rel="noopener">http://www.cnblogs.com/nsnow/p/4562308.html</a></p>
</blockquote>
<blockquote>
<p>深度学习（卷积神经网络）一些问题总结<br><a href="http://blog.csdn.net/nan355655600/article/details/17690029" target="_blank" rel="noopener">http://blog.csdn.net/nan355655600/article/details/17690029</a></p>
</blockquote>
<blockquote>
<p>卷积神经网络（CNN）<br><a href="http://ibillxia.github.io/blog/2013/04/06/Convolutional-Neural-Networks/" target="_blank" rel="noopener">http://ibillxia.github.io/blog/2013/04/06/Convolutional-Neural-Networks/</a></p>
</blockquote>
<blockquote>
<p>Deep Learning模型之：CNN卷积神经网络（一）深度解析CNN<br><a href="http://www.cnblogs.com/nsnow/p/4562363.html" target="_blank" rel="noopener">http://www.cnblogs.com/nsnow/p/4562363.html</a></p>
</blockquote>
<blockquote>
<p>数据挖掘系列（10）——卷积神经网络算法的一个实现(转)<br><a href="http://blog.sina.com.cn/s/blog_4ff49c7e0102vl5m.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_4ff49c7e0102vl5m.html</a></p>
</blockquote>
<blockquote>
<p>Matlab/DeepLearnToolbox<br><a href="https://github.com/rasmusbergpalm/DeepLearnToolbox" target="_blank" rel="noopener">https://github.com/rasmusbergpalm/DeepLearnToolbox</a></p>
</blockquote>
<blockquote>
<p>Deep Learning论文笔记之（四）CNN卷积神经网络推导和实现<br><a href="http://blog.csdn.net/zouxy09/article/details/9993371" target="_blank" rel="noopener">http://blog.csdn.net/zouxy09/article/details/9993371</a></p>
</blockquote>
<blockquote>
<p>Deep Learning论文笔记之（五）CNN卷积神经网络代码理解<br><a href="http://blog.csdn.net/zouxy09/article/details/9993743" target="_blank" rel="noopener">http://blog.csdn.net/zouxy09/article/details/9993743</a></p>
</blockquote>
<blockquote>
<p>斯坦福  池化<br><a href="http://ufldl.stanford.edu/wiki/index.php/%E6%B1%A0%E5%8C%96" target="_blank" rel="noopener">http://ufldl.stanford.edu/wiki/index.php/%E6%B1%A0%E5%8C%96</a></p>
</blockquote>
<blockquote>
<p>CNN神经网络层次分析<br><a href="http://blog.csdn.net/liulina603/article/details/44915905" target="_blank" rel="noopener">http://blog.csdn.net/liulina603/article/details/44915905</a></p>
</blockquote>
<blockquote>
<p>深度学习笔记1(卷积神经网络)<br><a href="http://blog.csdn.net/lu597203933/article/details/46575779" target="_blank" rel="noopener">http://blog.csdn.net/lu597203933/article/details/46575779</a></p>
</blockquote>
<blockquote>
<p>CNN公式推导<br><a href="http://blog.csdn.net/lu597203933/article/details/46575871" target="_blank" rel="noopener">http://blog.csdn.net/lu597203933/article/details/46575871</a></p>
</blockquote>
<blockquote>
<p>前向型神经网络之BPNN(附源码)<br><a href="http://blog.csdn.net/heyongluoyao8/article/details/48213345" target="_blank" rel="noopener">http://blog.csdn.net/heyongluoyao8/article/details/48213345</a></p>
</blockquote>
<blockquote>
<p>残差与误差的区别<br><a href="http://wenku.baidu.com/link?url=DUDkyV1tnD_SEGzgcxb9AaFU5VUcP9ISNR8q39-fpCcq_LGUHY7ucx5vDwr-MCfU_ofr7yIQZ_UgTfiivTtaDOulW2DD3pGs07eYmiQv5P7" target="_blank" rel="noopener">http://wenku.baidu.com/link?url=DUDkyV1tnD_SEGzgcxb9AaFU5VUcP9ISNR8q39-fpCcq_LGUHY7ucx5vDwr-MCfU_ofr7yIQZ_UgTfiivTtaDOulW2DD3pGs07eYmiQv5P7</a></p>
</blockquote>
<blockquote>
<p>反向传导算法<br><a href="http://deeplearning.stanford.edu/wiki/index.php/%E5%8F%8D%E5%90%91%E4%BC%A0%E5%AF%BC%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">http://deeplearning.stanford.edu/wiki/index.php/%E5%8F%8D%E5%90%91%E4%BC%A0%E5%AF%BC%E7%AE%97%E6%B3%95</a></p>
</blockquote>
<blockquote>
<p>图像卷积与滤波的一些知识点<br><a href="http://blog.csdn.net/zouxy09/article/details/49080029" target="_blank" rel="noopener">http://blog.csdn.net/zouxy09/article/details/49080029</a></p>
</blockquote>
<blockquote>
<p>CNN卷积神经网络原理简介+代码详解<br><a href="http://doc.okbase.net/u012162613/archive/126058.html" target="_blank" rel="noopener">http://doc.okbase.net/u012162613/archive/126058.html</a></p>
</blockquote>
<blockquote>
<p>卷积神经网络（lenet）<br><a href="http://deeplearning.net/tutorial/lenet.html" target="_blank" rel="noopener">http://deeplearning.net/tutorial/lenet.html</a></p>
</blockquote>
<blockquote>
<p>激活函数的作用<br><a href="https://www.zhihu.com/question/22334626" target="_blank" rel="noopener">https://www.zhihu.com/question/22334626</a></p>
</blockquote>
<blockquote>
<p>神经网络入门第一部分<br><a href="http://blog.sina.com.cn/s/blog_6a67b5c50100tspb.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_6a67b5c50100tspb.html</a></p>
</blockquote>
<blockquote>
<p>神经网络入门第二部分<br><a href="http://blog.sina.com.cn/s/blog_6a67b5c50100tspe.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_6a67b5c50100tspe.html</a></p>
</blockquote>
<blockquote>
<p>卷积神经网络全面解析<br><a href="http://www.moonshile.com/post/juan-ji-shen-jing-wang-luo-quan-mian-jie-xi" target="_blank" rel="noopener">http://www.moonshile.com/post/juan-ji-shen-jing-wang-luo-quan-mian-jie-xi</a></p>
</blockquote>
<blockquote>
<p>Deep learning：四十一(Dropout简单理解)<br><a href="http://www.cnblogs.com/tornadomeet/p/3258122.html" target="_blank" rel="noopener">http://www.cnblogs.com/tornadomeet/p/3258122.html</a></p>
</blockquote>
<blockquote>
<p>DeepLearning (六) 学习笔记整理：神经网络以及卷积神经网络<br><a href="http://www.07net01.com/2015/11/963741.html" target="_blank" rel="noopener">http://www.07net01.com/2015/11/963741.html</a></p>
</blockquote>
<blockquote>
<p>深度卷积网络CNN与图像语义分割<br><a href="http://blog.csdn.net/xiahouzuoxin/article/details/47789361" target="_blank" rel="noopener">http://blog.csdn.net/xiahouzuoxin/article/details/47789361</a></p>
</blockquote>
<blockquote>
<p>MATLAB conv2卷积的实现<br><a href="http://blog.csdn.net/celerychen2009/article/details/38852105" target="_blank" rel="noopener">http://blog.csdn.net/celerychen2009/article/details/38852105</a><br></p>
</blockquote>
<div style="color:white"><br><span>William</span><br><span>会打代码的扫地王大爷</span><br><span>wlmnzf</span><br><span>中科院信工所</span><br><span>IIE</span><br><span>CAS</span><br><span>csuncle</span><br><span>丁洁的男朋友</span><br><span>丁洁的人</span><br><span>王立敏</span><br></div>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/avatar.png"
               alt="William Wang" />
          <p class="site-author-name" itemprop="name">William Wang</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">13</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">24</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/wlmnzf" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/wlmnzf" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/1505236542" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.linkedin.com/in/wlmnzf" target="_blank" title="Linkedin">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  Linkedin
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://note.junyangz.com" title="Junyangz" target="_blank">Junyangz</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">William Wang</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

 <span>Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a></span>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.1"></script>



  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






   
   
   
   
   <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
   <script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
   
       <script type="text/javascript">
           function ShowGitment(){
               document.getElementById("gitment-display-button").style.display = "none";
               document.getElementById("gitment-container").style.display = "block";
               var gitment = new Gitment({
                   id: '', 
                   owner: 'wlmnzf',
                   repo: 'wlmnzf.github.io',
                   oauth: {
                       client_id: 'a8bc66fc03c165358b9b',
                       client_secret: '21860ee458dee914048f630f9f1a23ff3fc2f96b',
                   }});
               gitment.render('gitment-container');
           }
       </script>
   


  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
