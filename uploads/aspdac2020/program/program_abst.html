<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1">
<html>
<head>
<title>ASP-DAC 2020 Technical Program</title>
<style>
<!--
.tbl1 { border-collapse: collapse; background-color: #ffffcf; }
.tbl2, .tbl3 { border-collapse: collapse; }
.tbl1 th, .tbl1 td, .tbl2 th, .tbl2 td { border: 1px solid gray; padding: 2px; min-width: 2em; }
.tbl3 th, .tbl3 td { border: 0; padding: 1px; min-width: 2em; }
@media all and (-ms-high-contrast:none){ /* on or after IE10 */
 .tbl1 th, .tbl1 td, .tbl2 th, .tbl2 td { padding: 4px; line-height: 120%; }
 .tbl3 th, .tbl3 td { padding: 4px; line-height: 120%; }
 table { margin: 2px; }
}
input.button_submit {
 font-size: 20pt;
 color: white;
 font-weight: bold;
 background-color: #4E9AE6;
 box-shadow: 5px 5px 5px #999;
}
input.button_submit:hover {
 background-color: #185fa7
}
input.button_check {
 font-size: 20pt;
 color: white;
 font-weight: bold;
 background-color: #CC99FF;
 box-shadow: 5px 5px 5px #999;
}
input.button_check:hover {
 background-color: #a54bff
}
td.button_submit_small {
 font-size: 12pt;
 color: white;
 font-weight: bold;
 background-color: #4E9AE6;
 box-shadow: 5px 5px 5px #999;
 border-collapse: separate; /* IE, Edge */                                      
}
td.button_submit_small:hover {
 background-color: #185fa7
}
td.button_check_small {
 font-size: 12pt;
 color: white;
 font-weight: bold;
 background-color: #CC99FF;
 box-shadow: 5px 5px 5px #999;
 border-collapse: separate; /* IE, Edge */                                      
}
td.button_check_small:hover {
 background-color: #a54bff
}
@supports (-ms-ime-align:auto) { /* Edge */
}
@-moz-document url-prefix(){ /* Firefox */
}
body { margin: 20px; padding: 0; }
pre{
 white-space: -moz-pre-wrap;
 white-space: -pre-wrap;
 white-space: -o-pre-wrap;
 white-space: pre-wrap;
}
-->
</style>
</head>
<body>
<a href="../index.html" target="_top">(Go to Top Page)</a>
<center>
<h1>The 25th Asia and South Pacific Design Automation Conference <br>Technical Program</h1>
</center>
<font color="red">Remark:</font> The presenter of each paper is marked with "<b><font color="Maroon" size=+1>*</font></b>".
<hr>
<b><font color="#800000">Technical Program:&nbsp;&nbsp;&nbsp;<a href="program.html">SIMPLE version</a>&nbsp;&nbsp;&nbsp;DETAILED version with abstract</font></b>
<hr>
<b><font color="#800000">Author Index:&nbsp;&nbsp;&nbsp;<a href="author_index_abst.html">HERE</a></font></b>
<hr>
<center><h2><font color="red">Session Schedule</font></h2></center>
<a name="day1"></a>
<table border="2" cellspacing="0" cellpadding="5" bgcolor=#dddddd><tr><td>Tuesday, January 14, 2020</table>
<br>
<table class="tbl2" border="1" cellspacing="0" cellpadding="5" bgcolor="#ffffe9">
<tr>
<th width="25.0%" bgcolor="#fff6b1">Room 310</th><th width="25.0%" bgcolor="#fff6b1">Room 308</th><th width="25.0%" bgcolor="#fff6b1">Room 307A</th><th width="25.0%" bgcolor="#fff6b1">Room 307B</th></tr>
<tr>
<td colspan=4 valign=top><center><a href="#1K">1K&nbsp; (Room 311)<br>
Opening and Keynote Session I</a><br>9:00 - 10:30</center></td>
</tr>
<tr>
<td><center><a href="#1A">1A&nbsp; University Design Contest</a><br>10:45 - 12:00</center></td>
<td><center><a href="#1B">1B&nbsp; Machine Learning in Physical Design</a><br>10:45 - 12:00</center></td>
<td><center><a href="#1C">1C&nbsp; Toward Optimal Timing and PDN Design</a><br>10:45 - 12:00</center></td>
<td><center><a href="#1D">1D&nbsp; Side Channel Attacks and Countermeasures</a><br>10:45 - 12:00</center></td>
</tr>
<tr>
<td colspan=4 valign=top><center><a href="#2K">2K&nbsp; (Room 311)<br>
Keynote Session II</a><br>12:00 - 12:40</center></td>
</tr>
<tr>
<td colspan=4>
<center><b>Lunch Break</b><br>
12:40 - 14:00
</center>
</td>
</tr>
<tr>
<td><center><a href="#2A">2A&nbsp; (SS-1): Designing Reliable and Robust Circuits and Systems in the Nanometer Era</a><br>14:00 - 15:40</center></td>
<td><center><a href="#2B">2B&nbsp; System Architecture Innovation</a><br>14:00 - 15:40</center></td>
<td><center><a href="#2C">2C&nbsp; Optical Networks-on-Chips and Quantum Circuit Design</a><br>14:00 - 15:40</center></td>
<td><center><a href="#2D">2D&nbsp; Reliability from Design to Manufacturing</a><br>14:00 - 15:40</center></td>
</tr>
<tr>
<td colspan=4>
<center><b>Coffee Break</b><br>
15:40 - 16:00
</center>
</td>
</tr>
<tr>
<td><center><a href="#3A">3A&nbsp; Reliability and Security for Deep Neural Networks</a><br>16:00 - 17:15</center></td>
<td><center><a href="#3B">3B&nbsp; Memory Architecture for Emerging Technologies</a><br>16:00 - 17:15</center></td>
<td><center><a href="#3C">3C&nbsp; Techniques for Analog Circuits and NoC</a><br>16:00 - 17:15</center></td>
<td><center><a href="#3D">3D&nbsp; Advanced test, verification and fault tolerance techniques</a><br>16:00 - 17:15</center></td>
</tr>
</table>
<br>
<hr>
<br>
<a name="day2"></a>
<table border="2" cellspacing="0" cellpadding="5" bgcolor=#dddddd><tr><td>Wednesday, January 15, 2020</table>
<br>
<table class="tbl2" border="1" cellspacing="0" cellpadding="5" bgcolor="#ffffe9">
<tr>
<th width="25.0%" bgcolor="#fff6b1">Room 310</th><th width="25.0%" bgcolor="#fff6b1">Room 308</th><th width="25.0%" bgcolor="#fff6b1">Room 307A</th><th width="25.0%" bgcolor="#fff6b1">Room 307B</th></tr>
<tr>
<td colspan=4 valign=top><center><a href="#3K">3K&nbsp; (Room 311)<br>
Keynote Session III</a><br>9:00 - 10:00</center></td>
</tr>
<tr>
<td colspan=4>
<center><b>Coffee Break</b><br>
10:00 - 10:15
</center>
</td>
</tr>
<tr>
<td><center><a href="#4A">4A&nbsp; (DF-1): Trends in EDA</a><br>10:15 - 11:30</center></td>
<td><center><a href="#4B">4B&nbsp; Machine-Learning and Low-Power Design</a><br>10:15 - 11:30</center></td>
<td><center><a href="#4C">4C&nbsp; Cryptographic Hardware Implementation and Secure Approximate Computing</a><br>10:15 - 11:30</center></td>
<td><center><a href="#4D">4D&nbsp; Emerging Embedded Systems Architecture</a><br>10:15 - 11:30</center></td>
</tr>
<tr>
<td colspan=4 valign=top><center><a href="#4K">4K&nbsp; (Room 311)<br>
Keynote Session IV</a><br>11:30 - 12:10</center></td>
</tr>
<tr>
<td colspan=4>
<center><b>Lunch Break</b><br>
12:20 - 13:50
</center>
</td>
</tr>
<tr>
<td><center><a href="#5A">5A&nbsp; Architecture and Algorithm for Deep Neural Networks</a><br>13:50 - 15:30</center></td>
<td><center><a href="#5B">5B&nbsp; Advanced Memory Systems</a><br>13:50 - 15:30</center></td>
<td><center><a href="#5C">5C&nbsp; Advances in Physical Design</a><br>13:50 - 15:30</center></td>
<td><center><a href="#5D">5D&nbsp; System Simulation and Exploration</a><br>13:50 - 15:30</center></td>
</tr>
<tr>
<td colspan=4>
<center><b>Coffee Break</b><br>
15:30 - 15:45
</center>
</td>
</tr>
<tr>
<td><center><a href="#6A">6A&nbsp; (SS-2): Computation-in-Memory based on emerging non-volatile memories: Technology, design, and test and reliability</a><br>15:45 - 17:00</center></td>
<td><center><a href="#6B">6B&nbsp; (SS-3): Emerging Memory Enabled Computing in The Post-Moore’s Era</a><br>15:45 - 17:25</center></td>
<td><center><a href="#6C">6C&nbsp; (SS-4): AI Enhanced Simulation and Optimization in Back-End EDA Flow</a><br>15:45 - 17:00</center></td>
<td><center><a href="#6D">6D&nbsp; (DF-2): Emerging Design</a><br>15:45 - 17:00</center></td>
</tr>
<tr>
<td colspan=4 valign=top><center><a href="#5K">5K&nbsp; (Room 311)<br>
Keynote Session V</a><br>17:30 - 18:10</center></td>
</tr>
<tr>
<td colspan=4>
<center><b>Banquet (Room 311)</b><br>
18:30 - 20:00
</center>
</td>
</tr>
</table>
<br>
<hr>
<br>
<a name="day3"></a>
<table border="2" cellspacing="0" cellpadding="5" bgcolor=#dddddd><tr><td>Thursday, January 16, 2020</table>
<br>
<table class="tbl2" border="1" cellspacing="0" cellpadding="5" bgcolor="#ffffe9">
<tr>
<th width="25.0%" bgcolor="#fff6b1">Room 310</th><th width="25.0%" bgcolor="#fff6b1">Room 308</th><th width="25.0%" bgcolor="#fff6b1">Room 307A</th><th width="25.0%" bgcolor="#fff6b1">Room 307B</th></tr>
<tr>
<td colspan=4 valign=top><center><a href="#6K">6K&nbsp; (Room 311)<br>
Keynote Session VI</a><br>9:00 - 10:00</center></td>
</tr>
<tr>
<td colspan=4>
<center><b>Coffee Break</b><br>
10:00 - 10:15
</center>
</td>
</tr>
<tr>
<td><center><a href="#7A">7A&nbsp; Neuromorphic Computing</a><br>10:15 - 11:30</center></td>
<td><center><a href="#7B">7B&nbsp; Machine Learning for Embedded Systems</a><br>10:15 - 11:30</center></td>
<td><center><a href="#7C">7C&nbsp; Malicious Activities Generation and Detection</a><br>10:15 - 11:30</center></td>
<td><center><a href="#7D">7D&nbsp; Embedded Software for Energy Optimization and Non-Volatile Memory</a><br>10:15 - 11:30</center></td>
</tr>
<tr>
<td colspan=4>
<center><b>Lunch Break</b><br>
11:30 - 13:50
</center>
</td>
</tr>
<tr>
<td><center><a href="#8A">8A&nbsp; Search and Optimization for Deep Neural Networks</a><br>13:50 - 15:30</center></td>
<td><center><a href="#8B">8B&nbsp; FPGAs for Big Data Systems, Nonvolatile Computing, and Microfluidics</a><br>13:50 - 15:30</center></td>
<td><center><a href="#8C">8C&nbsp; Advances in Logic/High-Level Synthesis</a><br>13:50 - 15:30</center></td>
<td><center><a href="#8D">8D&nbsp; Scalable and Reconfigurable Approximate Arithmetic Units</a><br>13:50 - 15:30</center></td>
</tr>
<tr>
<td colspan=4>
<center><b>Coffee Break</b><br>
15:30 - 15:45
</center>
</td>
</tr>
<tr>
<td><center><a href="#9A">9A&nbsp; (SS-5): Resilience in Integrated Systems</a><br>15:45 - 17:00</center></td>
<td><center><a href="#9B">9B&nbsp; (SS-6): Emerging Technologies across the Abstraction Layers</a><br>15:45 - 17:00</center></td>
<td><center><a href="#9C">9C&nbsp; (SS-7): CMOS Annealing Hardware: Pursuing Efficiency for Solving Combinatorial Optimization Problems</a><br>15:45 - 17:00</center></td>
<td><center><a href="#9D">9D&nbsp; (DF-3): AI Accelerators</a><br>15:45 - 17:00</center></td>
</tr>
</table>
<br>
<hr>
<br>

DF: Designers' Forum, SS: Special Session
<hr>
<h2><center><font color="red">List of papers</font></center></h2>
<font color="red">Remark:</font> The presenter of each paper is marked with "<b><font color="Maroon" size=+1>*</font></b>".
<hr>
<br>
<table border="2" cellspacing="0" cellpadding="5" bgcolor=#dddddd><tr><td>Tuesday, January 14, 2020</table>
<br>
<div style="position: absolute; right: 20px"><a name="1K"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 1K</b>&nbsp; <font size=+1><b>Opening and Keynote Session I</b></font><br>
Time: 9:00 - 10:30 Tuesday, January 14, 2020<br>
Location: Room 311<br>
<p></p>
<a name="1K-1"></a>
1K-1
<font size=-1>(Time: 9:30 - 10:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Keynote Address)</font> <font color="navy">Skin Electronics for Continuous Health Monitoring</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Takao Someya (The University of Tokyo, Japan)</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Keynote</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Flexible and stretchable hybrid electronics are expected to open up a new class of applications ranging from healthcare, medical, sports, wellness, human-machine interfaces, and new IT fashion. In particular, to expand emerging applications of wearable technologies, printed flexible biomedical sensors have attracted much attention recently. In order to minimize the discomfort of wearing sensors, it is highly desirable to use soft electronic materials particularly for devices that come directly into contact with the skin and/or biological tissues. In this regard, electronics manufactured on thin polymeric films, elastomeric and textile substrates by printing are very attractive. In this talk, I will review recent progresses of wearables, smart apparels, and artificial electronic skins (E-skins) from the contexts of high-precision and long-term vital signal monitoring. Furthermore, the issues and the future prospect of wearables and beyond wearables will be addressed.</td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="1A"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 1A</b>&nbsp; <font size=+1><b>University Design Contest</b></font><br>
Time: 10:45 - 12:00 Tuesday, January 14, 2020<br>
Location: Room 310<br>
Chair: Dajiang Liu (Chongqing University)
<p></p>
<a name="1A-1"></a>
<font color="Maroon"><b>Best Design Award</b></font><br>
1A-1
<font size=-1>(Time: 10:45 - 10:48)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Design of a Single-Stage Wireless Charger with 92.3%-Peak-Efficiency  for Portable Devices Applications</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Lin Cheng (University of Science and Technology of China, China), Xinyuan Ge, Wai Chiu Ng, Wing-Hung Ki, Jiawei Zheng, Tsz Fai Kwok, Chi-Ying Tsui (The Hong Kong University of Science and Technology, China), Ming Liu (Institute of Microelectronics, Chinese Academy of Sciences,, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 1 - 2</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Wireless charging, single-stage, CC-CV charging, high efficiency</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>This summary presents a fully-integrated wireless charger to achieve high efficiency with low cost and volume. The charger realizes power rectification, voltage regulation and CC-CV charging in one power stage only. A bootstrapping technique is also designed for on-chip integration of the bootstrap capacitors. A chip prototype was fabricated in a standard 0.35µm CMOS process with a die area of 8mm2. The charger achieves peak efficiency of 92.3% and 91.4% when the charging currents are 1A and 1.5A, respectively..</td></tr>
<tr><td colspan="2"><a href="../pdf/p1_1A-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="1A-2"></a>
1A-2
<font size=-1>(Time: 10:48 - 10:51)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">A Capacitance-to-Digital Converter with Differential Bondwire Accelerometer,  On-chip Air Pressure and Humidity Sensor in 0.18 um CMOS</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Sujin Park (Korea Advanced Institute of Science and Technology, Republic of Korea), Geon-Hwi Lee (Korea Advanced Institute of Science and Technology/SK Hynix, Republic of Korea), <b><font color="Maroon" size=+1>*</font></b>Seungmin Oh, SeongHwan Cho (Korea Advanced Institute of Science and Technology, Republic of Korea)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 3 - 4</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Capacitance-to-digital converter, Air pressure sensor, Relative humidity sensor, Accelerometer, Standard CMOS sensor</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>This paper presents a sensor front-end for air pressure sensor, relative humidity (RH) sensor, and accelerometer in a standard CMOS process. For air pressure and RH, interdigitated top metals in air and polyimide are exploited respectively, which exhibit the change in dielectric constant. For acceleration, separation among three bondwires is exploited. These sensing transducers induce capacitance change that is quantized by a CDC based on a dual quantization architecture that employs a single-bit 1st-order delta-sigma modulator and a 7-bit SAR ADC.</td></tr>
<tr><td colspan="2"><a href="../pdf/p3_1A-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="1A-3"></a>
1A-3
<font size=-1>(Time: 10:51 - 10:54)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">A 28GHz CMOS Differential Bi-Directional Amplifier for 5G NR</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Zheng Li, Jian Pang, Ryo Kubozoe, Xueting Luo, Rui Wu, Yun Wang, Dongwon You, Ashbir Aviat Fadila, Joshua Alvin, Bangan Liu, Zheng Sun, Hongye Huang, Atsushi Shirane, Kenichi Okada (Tokyo Institute of Technology, Japan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 5 - 6</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>28GHz, bi-directional, amplifier, CMOS, 5G NR</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>A 28GHz differential bi-directional amplifier in a standard 65nm CMOS process is presented. This work is realized based on the neutralized bi-directional core together with the fully shared inter-stage matching networks. The core chip area is only 0.11mm2. At 28GHz, a 15.1-dBm saturation output power and a 4.2-dB noise figure are realized for PA mode and LNA mode, respectively. The DC power consumptions for PA mode and LNA mode are 149mW and 31mW, respectively, under 1-V DC supply.</td></tr>
<tr><td colspan="2"><a href="../pdf/p5_1A-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="1A-4"></a>
1A-4
<font size=-1>(Time: 10:54 - 10:57)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">A Quantity Evaluation and Reconfiguration Mechanism for Signal- and Power-Interconnections in 3D-Stacking System</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Ching-Hwa Cheng (Feng Chia University, Taiwan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 7 - 8</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>3D stacking system, Interconnection test, design for testable</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Due to the high integration required for system application, the three-dimensional chip may resolve this requirement. The three-dimensional vertically stacking (3D-stacking) systems have been proposed to satisfy these requirements. However, the 3D-stacking system contains several design risks from its long layer interconnections. For a 3D-stacking system, it is difficult to identify where the numerous power and signal-interconnection are open-, shorted-fault, or resistive-short has accrued. Therefore, solving these interconnection problems is necessary. A feasible interconnection quality-evaluation, fault-diagnosis, and connection-reconfigurable mechanism are proposed. The proposed interconnection-measurement-recovery (IMR) mechanism will make it easy to find interconnection faults and make recovery in 3D-Stacking systems. The proposed IMR can detect interconnection open, short, bridge and resistive defects with the path-reroute mechanism. Future more, the signal transmission quality can be measured. This measurement provides to monitor signal propagation in pico-second accuracy. IMR has less extra area and power consumption overhead. The feasibilities of the proposed mechanism have been justified by 2D-chip and 3D-stacking MorPack both systems.</td></tr>
<tr><td colspan="2"><a href="../pdf/p7_1A-4.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="1A-5"></a>
1A-5
<font size=-1>(Time: 10:57 - 11:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">An Inductively Coupled Wireless Bus for Chiplet-Based Systems</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Junichiro Kadomoto, Satoshi Mitsuno, Hidetsugu Irie, Shuichi Sakai (The University of Tokyo, Japan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 9 - 10</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>chiplet, inductive coupling, wireless communication</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>A wireless bus for inter-chiplet communication is presented. Utilizing horizontal inductive coupling of on-chip coils, wireless connection between chiplets are established. A test chip prototyped in 0.18 &#956;m CMOS confirms 2.0 Gb/s bus communication between horizontally arranged coils with BER of less than 10-12.</td></tr>
<tr><td colspan="2"><a href="../pdf/p9_1A-5.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="1A-6"></a>
1A-6
<font size=-1>(Time: 11:00 - 11:03)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">FPGA-based Heterogeneous Solver for Three-Dimensional Routing</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Kento Hasegawa, <b><font color="Maroon" size=+1>*</font></b>Ryota Ishikawa, Makoto Nishizawa, Kazushi Kawamura, Masashi Tawada, Nozomu Togawa (Waseda University, Japan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 11 - 12</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>heterogeneous, FPGA</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>A heuristic algorithm is one of the approaches to solve an NP-hard problem.
In order to enhance the capability of the system, heterogeneous computing is often adapted.
In this paper, we propose an FPGA-based heterogeneous solver for three-dimensional routing.
The proposed system is implemented into multiple FPGA boards and a single-board computer.
The experimental results demonstrate that the proposed system outperforms a single FPGA system.</td></tr>
<tr><td colspan="2"><a href="../pdf/p11_1A-6.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="1B"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 1B</b>&nbsp; <font size=+1><b>Machine Learning in Physical Design</b></font><br>
Time: 10:45 - 12:00 Tuesday, January 14, 2020<br>
Location: Room 308<br>
Chair: Iris Hui-Ru Jiang (National Taiwan University)
<p></p>
<a name="1B-1"></a>
1B-1
<font size=-1>(Time: 10:45 - 11:10)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">PowerNet: Transferable Dynamic IR Drop Estimation via Maximum Convolutional Neural Network</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Zhiyao Xie (Duke University, USA), Haoxing Ren, Brucek Khailany, Ye Sheng, Santosh Santosh (Nvidia, USA), Jiang Hu (TAMU, USA), Yiran Chen (Duke University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 13 - 18</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>IR drop, machine learning</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>IR drop is a fundamental constraint required by almost all chip designs. However, its evaluation usually takes a long time that hinders mitigation techniques for fixing its violations. In this work, we develop a fast dynamic IR drop estimation technique, named PowerNet, based on a convolutional neural network (CNN). It can handle both vector-based and vectorless IR analyses. Moreover, the proposed CNN model is general and transferable to different designs. This is in contrast to most existing machine learning (ML) approaches, where a model is applicable only to a specific design. Experimental results show that PowerNet outperforms the latest ML method by 9% in accuracy for the challenging case of vectorless IR drop and achieves a 30 times speedup compared to an accurate IR drop commercial tool. Further, a mitigation tool guided by PowerNet reduces IR drop hotspots by 26% and 31% on two industrial designs, respectively, with very limited modification on their power grids.</td></tr>
<tr><td colspan="2"><a href="../pdf/p13_1B-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="1B-2"></a>
1B-2
<font size=-1>(Time: 11:10 - 11:35)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">FIST: A Feature-Importance Sampling and Tree-Based Method for Automatic Design Flow Parameter Tuning</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Zhiyao Xie (Duke University, USA), Guan-Qi Fang, Yu-Hung Huang (National Taiwan University of Science and Technology, Taiwan), Haoxing Ren, Yanqing Zhang, Brucek Khailany (Nvidia, USA), Shao-Yun Fang (National Taiwan University of Science and Technology, Taiwan), Jiang Hu (TAMU, USA), Yiran Chen (Duke University, USA), Erick Carvajal Barboza (TAMU, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 19 - 25</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>automatic parameter tuning, design flow, machine learning</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Design flow parameters are of utmost importance to chip design quality and require a painfully long time to evaluate their effects. In reality, flow parameter tuning is usually performed manually based on designers' experience in an ad hoc manner. In this work, we introduce a machine learning-based automatic parameter tuning methodology that aims to find the best design quality with a limited number of trials. Instead of merely plugging in machine learning engines, we develop clustering and approximate sampling techniques for improving tuning efficiency. The feature extraction in this method can reuse knowledge from prior designs. Furthermore, we leverage a state-of-the-art XGBoost model and propose a novel dynamic tree technique to overcome overfitting. Experimental results on benchmark circuits show that our approach achieves 25% improvement in design quality or 37% reduction in sampling cost compared to random forest method, which is the kernel of a highly cited previous work. Our approach is further validated on two industrial designs. By sampling less than 0.02% of possible parameter sets, it reduces area by 1.83% and 1.43% compared to the best solutions hand-tuned by experienced designers.</td></tr>
<tr><td colspan="2"><a href="../pdf/p19_1B-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="1B-3"></a>
1B-3
<font size=-1>(Time: 11:35 - 12:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">High-Definition Routing Congestion Prediction for Large-Scale FPGAs</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Mohamed Baker Alawieh, Wuxi Li, <b><font color="Maroon" size=+1>*</font></b>Yibo Lin (The University of Texas at Austin, USA), Love Singhal, Mahesh A. Iyer (Intel, USA), David Z. Pan (The University of Texas at Austin, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 26 - 31</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Congestion, Routing, FPGA, Machine Learning</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>To speed up the FPGA placement and routing closure, we propose a
novel approach to predict the routing congestion map for large-scale
FPGA designs at the placement stage. After reformulating the problem
into an image translation task, our proposed approach leverages recent
advancement in generative adversarial learning to address the task.
Particularly, state-of-the-art generative adversarial networks for high- resolution image translation are used along with well-engineered features extracted from the placement stage. Unlike available approaches, our novel framework demonstrates a capability of handling large-scale FPGA designs. With its superior accuracy, our proposed approach can be incorporated into the placement engine to provide congestion prediction resulting in up to 7% reduction in routed wirelength for the most congested design in ISPD 2016 benchmark.</td></tr>
<tr><td colspan="2"><a href="../pdf/p26_1B-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="1C"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 1C</b>&nbsp; <font size=+1><b>Toward Optimal Timing and PDN Design</b></font><br>
Time: 10:45 - 12:00 Tuesday, January 14, 2020<br>
Location: Room 307A<br>
Chairs: Yu-Guang Chen (National Central University, Taiwan), Jianglei Yang (Beihang University)
<p></p>
<a name="1C-1"></a>
<font color="Maroon"><b>Best Paper Candidate</b></font><br>
1C-1
<font size=-1>(Time: 10:45 - 11:10)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Integrated Airgap Insertion and Layer Reassignment for Circuit Timing Optimization</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Younggwang Jung, Daijoon Hyun, Youngsoo Shin (Korea Advanced Institute of Science and Technology, Republic of Korea)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 32 - 37</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Airgap, Airgap insertion, Layer reassignment, Timing optimization</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Airgap is an intentional void formed in inter-metal dielectric. It brings about reduced coupling capacitance, and so can be used to improve circuit timing. Airgap can be utilized in a limited number of metal layers due to its high process cost. For given airgap layers, two problems should be addressed to insert airgap: relocate some metal segments in non-airgap layers into airgap layers (called layer reassignment) and determine the amount of airgap for each metal segment in airgap layers (airgap insertion). Two problems are solved together in this paper with a goal of maximizing setup total negative slack (TNS) while assuring no hold violations. It is formulated as mixed integer quadratically constrained programming (MIQCP); heuristic algorithm is proposed for practical application and its performance against MIQCP is experimentally assessed using small test circuits. Experiments demonstrate that TNS and WNS are improved by 35% and 10%, respectively, while simple minded approach achieves 6% and 4% less improvements compared to the proposed method.</td></tr>
<tr><td colspan="2"><a href="../pdf/p32_1C-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="1C-2"></a>
1C-2
<font size=-1>(Time: 11:10 - 11:35)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">An Adaptive Electromigration Assessment Algorithm for Full-chip Power/Ground Networks</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Shaobin Ma, Xiaoyi Wang (Beijing Engineering Research Center for IoT Software and Systems,Beijing University of Technology, China), Sheldon X.-D. Tan, Liang Chen (Department of Electrical and Computer Engineering, University of California, Riverside, USA), Jian He (Beijing Engineering Research Center for IoT Software and Systems,Beijing University of Technology, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 38 - 43</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Electromigration, Power/Ground Networks, Eigenfunction</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>In this paper, an adaptive algorithm is proposed to perform electromigration (EM) assessment for full-chip power/ground networks. Based on the eigenfunction solutions, the proposed method improves the efficiency by properly selecting the eigenfunction terms and utilizing the closed-form eigenfunctions for commonly seen interconnect wires such as T-shaped or cross-shaped wires. It is demonstrated that the proposed method can trad-off well among the accuracy, efficiency and applicability of the eigenfunction based methods. The experimental results show that the proposed method is about three times faster than the finite difference method and other eigenfunction based methods.</td></tr>
<tr><td colspan="2"><a href="../pdf/p38_1C-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="1C-3"></a>
1C-3
<font size=-1>(Time: 11:35 - 12:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Template-based PDN Synthesis in Floorplan and Placement Using Classifier and CNN Techniques</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Vidya A. Chhabria (University of Minnesota, USA), Andrew B. Kahng, Minsoo Kim, Uday Mallappa (University of California, San Diego, USA), Sachin S. Sapatnekar (University of Minnesota, USA), Bangqi Xu (University of California, San Diego, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 44 - 49</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Power Delivery Network, Machine Learning</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Designing an optimal power delivery network (PDN) is a
time-intensive task that involves many iterations. This paper proposes a
methodology that employs a library of predesigned, stitchable templates,
and uses machine learning (ML) to rapidly build a PDN with region-wise
uniform pitches based on these templates. Our methodology is applicable
at both the floorplan and placement stages of physical implementation.
(i) At the floorplan stage, we synthesize an optimized PDN based
on early estimates of current and congestion, using a simple multilayer
perceptron classifier. (ii) At the placement stage, we incrementally
optimize an existing PDN based on more detailed congestion and current
distributions, using a convolution neural network. At each stage, the
neural network builds a safe-by-construction PDN that meets IR drop
and electromigration (EM) specifications. On average, the optimization
of the PDN brings an extra 3% (1,850 tracks) of routing resources, which
corresponds to a thousands of routing tracks in congestion-critical regions, when compared to a globally uniform PDN, while staying within the IR drop and EM limits.</td></tr>
<tr><td colspan="2"><a href="../pdf/p44_1C-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="1D"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 1D</b>&nbsp; <font size=+1><b>Side Channel Attacks and Countermeasures</b></font><br>
Time: 10:45 - 12:00 Tuesday, January 14, 2020<br>
Location: Room 307B<br>
Chairs: Hiromitsu Awano (Osaka University, Japan), Song Bian (Kyoto University, Japan)
<p></p>
<a name="1D-1"></a>
<font color="Maroon"><b>Best Paper Candidate</b></font><br>
1D-1
<font size=-1>(Time: 10:45 - 11:10)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Analyzing The Security of  The Cache Side Channel Defences With Attack Graphs</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Limin Wang, Ziyuan Zhu, Zhanpeng Wang, Dan Meng (Institute of Information Engineering, Chinese Academy of Sciences, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 50 - 55</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>cache side-channel defences, micro-architecture, model checking, attack graph, early-stage design</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Note that very limited work is proposed to analyze the security of defenses against the cache side channel attacks on micro-architecture. In this paper, we propose a model based method to generate a visual attack graph and analyze the security of micro-architecture security designs in the early stages of processor design. The experiments indicate that our method can identify the special attack paths that some common security designs fail to defend against and show them in an attack graph.</td></tr>
<tr><td colspan="2"><a href="../pdf/p50_1D-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="1D-2"></a>
1D-2
<font size=-1>(Time: 11:10 - 11:35)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">iGPU Leak: An Information Leakage Vulnerability on Intel Integrated GPU</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Wenjian He, Wei Zhang (The Hong Kong University of Science and Technology, Hong Kong), Sharad Sinha (Indian Institute of Technology Goa, India), Sanjeev Das (University of North Carolina at Chapel Hill, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 56 - 61</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Security, Information Leakage, Integrated GPU</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Hardware accelerators such as integrated graphics processing units (iGPUs) are increasingly prevalent in modern systems. They typically provide multiplexing support where several user applications can share the iGPU acceleration resources. However, security in this setting has not received sufficient consideration. In this work, we disclose a critical information leakage vulnerability due to defective GPU context management. In essence, residual register values and shared local memory in the iGPU are not cleared during a context switch. As a result, adversaries can recover the secret key of a cryptographic algorithm running on an iGPU from a single snapshot of the leaking channel. User privacy is also under threat due to browser activity eavesdropping through website-fingerprinting attack with high accuracy and resolution. Moreover, this vulnerability can constitute a covert channel with a bandwidth of up to 8 Gbps.</td></tr>
<tr><td colspan="2"><a href="../pdf/p56_1D-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="1D-3"></a>
1D-3
<font size=-1>(Time: 11:35 - 12:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Design for EM Side-Channel Security through Quantitative Assessment of RTL Implementations</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Jiaji He (Tsinghua University, China), Haocheng Ma (Tianjin University, China), Xiaolong Guo (Kansas State University, USA), Yiqiang Zhao (Tianjin University, China), Yier Jin (University of Florida, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 62 - 67</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>side-channel attack, design for side-channel security, T-test, RTL hardware implementation</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Electromagnetic (EM) side-channel attacks aim at extracting secret information from cryptographic hardware implementations. Countermeasures have been proposed at device level, register-transfer level (RTL) and layout level, though efficient, there are still requirements for quantitative assessment of the hardware implementations' resistance against EM side-channel attacks. In this paper, we propose a design for EM side-channel security evaluation and optimization framework based on the t-test evaluation results derived from RTL hardware implementations. Different implementations of the same cryptographic algorithm are evaluated under different hypothesis leakage models considering the driven capabilities of logic components, and the evaluation results are validated with side-channel attacks on FPGA platform. Experimental results prove the feasibility of the proposed side-channel leakage evaluation method at pre-silicon stage. The remedies and suggested security design rules are also discussed.</td></tr>
<tr><td colspan="2"><a href="../pdf/p62_1D-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="2K"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 2K</b>&nbsp; <font size=+1><b>Keynote Session II</b></font><br>
Time: 12:00 - 12:40 Tuesday, January 14, 2020<br>
Location: Room 311<br>
<p></p>
<a name="2K-1"></a>
2K-1
<font size=-1>(Time: 12:00 - 12:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Keynote Address)</font> <font color="navy">Edge-to-Cloud Innovations for Inclusive AI</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Xiaoning Qi (Alibaba)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Technology has propelled us into an era of data and AI, and computing power is the force behind it all. At the core of computing power is the tiny yet mighty chip. T-Head has formed a full-stack chip system that facilitates edge-to-cloud integration, including processor IPs, SoC platforms, and AI chips. T-Head's success in hardware-software innovation is built on its self-developed chip structure and bolstered by Alibaba DAMO Academy's leading AI algorithms and AliOS operating system.</td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="2A"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 2A</b>&nbsp; <font size=+1><b>(SS-1): Designing Reliable and Robust Circuits and Systems in the Nanometer Era</b></font><br>
Time: 14:00 - 15:40 Tuesday, January 14, 2020<br>
Location: Room 310<br>
Chair: Sheldon Tan (University of California Riverside, USA)
<p></p>
<a name="2A-1"></a>
2A-1
<font size=-1>(Time: 14:00 - 14:25)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Impact of Self-Heating On Performance, Power and Reliability in FinFET Technology</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Victor M. van Santen, Paul R. Genssler, Om Prakash, Simon Thomann, Jörg Henkel, <b><font color="Maroon" size=+1>*</font></b>Hussam Amrouch (Karlsruhe Institute of Technology, Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 68 - 73</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Self Heating, Reliability, FinFET, Temperature</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Self-heating is one of the biggest threats to reliability in current CMOS technologies like FinFET and Nanowire. Encapsulating the channel with the gate dielectric improved electrostatics, but also thermally insulates the channel resulting in elevated channel temperatures as the generated heat is trapped within the channel. Elevated channel temperatures lowers performance, increases power consumption and lowers reliability of these circuits build from FinFET or Nanowire transistors. This work provides an overview over self-heating with respect to circuit design.</td></tr>
<tr><td colspan="2"><a href="../pdf/p68_2A-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="2A-2"></a>
2A-2
<font size=-1>(Time: 14:25 - 14:50)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Reliable Power Grid Network Design Framework Considering EM Immortalities for Multi-Segment Wires</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Han Zhou, Shuyuan Yu, Zeyu Sun, <b><font color="Maroon" size=+1>*</font></b>Sheldon X.-D. Tan (University of California, Riverside, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 74 - 79</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Power Grid, Electromigration, Immortality, Multi-Segment</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>This paper presents a new power grid network design and optimization technique that considers the new EM immortality constraint due to EM void saturation volume for multi-segment interconnects. Void may grow to its saturation volume without changing the wire resistance significantly. However, this phenomenon was ignored in existing EM-aware optimization methods. By considering this new effect, we can remove more conservativeness in the EM-aware on-chip power grid design. Along with recently proposed nucleation phase immortality constraint for multi-segment wires, we show that both EM immortality constraints can be naturally integrated into the existing programming based power grid optimization framework. To further mitigate the overly conservative problem of existing immortality-constrained optimization methods, we further explore two strategies: first we size up failed wires to meet one of immorality conditions subject to design rules; second, we consider the EM-induced aging effects on power supply networks for a targeted lifetime, which allows some short-lifetime wires to fail and optimizes the rest of the wires. Numerical results on a number of IBM and self-generated power supply networks demonstrate that the new method can reduce more power grid area compared to the existing EM-immortality constrained optimizations. Furthermore, the new method can optimize power grids with nucleated wires, which would not be possible with the existing methods.</td></tr>
<tr><td colspan="2"><a href="../pdf/p74_2A-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="2A-3"></a>
2A-3
<font size=-1>(Time: 14:50 - 15:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Investigating the Inherent Soft Error Resilience of Embedded Applications by Full-System Simulation</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Uzair Sharif, Daniel Müller-Gritschneder, <b><font color="Maroon" size=+1>*</font></b>Ulf Schlichtmann (Technical University of Munich, Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 80 - 84</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Soft error resilience, silent data corruption, application resilience, safety critical embedded systems</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>It has long been acknowledged that some applications
feature inherent resilience against soft errors, e.g., the
impact of soft errors on multimedia applications is often nonvisible
to humans. In this paper we investigate the inherent
resilience of two typical embedded applications using a case study
of a control system and a robot arm. Both studies were enabled
by our mixed-mode fault injection simulator ETISS-ML, which
allows RTL-accurate fault injection while being able to simulate
very long scenarios, e.g. robot movements of several seconds. Our
results indicate that full simulation of the embedded system and
its environment are required to classify whether the system can
tolerate the impact of a soft error. This is due to the fact that
it is hard to predict the impact of a certain output deviation
without investigating the change in the system behavior taking
into account the control loop. Based on this classification method
we hope to be able to exploit this resilience for lowering the cost
of error detection mechanisms in future research.</td></tr>
<tr><td colspan="2"><a href="../pdf/p80_2A-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="2B"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 2B</b>&nbsp; <font size=+1><b>System Architecture Innovation</b></font><br>
Time: 14:00 - 15:40 Tuesday, January 14, 2020<br>
Location: Room 308<br>
Chair: Eric Liang (Peking Universtiy)
<p></p>
<a name="2B-1"></a>
<font color="Maroon"><b>Best Paper Candidate</b></font><br>
2B-1
<font size=-1>(Time: 14:00 - 14:25)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Co-Exploring Neural Architecture and Network-on-Chip Design for Real-Time Artificial Intelligence</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Lei Yang (University of Pittsburgh, USA), Weiwen Jiang (University of Notre Dame, USA), Weichen Liu (Nanyang Technological University, Singapore), Edwin H. M. Sha (East China Normal University, China), Yiyu Shi (University of Notre Dame, USA), Jingtong Hu (University of Pittsburgh, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 85 - 90</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>NAS and NoC Co-Exploration</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Hardware-aware Neural Architecture Search (NAS), which automatically finds an architecture that works best on a given hardware design, has prevailed in response to the ever-growing demand for real-time Artificial Intelligence (AI). However, in many situations, the underlying hardware is not pre-determined. We argue that simply assuming an arbitrary yet fixed hardware design will lead to inferior solutions, and it is best to co-explore neural architecture space and hardware design space for the best pair of neural architecture and hardware design. To demonstrate this, we employ Network-on-Chip (NoC) as the infrastructure and propose a novel framework, namely NANDS, to co-explore NAS space and NoC Design Search (NDS) space with the objective to maximize accuracy and throughput. Since two metrics are tightly coupled, we develop a multi-phase manager to guide NANDS to gradually converge to solutions with the best accuracy-throughput tradeoff. On top of it, we propose techniques to detect and alleviate timing performance bottleneck, which allows better and more efficient exploration of NDS space.</td></tr>
<tr><td colspan="2"><a href="../pdf/p85_2B-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="2B-2"></a>
2B-2
<font size=-1>(Time: 14:25 - 14:50)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Thanos: High-Performance CPU-GPU Based Balanced Graph Partitioning Using Cross-Decomposition</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Dae Hee Kim, Rakesh Nagi, <b><font color="Maroon" size=+1>*</font></b>Deming Chen (University of Illinois at Urbana-Champaign, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 91 - 96</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Graph Partitioning, GPU, Cross-Decomposition, Acceleration</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>As graphs become larger and more complex, it is becoming nearly impossible to process them without graph partitioning. Graph partitioning creates many subgraphs which can be processed in parallel thus delivering high-speed computation results. However, graph partitioning is a difficult task. In this work, we introduce Thanos, a fast graph partitioning tool which uses the cross-decomposition algorithm that iteratively partitions a graph. It also produces balanced loads of partitions. The algorithm is well suited for parallel GPU programming which leads to fast and high-quality graph partitioning solutions. Experimental results show that we have achieved 30x speedup and 35% better edge cut reduction compared to the CPU version of the popular graph partitioner, METIS, on average.</td></tr>
<tr><td colspan="2"><a href="../pdf/p91_2B-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="2B-3"></a>
2B-3
<font size=-1>(Time: 14:50 - 15:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Reutilization of Trace Buffers for Performance Enhancement of NoC based MPSoCs</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Sidhartha Sankar Rout, Badri M, Sujay Deb (Indraprastha Institute of Information Technology, Delhi, India)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 97 - 102</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>network on chip, design for debug, trace buffers, virtual channels, fair division</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>The contemporary network-on-chips (NoCs) are so complex that capturing all network functional faults at pre-silicon verification stage is nearly impossible. So, on-chip design-for-debug (DfD) structures such as trace buffers are provided to assist capturing escaped faults during post-silicon debug. Most of the DfD modules are left idle after the debug process. Reuse of such structures can compensate for the area overhead introduced by them. In this work, the trace buffers are reutilized as extended virtual channels for the router nodes of an NoC during in-field execution. Optimal distribution of trace buffers among the routers is performed based upon their load profiling. Experiments with several benchmarks on the proposed architecture show an average of 11.36% increase in network throughput and 13.97% decrease in average delay.</td></tr>
<tr><td colspan="2"><a href="../pdf/p97_2B-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="2B-4"></a>
2B-4
<font size=-1>(Time: 15:15 - 15:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Formal Semantics of Predictable Pipelines: a Comparative Study</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Mathieu Jan, <b><font color="Maroon" size=+1>*</font></b>Mihail Asavoae (CEA LIST, France), Martin Schoeberl (Technical University of Denmark, Denmark), Edward A. Lee (University of California at Berkeley, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 103 - 108</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>real-time systems, timing anomalies, model-checking</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Computer architectures used in safety-critical domains are subjected to worst-case execution time analysis. The presence of performance-driven microarchitectures may trigger undesired timing phenomena, called timing anomalies, and complicate the timing analysis. This paper investigates pipelines specifically designed to simplify the worst-case execution time analysis (also called predictable pipelines). We propose formal and executable models of four research-oriented pipelines and one industrial pipeline to validate some of their claims related to their timing behavior. We indeed validate, via bounded model checking, the absence of a type of timing anomalies called amplification timing anomalies, or its potential presence by identifying prerequisite to situations where they can occur.</td></tr>
<tr><td colspan="2"><a href="../pdf/p103_2B-4.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="2C"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 2C</b>&nbsp; <font size=+1><b>Optical Networks-on-Chips and Quantum Circuit Design</b></font><br>
Time: 14:00 - 15:40 Tuesday, January 14, 2020<br>
Location: Room 307A<br>
Chairs: Rudy Raymond H.P. (IBM Research, Tokyo, Japan), Shigeru Yamashita (Ritsumeikan University)
<p></p>
<a name="2C-1"></a>
2C-1
<font size=-1>(Time: 14:00 - 14:25)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Maximizing the Communication Parallelism for Wavelength-Routed Optical Networks-on-Chips</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Mengchu Li, Tsun-Ming Tseng (Technical University of Munich, Germany), Mahdi Tala (University of Ferrara, Italy), Ulf Schlichtmann (Technical University of Munich, Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 109 - 114</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>WRONoC, Bit-Parallelism, ILP</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Wavelength-routed optical networks-on-chips (WRONoCs) apply a passive routing mechanism that statically reserves all data transmission paths at design time, and are thus able to avoid the latency and energy overhead for arbitration. Current research mostly assumes that in WRONoCs, each initiator sends one bit at a time to a target. However, the communication parallelism can be increased by assigning multiple wavelengths to each path, which requires a systematic analysis of the physical parameters of silicon microring resonators and the wavelength usage among different paths. This work proposes a mathematical modeling method to maximize the communication parallelism of a given WRONoC topology, which provides a foundation for exploiting the bandwidth potential of WRONoCs.</td></tr>
<tr><td colspan="2"><a href="../pdf/p109_2C-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="2C-2"></a>
2C-2
<font size=-1>(Time: 14:25 - 14:50)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Concurrency in DD-based Quantum Circuit Simulation</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Stefan Hillmich, Alwin Zulehner, Robert Wille (Johannes Kepler University Linz Institute for Integrated Circuits, Austria)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 115 - 120</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>quantum computing, decision diagrams, design automation</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Despite recent progress in physical implementations of quantum computers, a significant amount of research still depends on simulating quantum computations on classical computers. Here, most state-of-the-art simulators rely on array-based approaches which are perfectly suited for acceleration through concurrency using multi- or many-core processors. However, those methods have exponential memory complexities and, hence, become infeasible if the considered quantum circuits are too large. To address this drawback, complementary approaches based on decision diagrams (called DD-based simulation) have been proposed which provide more compact representations in many cases. While this allows to simulate quantum circuits that could not be simulated before, it is unclear whether DD-based simulation also allows for similar acceleration through concurrency as array-based approaches. In this work, we investigate this issue. The resulting findings provide a better understanding about when DD-based simulation can be accelerated through concurrent executions of sub-tasks and when not.</td></tr>
<tr><td colspan="2"><a href="../pdf/p115_2C-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="2C-3"></a>
2C-3
<font size=-1>(Time: 14:50 - 15:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Approximation of Quantum States Using Decision Diagrams</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Alwin Zulehner, Stefan Hillmich (Johannes Kepler University Linz Institute for Integrated Circuits, Austria), Igor L. Markov (University of Michigan, USA), <b><font color="Maroon" size=+1>*</font></b>Robert Wille (Johannes Kepler University Linz Institute for Integrated Circuits, Austria)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 121 - 126</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>quantum computing, decision diagrams, design automation</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>The computational power of quantum computers poses major challenges to new design tools since representing pure quantum states typically requires exponentially large memory. As shown previously, decision diagrams can reduce these memory requirements by exploiting redundancies. In this work, we demonstrate further reductions by allowing for small inaccuracies in the quantum state representation. Such inaccuracies are legitimate since quantum computers themselves experience gate and measurement errors and since quantum algorithms are somewhat resistant to errors (even without error correction). We develop four dedicated schemes that exploit these observations and effectively approximate quantum states represented by decision diagrams. We empirically show that the proposed schemes reduce the size of decision diagrams by up to several orders of magnitude while controlling the fidelity of approximate quantum state representations.</td></tr>
<tr><td colspan="2"><a href="../pdf/p121_2C-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="2C-4"></a>
2C-4
<font size=-1>(Time: 15:15 - 15:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Improved DD-based Equivalence Checking of Quantum Circuits</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Lukas Burgholzer, Robert Wille (Johannes Kepler University Linz, Austria)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 127 - 132</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>quantum computing, equivalence checking, decision diagrams, reversible circuits</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Quantum computing is gaining considerable momentum through the recent progress in physical realizations of quantum computers. This led to rather sophisticated design flows in which the originally specified quantum functionality is compiled through different abstractions. This increasingly raises the question whether the respectively resulting quantum circuits indeed realize the originally intended function. Accordingly, efficient methods for equivalence checking are gaining importance. However, existing solutions still suffer from significant shortcomings such as their exponential worst case performance and an increased effort to obtain counterexamples in case of non-equivalence. In this work, we propose an improved DD-based equivalence checking approach which addresses these shortcomings. To this end, we utilize decision diagrams and exploit the fact that  quantum operations are inherently reversible -- allowing for dedicated strategies that keep the overhead moderate in many cases. Experimental results confirm that the proposed strategies lead to substantial speed-ups -- allowing to perform equivalence checking of quantum circuits factors or even magnitudes faster than the state of the art.</td></tr>
<tr><td colspan="2"><a href="../pdf/p127_2C-4.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="2D"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 2D</b>&nbsp; <font size=+1><b>Reliability from Design to Manufacturing</b></font><br>
Time: 14:00 - 15:40 Tuesday, January 14, 2020<br>
Location: Room 307B<br>
Chair: Changhao Yan (Fudan University, China)
<p></p>
<a name="2D-1"></a>
<font color="Maroon"><b>Best Paper Award</b></font><br>
2D-1
<font size=-1>(Time: 14:00 - 14:25)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Equivalent Capacitance Guided Dummy Fill Insertion for Timing and Manufacturability</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Sheng-Jung Yu, Chen-Chien Kao, Chia-Han Huang, Iris Hui-Ru Jiang (National Taiwan University, Taiwan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 133 - 138</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>CMP, Dummy Fill, Equivalent Capacitance</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>To improve manufacturability, dummy fill insertion is widely adopted for reducing the thickness variation after chemical mechanical polishing.
However, inserted metal fills induce significant coupling to nearby signal nets, thus possibly incurring timing degradation.
Existing timing-aware fill insertion strategies focus on optimizing induced coupling capacitance instead of resultant equivalent capacitance.
Therefore, the impact on timing cannot be fully captured.
In contrast, in this paper, we analyze equivalent capacitance friendly regions for dummy fills.
The analysis can wisely guide dummy fill insertion to prevent unwanted and unnecessary increase in the resultant equivalent capacitance of timing critical nets. 
Experimental results based on the ICCAD 2018 CAD Contest benchmark suite show that our solution outperforms the contest winning teams and state-of-the-art work.
Moreover, our analysis results are highly correlated to actual equivalent capacitance values and indeed provide accurate guidance for timing-aware dummy fill insertion.</td></tr>
<tr><td colspan="2"><a href="../pdf/p133_2D-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="2D-2"></a>
2D-2
<font size=-1>(Time: 14:25 - 14:50)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Synthesis of Hardware Performance Monitoring and Prediction Flow Adapting to Near-Threshold Computing and Advanced Process Nodes</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Jeongwoo Heo (Seoul National University, Republic of Korea), Kwangok Jeong (Samsung Electronics Co., Ltd., Republic of Korea), Taewhan Kim, Kyumyung Choi (Seoul National University, Republic of Korea)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 139 - 144</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>monitoring, performance, variation, prediction</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>An elaborate hardware performance monitor (HPM) has become increasingly important for handling huge performance variation of near-threshold computing and recent process technologies. In this paper, we propose a new approach to the problem of predicting critical path delays (CPDs) using HPM. Precisely, for a target circuit or system, we formulate the problem of finding an efficient combination of ring oscillators (ROs) for accurate prediction of CPDs on the circuit as a mixed integer second-order cone programming and propose a method of minimizing the total number of ROs for a given pessimism level of prediction. Then, we propose a prediction flow of CPDs through statistical estimation of process parameters from measurements of the customized HPM and machine learning based delay mapping from the estimation. For a set of benchmark circuits tested using 28nm PDK and 0.6V operation, it is shown that our approach is very effective, reducing the pessimism of CPDs and minimum supply voltages by 6.7~52.9% and 20.6~50.8% over those of conventional approaches, respectively.</td></tr>
<tr><td colspan="2"><a href="../pdf/p139_2D-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="2D-3"></a>
2D-3
<font size=-1>(Time: 14:50 - 15:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Enhancing Generalization of Wafer Defect Detection by Data Discrepancy-aware Preprocessing and Contrast-varied Augmentation</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Chaofei Yang, Hai Li, <b><font color="Maroon" size=+1>*</font></b>Yiran Chen (Duke University, USA), Jiang Hu (Texas A&amp;M University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 145 - 150</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Wafer, Defect, CNN, Preprocessing, Augmentation</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Wafer inspection locates defects at early fabrication stages and traditionally focuses on pixel-level defects. However, there are very few solutions that can effectively detect large-scale defects. In this work, we leverage Convolutional Neural Networks (CNNs) to automate the wafer inspection process and propose several techniques to preprocess and augment wafer images for enhancing our model's generalization on unseen wafers (e.g., from other fabs). Cross-fab experimental results of both wafer-level and pixel-level detections show that the F1 score increases from 0.09 to 0.77 and the Precision-Recall area under curve (PR AUC) increases from 0.03 to 0.62 using our proposed method.</td></tr>
<tr><td colspan="2"><a href="../pdf/p145_2D-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="2D-4"></a>
2D-4
<font size=-1>(Time: 15:15 - 15:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Exploring Graphical Models with Bayesian Learning and MCMC for Failure Diagnosis</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Hongfei Wang, Wenjie Cai, Jianwen Li, Kun He (Huazhong University of Science and Technology, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 151 - 156</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Graphical Models, Diagnosis, machine learning, Bayesian methods, test</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Graphical models are powerful machine learning
techniques for data analytics. Being capable of statistical reasoning
and probabilistic inference, graphical models have the
advantages of encoding prior knowledges into the learning procedure,
and producing explainable models that can be understood
and effectively tuned. In this work, we describe our exploration
on the frontier of using graphical models for improving circuit
diagnosis results. A statistical framework has been proposed for
this aim, which builds Bayesian inference models using directed
chain graphs, and structural learning models using undirected
tree graphs. As a generative model, the framework integrates
Markov chain Monte Carlo (MCMC) algorithm for sampling to
evaluate the quality of diagnostic results. It exploits maximumlikelihood
to estimate the underlying defect types, which can
be informative towards the possible follow-up failure analysis.
Five circuit examples demonstrate that the proposed framework
achieves the same or better results over a state-of-the-art work.
Moreover, our method also shows opportunities for dealing with
missing features and locating root causes.</td></tr>
<tr><td colspan="2"><a href="../pdf/p151_2D-4.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="3A"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 3A</b>&nbsp; <font size=+1><b>Reliability and Security for Deep Neural Networks</b></font><br>
Time: 16:00 - 17:15 Tuesday, January 14, 2020<br>
Location: Room 310<br>
Chair: Andrew Putnam (Microsoft, USA)
<p></p>
<a name="3A-1"></a>
3A-1
<font size=-1>(Time: 16:00 - 16:25)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Mitigating Adversarial Attacks for Deep Neural Networks by Input Deformation and Augmentation</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Pengfei Qiu (Tsinghua University, China), Qian Wang (University of Maryland, College Park, USA), Dongsheng Wang, Yongqiang Lyu (Tsinghua University, China), Zhaojun Lu, Gang Qu (University of Maryland, College Park, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 157 - 162</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Deep Neural Network, Adversarial Attack, Input Deformation, Data Augmentation, Majority Voting</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Typical Deep Neural Networks (DNN) are susceptible to adversarial attacks that add malicious perturbations to input to mislead the DNN model. Most of the state-of-the-art countermeasures concentrate on the defensive distillation or parameter re-training, which require prior knowledge of the target DNN and/or the attacking methods and hence greatly limit their generality and usability. In this paper, we propose to defend against adversarial attacks by utilizing the input deformation and augmentation techniques that are currently widely utilized to enlarge the dataset during DNN's training phase. This is based on the observation that certain input deformation and augmentation methods will have little or no impact on DNN model's accuracy, but the adversarial attacks will fail when the maliciously induced perturbations are randomly deformed. We also use the ensemble of decisions to further improve DNN model's accuracy and the effectiveness of defending various attacks. Our proposed mitigation method is model independent (i.e. it does not require additional training, parameter fine-tuning, or any structure modifications of the target DNN model) and attack independent (i.e., it does not require any knowledge of the adversarial attacks). So it has excellent generality and usability. We conduct experiments on standard CIFAR-10 dataset and three representative adversarial attacks: Fast Gradient Sign Method, Carlini and Wagner, and Jacobian-based Saliency Map Attack. Results show that the average success rate of the attacks can be reduced from 96.5% to 28.7% while the DNN model accuracy is improved by about 2%.</td></tr>
<tr><td colspan="2"><a href="../pdf/p157_3A-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="3A-2"></a>
3A-2
<font size=-1>(Time: 16:25 - 16:50)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">When Single Event Upset Meets Deep Neural Networks: Observations, Explorations, and Remedies</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Zheyu Yan (Zhejiang University, China), Yiyu Shi (University of Notre Dame, USA), Wang Liao, Masanori Hashimoto (Osaka University, Japan), Xichuan Zhou (Chongqing University, China), <b><font color="Maroon" size=+1>*</font></b>Cheng Zhuo (Zhejiang University, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 163 - 168</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>DNN, SEU, ECC</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>For Deep Neural Network (DNN) used in security sensitive systems, we investigate from hardware perspective about the impact of Single Event Upset (SEU) induced parameter perturbation (SIPP). We define the fault models of SEU and then provide a robustness measure for networks. We then analytically explore the impact of SIPP on different SEU patterns and networks. We then propose remedy solutions to protect DNNs from SIPPs, mitigating accuracy degradation from 28% to 0.27% for ResNet with 25% SRAM area overhead.</td></tr>
<tr><td colspan="2"><a href="../pdf/p163_3A-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="3A-3"></a>
3A-3
<font size=-1>(Time: 16:50 - 17:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Concurrent Monitoring of Operational Health in Neural Networks Through Balanced Output Partitions</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Elbruz Ozen, <b><font color="Maroon" size=+1>*</font></b>Alex Orailoglu (University of California, San Diego, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 169 - 174</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>fault-tolerance, deep neural networks, autonomous driving</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>The abundant usage of deep neural networks in safety-critical domains such as autonomous driving raises concerns regarding the impact of hardware-level faults on deep neural network computations. As a failure can prove to be disastrous, low-cost safety mechanisms are needed to check the integrity of the deep neural network computations. We embed safety checksums into deep neural networks by introducing a custom regularization term in the network training. We partition the outputs of each network layer into two groups and guide the network to balance the summation of these groups through an additional penalty term in the cost function. The proposed approach delivers twin benefits. While the embedded checksums deliver low-cost detection of computation errors upon violations of the trained equilibrium during network inference, the regularization term enables the network to generalize better during training by preventing overfitting, thus leading to significantly higher network accuracy.</td></tr>
<tr><td colspan="2"><a href="../pdf/p169_3A-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="3B"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 3B</b>&nbsp; <font size=+1><b>Memory Architecture for Emerging Technologies</b></font><br>
Time: 16:00 - 17:15 Tuesday, January 14, 2020<br>
Location: Room 308<br>
Chairs: Dongsuk Jeon (Seoul National University), Xianzhang Chen (Chongqing University)
<p></p>
<a name="3B-1"></a>
3B-1
<font size=-1>(Time: 16:00 - 16:25)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">PARC: A Processing-in-CAM Architecture for Genomic Long Read Pairwise Alignment using ReRAM</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Fan Chen, Linghao Song, Hai &quot;Helen&quot; Li, Yiran Chen (Duke University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 175 - 180</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>memristor, DNA Alignment, Processing-in-Memory</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Technological advances in long read sequences have greatly facilitated the development of genomics. However, managing and analyzing the raw genomic data that outpaces Moore’s Law requires extremely high computational efficiency. On the one hand, existing software solutions can take hundreds of CPU hours to complete human genome alignment. On the other hand, the recently proposed hardware platforms achieve low processing throughput with significant overhead. In this paper, we propose PARC, an Processing-in-Memory architecture for long read pair-wise alignment leveraging emerging resistive CAM (content-addressable memory) to accelerate the bottleneck chaining step in DNA alignment. Chaining takes 2-tupleanchorsas inputs and identifies a set of correlated anchors as potential alignment candidates. Unlike traditional main memory which organizes relational data structure in a linear address space, PARC stores tuples in two neighboring crossbar arrays with shared row decoder such that column-wise in-memory computational operations and row-wise memory accesses can be performed in-situ in a symmetric crossbar structure. Compared to both software tools and state-of-the-art accelerators, PARC shows significant improvement in alignment throughput and energy efficiency, thanks to the in-site computation capability and optimized data mapping.</td></tr>
<tr><td colspan="2"><a href="../pdf/p175_3B-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="3B-2"></a>
3B-2
<font size=-1>(Time: 16:25 - 16:50)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">RRAM-VAC: A Variability-Aware Controller for RRAM-based Memory Architectures</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Shikhar Tuli, Marco Rios, Alexandre Levisse, David Atienza (Swiss Federal Institute of Technology (EPFL), Switzerland)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 181 - 186</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>RRAM, controller, variability, edge computing, WBSN</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>The growing need for connected, smart and energy efficient devices requires them to provide both ultra-low standby power and relatively high computing capabilities when awoken. In this context, emerging resistive memory technologies (RRAM) appear as a promising solution as they enable cheap fine grain technology co-integration with CMOS, fast switching and non-volatile storage. However, RRAM technologies suffer from fundamental flaws such as a strong device-to-device and cycle-to-cycle variability which is worsened by aging, forcing the designers to consider worst case design conditions. In this work, we propose, for the first time, a circuit that can take advantage of recently published Write Termination (WT) circuits from both the energy and performances point of view. The proposed RRAM Variability Aware Controller (RRAM-VAC) stores and then coalesces the write requests from the
processor before triggering the actual write process. By doing so, it averages the RRAM variability and enables the system to run at the memory programming time distribution mean rather than the worst case tail. We explore the design space of the proposed solution for various RRAM variability specifications, benchmark the effect of the proposed memory controller with real application memory traces and show (for the considered RRAM technology specifications) 44 % to 50 % performances improvement and from
10% to 85% energy gains depending on the application memory access patterns.</td></tr>
<tr><td colspan="2"><a href="../pdf/p181_3B-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="3B-3"></a>
3B-3
<font size=-1>(Time: 16:50 - 17:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Defects Mitigation in Resistive Crossbars for Analog Vector/Matrix Multiplication</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Fan Zhang, Miao Hu (Binghamton University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 187 - 192</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Resistive crossba, memristor defect, matrix multiplication</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>With storage and computation happening at the same place, computing in resistive crossbars minimizes data movement and avoids the memory bottleneck issue. It leads to ultra-high energy efficiency for data-intensive applications. However, defects in crossbars severely affect computing accuracy. Existing solutions, including re-training with defects and redundant designs, but they have limitations in practical implementations. In this work, we introduce row shuffling and output compensation to mitigate defects without re-training or redundant resistive crossbars. We also analyzed the coupling effects of defects and circuit parasitics. Moreover, We study different combinations of methods to achieve the best trade-off between cost and performance. Our proposed methods could rescue up to 10% defects in ResNet-20 application without performance degradation.</td></tr>
<tr><td colspan="2"><a href="../pdf/p187_3B-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="3C"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 3C</b>&nbsp; <font size=+1><b>Techniques for Analog Circuits and NoC</b></font><br>
Time: 16:00 - 17:15 Tuesday, January 14, 2020<br>
Location: Room 307A<br>
Chairs: Markus Olbrich (Leibniz University Hannover, Germany), Fan Yang (Fudan University, China)
<p></p>
<a name="3C-1"></a>
<font color="Maroon"><b>Best Paper Candidate</b></font><br>
3C-1
<font size=-1>(Time: 16:00 - 16:25)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">S<sup>3</sup>DET: Detecting System Symmetry Constraints for Analog Circuits with Graph Similarity</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Mingjie Liu, Wuxi Li, Keren Zhu, Biying Xu, <b><font color="Maroon" size=+1>*</font></b>Yibo Lin, Linxiao Shen, Xiyuan Tang, Nan Sun, David Z. Pan (The University of Texas at Austin, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 193 - 198</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Analog, System, Symmetry, Graph, Similarity</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Symmetry and matching between critical building blocks have a significant impact on analog system performance. However, there is limited research on generating system level symmetry constraints. In this paper, we propose a novel method of detecting system symmetry constraints for analog circuits with graph similarity. Leveraging spectral graph analysis and graph centrality, the proposed algorithm can be applied to circuits and systems of large scale and different architectures. To the best of our knowledge, this is the first work in detecting system level symmetry constraints for analog and mixed-signal (AMS) circuits. Experimental results show that the proposed method can achieve high accuracy of 88.3\% with low false alarm rate of less than 1.1\% in large-scale AMS designs.</td></tr>
<tr><td colspan="2"><a href="../pdf/p193_3C-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="3C-2"></a>
3C-2
<font size=-1>(Time: 16:25 - 16:50)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Establishing Reachset Conformance for the Formal Analysis of Analog Circuits</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Niklas Kochdumper (Technical University of Munich, Germany), Ahmad Tarraf (Goethe University Frankfurt, Germany), Malgorzata Rechmal, Markus Olbrich (Leibniz University Hannover, Germany), Lars Hedrich (Goethe University Frankfurt, Germany), Matthias Althoff (Technical University of Munich, Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 199 - 204</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>reachset conformance, hybrid systems, analog circuits, linear abstraction</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>We present the first work on the automated generation of reachset conformant models for analog circuits. Our approach applies reachset conformant synthesis to add non-determinism to piecewise-linear circuit models so that they enclose all recorded behaviors of the real system. To achieve this, we present a novel technique to compute the required non-determinism for the piecewise-linear models. The effectiveness of our approach is demonstrated on a real analog circuit. Since the resulting models enclose all measurements, they can be used for formal verification.</td></tr>
<tr><td colspan="2"><a href="../pdf/p199_3C-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="3C-3"></a>
3C-3
<font size=-1>(Time: 16:50 - 17:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Contention Minimized Bypassing in SMART NoC</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Peng Chen (Nanyang Technological University/Chongqing University, Singapore), Weichen Liu (Nanyang Technological University, Singapore), Mengquan Li (Nanyang Technological University/Chongqing University, Singapore), Lei Yang (University of Pittsburgh, USA), Nan Guan (The Hong Kong Polytechnic University, Hong Kong)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 205 - 210</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>SMART NoC, Routing Strategy, Contention Minimization</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>SMART, a recently proposed dynamically reconfigurable NoC, enables single-cycle long-distance communication by building single-bypass paths. However, such a single-cycle single-bypass path will be broken when contention occurs. Thus, lower-priority packets will be buffered at intermediate routers with blocking latency from higher-priority packets, and extra router-stage latency to rebuild remaining path, reducing the bypassing benefits that SMART offers. In this paper, we for the first time propose an effective routing strategy to achieve nearly contention-free bypassing in SMART NoC. Specifically, we identify two different routes for communication pairs: direct route, with which data can reach the destination in a single bypass; and indirect route, with which data can reach the destination in two bypasses via an intermediate router. If a direct route is not found, we would alternatively resort to an indirect route in advance to eliminate the blocking latency, at the cost of only one router-stage latency. Compared with the current routing, our new approach can effectively isolate conflicting communication pairs, greatly balance the traffic loads and fully utilize bypass paths. Experiments show that our approach makes 22.6% performance improvement on average in terms of communication latency.</td></tr>
<tr><td colspan="2"><a href="../pdf/p205_3C-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="3D"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 3D</b>&nbsp; <font size=+1><b>Advanced test, verification and fault tolerance techniques</b></font><br>
Time: 16:00 - 17:15 Tuesday, January 14, 2020<br>
Location: Room 307B<br>
Chairs: Ying Zhang (Tongji University, China), Michihiro Shintani (Nara Institute of Science and Technology, Japan)
<p></p>
<a name="3D-1"></a>
3D-1
<font size=-1>(Time: 16:00 - 16:25)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">FTT-NAS: Discovering Fault-Tolerant Neural Architecture</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Wenshuo Li, Xuefei Ning, Guangjun Ge (Tsinghua University, China), Xiaoming Chen (State Key Laboratory of Computer Architecture, Institute of Computing Technology, China), Yu Wang, Huazhong Yang (Tsinghua University, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 211 - 216</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>fault tolerance, neural architecture search</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>With the fast evolvement of deep-learning specific embedded computing systems, applications powered by deep learning are moving from the cloud to the edge. When deploying NNs onto the edge devices under complex environments, there are various types of possible faults: soft errors caused by atmospheric neutrons and radioactive impurities, voltage instability, aging, temperature variations, and malicious attackers. Thus the safety risk of deploying neural networks at edge computing devices in safety-critic applications is now drawing much attention. In this paper, we implement the random bit-flip, Gaussian, and Salt-and-Pepper fault models and establish a multi-objective fault-tolerant neural architecture search framework. On top of the NAS framework, we propose Fault-Tolerant Neural Architecture Search (FT-NAS) to automatically discover convolutional neural network (CNN) architectures that are reliable to various faults in nowadays edge devices. Then we incorporate fault- tolerant training (FTT) in the search process to achieve better results, which we called FTT-NAS. Experiments show that the discovered architecture FT-NAS-Net and FTT-NAS-Net outperform other hand-designed baseline architectures (58.1%/86.6% VS. 10.0%/52.2%), with comparable FLOPs and less parameters. What is more, the architectures trained under a single fault model can also defend against other faults. By inspecting the discovered architecture, we find that there are redundant connections learned to protect the sensitive paths. This insight can guide future fault-tolerant neural architecture design, and we verify it by a modification on ResNet-20 — ResNet-M.</td></tr>
<tr><td colspan="2"><a href="../pdf/p211_3D-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="3D-2"></a>
3D-2
<font size=-1>(Time: 16:25 - 16:50)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">The Notion of Cross Coverage in AMS Design Verification</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Sayandeep Sanyal, Aritra Hazra, <b><font color="Maroon" size=+1>*</font></b>Pallab Dasgupta (Indian Institute of Technology Kharagpur, India), Scott Morrison (Texas Instruments, USA), Sudhakar Surendran, Lakshmanan Balasubramanian (Texas Instruments (India) Pvt. Ltd., India)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 217 - 222</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Cross Coverage, AMS Coverage</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Coverage monitoring is fundamental to design verification. Coverage artifacts are well developed for digital integrated circuits and these aim to cover the discrete state space and logical behaviors of the design. Analog designers are similarly concerned with the operating regions of the design and its response to an infinite and dense input space. Analog variables can influence each other in far more complex ways as compared to digital variables, consequently, the notion of cross coverage, as introduced in the analog context for the first time in this paper, is of high importance in analog design verification. This paper presents the formal syntax and semantics of analog cross coverage artifacts, the methods for evaluating them using our tool kit, and most importantly, the insights that can be gained from such cross coverage analysis.</td></tr>
<tr><td colspan="2"><a href="../pdf/p217_3D-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="3D-3"></a>
3D-3
<font size=-1>(Time: 16:50 - 17:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Automated Test Generation for Activation of Assertions in RTL Models</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Yangdi Lyu, Prabhat Mishra (University of Florida, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 223 - 228</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Concolic Testing, RTL model, Assertions, Test Generation, Validation</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>A major challenge in assertion-based validation is how to activate the assertions to ensure that they are valid. While existing test generation using model checking is promising, it cannot generate directed tests for large designs due to state space explosion. We propose an automated and scalable mechanism to generate directed tests using a combination of symbolic execution and concrete simulation of RTL models. Experimental results show that the directed tests are able to activate assertions non-vacuously.</td></tr>
<tr><td colspan="2"><a href="../pdf/p223_3D-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<br>
<table border="2" cellspacing="0" cellpadding="5" bgcolor=#dddddd><tr><td>Wednesday, January 15, 2020</table>
<br>
<div style="position: absolute; right: 20px"><a name="3K"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 3K</b>&nbsp; <font size=+1><b>Keynote Session III</b></font><br>
Time: 9:00 - 10:00 Wednesday, January 15, 2020<br>
Location: Room 311<br>
<p></p>
<a name="3K-1"></a>
3K-1
<font size=-1>(Time: 9:00 - 10:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Keynote Address)</font> <font color="navy">Design Automation for Customizable Computing</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Jason Cong (University of California, Los Angles, USA)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>With large-scale deployment of FPGAs in both private and public clouds in the past a few years, customizable computing is transitioning from advanced research into mainstream computing.  Customized accelerators have demonstrated significant performance and energy efficiency benefits for a wide range of applications. However, efficient design and implementation of various accelerators on FPGAs remains a formidable barrier to many software programmers, despite the recent advances in high-level synthesis.  This calls for a community-wide effort to “demacratize customizable computing”.  In this talk, I shall first discuss various research opportunities associated with design automation for customizable computing. Then,  I shall highlight our recent progress on source-code level transformation and optimization for customizable computing, including support of high-level domain-specific languages (DSL) for deep learning (e.g. Caffe), imaging processing (e.g. Halide), and big-data processing (e.g. Spark), and suppoort of automated compilation to customized microarchictecture templates, such as systolic arrays, stencils, and CPPs (composable parallel and pipelined).</td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="4A"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 4A</b>&nbsp; <font size=+1><b>(DF-1): Trends in EDA</b></font><br>
Time: 10:15 - 11:30 Wednesday, January 15, 2020<br>
Location: Room 310<br>
Chair: Bei Yu (The Chinese University of Hong Kong)
<p></p>
<a name="4A-1"></a>
4A-1
<font size=-1>(Time: 10:15 - 10:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Designers' Forum)</font> <font color="navy">The Golden Age of EDA — Clock Design, Machine Learning and A-I Collaboration</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Zhuo Li (Cadence design systems, USA)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Dr. David Patterson said it is a new golden age for computer architecture at 2018 Design Automation Conference. With the booming of electronic design and systems for applications like machine learning and AI, autonomous system, 5g, cloud computing, and embedded systems, more domain specific architectures are needed. At the same time, the advancement of technology nodes takes longer and needs much more investment. It is a new golden age for EDA industry, which serves the increasing requirement of low power and high performance for both traditional and new architectures, and the pressure of time to market and design productivity. At this talk, I will focus on some new trend and challenges in clock design and synthesis, front to back synthesis and optimization integration, machine learning in EDA as well as some design challenges in ML/AI chips. Finally, I will briefly discuss the academic and industry collaboration during this new age.</td></tr>
</table>
<p></p>
<a name="4A-2"></a>
4A-2
<font size=-1>(Time: 10:40 - 11:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Designers' Forum)</font> <font color="navy">New Trend on High-Level Synthesis and Customized Compiler for Edge Intelligence</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Deming Chen (UIUC, USA)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>High-level synthesis (HLS) has gained significant traction recently for both FPGA and ASIC designs. Especially, when FPGAs are moving into cloud computing and also being developed into a commodity product, HLS would become essential to make FPGAs more accessible and programmable. Meanwhile, AI computing on the edge also represents an important future trend due to its unique advantages, including faster speed, cheaper cost, and higher level of privacy protection. Combined together, treating machine-learning as a special domain, domain-specific HLS and customized compiler to map machine learning algorithms to edge devices are important future trends as well. In this talk, we will discuss some great future opportunities in these areas and also present some challenges we need to overcome in order to facilitate the solid growth of AI solutions for various smart applications.</td></tr>
</table>
<p></p>
<a name="4A-3"></a>
4A-3
<font size=-1>(Time: 11:05 - 11:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Designers' Forum)</font> <font color="navy">Data-driven Instant Model Synthesis Enhanced by Learning Algorithms For DTCO Enablement In the FinFET Era</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Yanfeng Li (Platform Design Automation, Inc., China)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Faster and more accurate variation characterizations and instant modeling of semiconductor devices/circuits are in great demand as process technologies scale down to Fin-FET era, they are also crucial inputs for Design Technology Co-Optimization (DTCO) methodology to work . Traditional methods with intensive data testing are extremely costly, also SPICE model generations are carried out manually by engineers, which often take weeks thus become the bottleneck of DTCO in practice. In this paper, we propose for the first time, a complete eco-system with super-fast device characterization capability and instant model generation enabled by learning algorithms.</td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="4B"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 4B</b>&nbsp; <font size=+1><b>Machine-Learning and Low-Power Design</b></font><br>
Time: 10:15 - 11:30 Wednesday, January 15, 2020<br>
Location: Room 308<br>
Chairs: Cheng Zhuo (Zhejiang University, China), Hai Wang (UESTC, China)
<p></p>
<a name="4B-1"></a>
4B-1
<font size=-1>(Time: 10:15 - 10:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Machine Learning Based Online Full-Chip Heatmap Estimation</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Sheriff Sadiqbatcha, Yue Zhao, Jinwei Zhang (University of California, Riverside, USA), Hussam Amrouch, Joerg Henkel (Karlsruhe Institute of Technology, Germany), <b><font color="Maroon" size=+1>*</font></b>Sheldon X.-D. Tan (University of California, Riverside, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 229 - 234</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Thermal Model, RNN, Infrared Imaging, Online Estimation, deep learning</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Runtime power and thermal control is crucial in
any modern processor. However, these control schemes require
accurate real-time temperature information, ideally of the entire
die area, in order to be effective. On-chip temperature sensors
alone cannot provide the full-chip temperature information since
the number of sensors that are typically available is very limited
due to their high area and power overheads. Furthermore, as
we will demonstrate, the peak locations within hot-spots are
not stationary and are very workload dependent, making it
difficult to rely on fixed temperature sensors alone. Therefore,
we propose a novel approach to real-time estimation of fullchip
transient heatmaps for commercial processors based on
machine learning. The model derived in this work supplements
the temperature data sensed from the existing on-chip sensors,
allowing for the development of more robust runtime power
and thermal control schemes that can take advantage of the
additional thermal information that is otherwise not available.
The new approach involves offline acquisition of accurate spatial
and temporal heatmaps using an infrared thermal imaging
setup while nominal working conditions are maintained on the
chip. To build the dynamic thermal model, we apply Long-
Short-Term-Memory (LSTM) neutral networks with system-level
variables such as chip frequency, instruction counts, and other
performance metrics as inputs. To reduce the dimensionality of
the model, 2D spatial discrete cosine transformation (DCT) is first performed on the heatmaps so that they can be expressed with
just their dominant DCT frequencies. Our study shows that only
6x6 DCT coefficients are required to maintain sufficient accuracy
across a variety of workloads. Experimental results show that the
proposed approach can estimate the full-chip heatmaps with less
than 1.4C root-mean-square-error and take only ~19ms for each
inference which suits well for real-time use.</td></tr>
<tr><td colspan="2"><a href="../pdf/p229_4B-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="4B-2"></a>
4B-2
<font size=-1>(Time: 10:40 - 11:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">A Reconfigurable Approximate Multiplier for Quantized CNN Applications</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Chuliang Guo, Li Zhang, Xian Zhou (Zhejiang University, China), Weikang Qian (Shanghai Jiao Tong University, China), Cheng Zhuo (Zhejiang University, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 235 - 240</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Approximate Computing, Approximate Multiplier, Quantization, Neural Network, Energy Efficiency</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Quantized CNNs, featured with different bit- widths at different layers, have been widely deployed in mobile and embedded applications. The implementation of a quantized CNN may have multiple multipliers at different precisions with limited resource reuse or one multiplier at higher precision than needed causing area overhead. It is then highly desired to design a multiplier by accounting for the characteristics of quantized CNNs to ensure both flexibility and energy efficiency. In this work, we present a reconfigurable approximate multiplier to support multiplications at various precisions, i.e., bit-widths. Moreover, unlike prior works assuming uniform distribution with bit-wise independence, a quantized CNN may have centralized weight distribution and hence follow a Gaussian-like distribution with correlated adjacent bits. Thus, a new block- based approximate adder is also proposed as part of the multiplier to ensure energy efficient operation with awareness of bit-wise correlation. Our experimental results show that the proposed adder significantly reduces the error rate by 76-98% over a state-of-the-art approximate adder for such scenarios. Moreover, with the deployment of the proposed multiplier, which is 17% faster and 22% more power saving than a Xilinx multiplier IP at the same precision, a quantized CNN implemented in FPGA achieves 17% latency reduction and 15% power saving compared with a full precision case.</td></tr>
<tr><td colspan="2"><a href="../pdf/p235_4B-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="4B-3"></a>
4B-3
<font size=-1>(Time: 11:05 - 11:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">EFFORT: Enhancing Energy Efficiency and Error Resilience of a Near-Threshold Tensor Processing Unit</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Noel Daniel Gundi, Tahmoures Shabanian, Prabal Basu, Pramesh Pandey, Sanghamitra Roy, Koushik Chakraborty, Zhen Zhang (Utah State University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 241 - 246</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Low Power, Error Resilience, DNN, Accelerator</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Modern deep neural network (DNN) applications demand a remarkable processing throughput usually unmet by traditional Von Neumann architectures. Consequently, hardware accelerators, comprising a sea of multiplier and accumulate (MAC) units, have recently gained prominence in accelerating DNN inference engine. For example, Tensor Processing Units (TPU) account for a lion’s share of Google’s datacenter inference operations. The proliferation of real-time DNN predictions is accompanied with a tremendous energy budget. In quest of trimming the energy footprint of DNN accelerators, we propose EFFORT—an energy optimized, yet high performance TPU architecture, operating at the Near-Threshold Computing (NTC) region. EFFORT promotes a better-than-worst-case design by operating the NTC TPU at a substantially high frequency while keeping the voltage at the NTC nominal value. In order to tackle the timing errors due to such aggressive operation, we employ an opportunistic error mitigation strategy. Additionally, we implement an in-situ clock gating architecture, drastically reducing the MACs’ dynamic power consumption. Compared to a cutting-edge error mitigation technique for TPUs, EFFORT enables up to 2.5× better performance at NTC with only 2% average accuracy drop across 3 out of 4 DNN datasets.</td></tr>
<tr><td colspan="2"><a href="../pdf/p241_4B-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="4C"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 4C</b>&nbsp; <font size=+1><b>Cryptographic Hardware Implementation and Secure Approximate Computing</b></font><br>
Time: 10:15 - 11:30 Wednesday, January 15, 2020<br>
Location: Room 307A<br>
Chair: Weiqiang Liu (Nanjing University of Aeronautics and Astronautics, China)
<p></p>
<a name="4C-1"></a>
4C-1
<font size=-1>(Time: 10:15 - 10:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Towards Efficient Kyber on FPGAs: A Processor for Vector of Polynomials</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Zhaohui Chen (School of Computer Science and Technology, University of Chinese Academy of Sciences, China), Yuan Ma, Tianyu Chen, Jingqiang Lin (State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, China), Jiwu Jing (School of Computer Science and Technology, University of Chinese Academy of Sciences, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 247 - 252</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Post-quantum Cryptography, Security, Hardware implementation, Kyber, FPGA</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Kyber is a promising candidate in post-quantum cryptography standardization process. In this paper, we propose a targeted optimization strategy and implement a processor for Kyber on FPGAs. By merging the operations, we cut off 29.4% clock cycles for Kyber512 and 33.3% for Kyber1024 compared with the textbook implementations. We utilize Gentlemen-Sande (GS) butterfly to optimize the Number-Theoretic Transform (NTT) implementation. The bottleneck of memory access is broken taking advantage of a dual-column sequential scheme. We further propose a pipeline architecture for better performance. The optimizations help the processor achieve 31684 NTT operations per second using only 477 LUTs, 237 FFs and 1 DSP. Our strategy is at least 3x more efficient than the state-of-the-art module for NTT with a similar security level.</td></tr>
<tr><td colspan="2"><a href="../pdf/p247_4C-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="4C-2"></a>
4C-2
<font size=-1>(Time: 10:40 - 11:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Efficient Subquadratic Space Complexity Digit-Serial Multipliers over GF(2<sup>m</sup>) based on Bivariate Polynomial Basis Representation</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Chiou-Yng Lee (Lunghwa University of Science and Technology, Taiwan), <b><font color="Maroon" size=+1>*</font></b>Jiafeng Xie (Villanova University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 253 - 258</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Bivariate polynomial basis, digit-serial multiplier, Karatsuba algorithm block recombination, subquadratic space complexity, GF(2m)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Digit-serial finite field multipliers over GF(2<sup>m</sup>) with subquadratic space complexity are critical components to many applications such as elliptic curve cryptography.
In this paper, we propose a pair of novel digit-serial multipliers based on bivariate polynomial basis (BPB). Firstly, we have proposed a novel digit-serial BPB multiplication algorithm based on a new decomposition strategy. Secondly, the proposed algorithm is properly mapped into a pair of pipelined and non-pipelined digit-serial multipliers. Lastly, through the detailed complexity analysis and comparison, the proposed designs are found to have less area-time complexities than the competing ones.</td></tr>
<tr><td colspan="2"><a href="../pdf/p253_4C-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="4C-3"></a>
4C-3
<font size=-1>(Time: 11:05 - 11:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Security Threats and Countermeasures for Approximate Arithmetic Computing</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Pruthvy Yellu, Mezanur Rahman Monjur, Timothy Kammerer, Dongpeng Xu, Qiaoyan Yu (University of New Hampshire, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 259 - 264</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Approximate computing, security, Hardware Trojan, ANN, attack model</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Approximate computing (AC) emerges as a promising approach for energy-accuracy trade-off in compute-intensive applications.However, recent work reveals that AC techniques could lead to new security vulnerabilities, which are presented in a format of visionary view. There is a lack of in-depth research on concrete attack models and estimation of the significance of the attacks on approximate arithmetic computing systems. This work presents several practical attack examples and then proposes two attack models with quantitative analysis. Input integrity check and exclusive logic based attack detection methods are proposed to address the attacks on AC systems. The experimental results show that the attack detection failure rate of our method is below2.2&#8727;10&#8722;3 and the area and power overhead is less than 6.8% and 1.5%, respectively.</td></tr>
<tr><td colspan="2"><a href="../pdf/p259_4C-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="4D"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 4D</b>&nbsp; <font size=+1><b>Emerging Embedded Systems Architecture</b></font><br>
Time: 10:15 - 11:30 Wednesday, January 15, 2020<br>
Location: Room 307B<br>
<p></p>
<a name="4D-1"></a>
4D-1
<font size=-1>(Time: 10:15 - 10:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Broadcast Mechanism Based on Hybrid Wireless/Wired NoC for Efficient Barrier Synchronization in Parallel Computing</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Hemanta Kumar Mondal (National Institute of Technology Durgapur, India), <b><font color="Maroon" size=+1>*</font></b>Navonil Chatterjee, Rodrigo Cataldo, Jean-Philippe Diguet (Université de Bretagne Sud, France)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 265 - 270</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>NoC, Wireless, Broadcast, Parallel Computing, Barrier</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Parallel computing is essential to achieve the manycore architecture performance potential, since it utilizes the parallel nature provided by the hardware for its computing. These applications will inevitably have to synchronize its parallel execution: for instance, broadcast operations for barrier synchronization. Conventional network-on-chip architectures for broadcast operations limit the performance as the synchronization is affected significantly due to the critical path communications that increase the network latency and degrade the performance drastically. A Wireless network-on-chip offers a promising solution to reduce the critical path communication bottlenecks of such conventional architectures by providing hardware broadcast support. We propose efficient barrier synchronization support using hybrid wireless/wired NoC to reduce the cost of broadcast operations. The proposed architecture reduces the barrier synchronization cost up to 42.79% regarding network latency and saves up to 42.65% communication energy consumption for a subset of applications from the PARSEC benchmark.</td></tr>
<tr><td colspan="2"><a href="../pdf/p265_4D-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="4D-2"></a>
4D-2
<font size=-1>(Time: 10:40 - 11:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">A Generic FPGA Accelerator for Minimum Storage Regenerating Codes</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Mian Qin (Texas A&amp;M University, USA), Joo Hwan Lee, Rekha Pitchumani, Yang Seok Ki (Samsung Semiconductor Inc., USA), Narasimha Reddy, <b><font color="Maroon" size=+1>*</font></b>Paul V. Gratz (Texas A&amp;M University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 271 - 276</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Erasure codes, Minimum Storage Regenerating Codes, FPGA, accelerator</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Erasure coding is widely used in storage systems
to achieve fault tolerance while minimizing the storage over-
head. Recently, Minimum Storage Regenerating (MSR) codes
are emerging to minimize repair bandwidth while maintaining
the storage ef&#64257;ciency. Traditionally, erasure coding is imple-
mented in the storage software stacks, which hinders normal
operations and blocks resources that could be serving other
user needs due to poor cache performance and costs high
CPU and memory utilizations. In this paper, we propose a
generic FPGA accelerator for MSR codes encoding/decoding
which maximizes the computation parallelism and minimizes
the data movement between off-chip DRAM and the on-chip
SRAM buffers. To demonstrate the ef&#64257;ciency of our proposed
accelerator, we implemented the encoding/decoding algorithms
for a speci&#64257;c MSR code called Zigzag code on Xilinx VCU1525
acceleration card. Our evaluation shows our proposed accelerator
can achieve &#8764;2.4-3.1x better throughput and &#8764;4.2-5.7x better
power ef&#64257;ciency compared to the state-of-art multi-core CPU
implementation and &#8764;2.8-3.3x better throughput and &#8764;4.2-5.3x
better power ef&#64257;ciency compared to a modern GPU accelerator.</td></tr>
<tr><td colspan="2"><a href="../pdf/p271_4D-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="4D-3"></a>
4D-3
<font size=-1>(Time: 11:05 - 11:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Parallel-Log-Single-Compaction-Tree: Flash-Friendly Two-Level Key-Value Management in KVSSDs</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Yen-Ting Chen (Department of Computer Science, National Tsing Hua University, Taiwan), Ming-Chang Yang (The Chinese University of Hong Kong, Hong Kong), Yuan-Hao Chang (Institute of Information Science, Academia Sinica, Taiwan), Wei-Kuan Shih (Department of Computer Science, National Tsing Hua University, Taiwan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 277 - 282</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>key-value, flash storage system, LSM-tree, performance</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Log-Structured Merge-Trees (LSM-trees) based key-value store applications have gained popularity due to their high write performance. To further pursue better performance for key-value applications, various researches were conducted by adopting or proposing different architecture of flash devices, such as key-value solid-state drive (KVSSD). However, since LSM-trees are originally designed based on the architecture of hard disk drives (HDDs), true potential of SSDs can not be well exploited without re-designing the management strategy. In this work, we propose Parallel-Log-Single-Compaction-Tree (PLSC-tree), which is a two-level and flash-friendly key-value management strategy specially tailored for KVSSDs. In particular, the first layer takes advantage of the massive internal parallelism of SSDs for maximizing the write performance via logging, while the second layer is designed to alleviate the internal recycling (i.e., compaction) overheads of flash device for ultimately optimizing the performance on managing key-value pairs. A series of experiments were conducted based on a well-known SSD simulator with realistic workloads, and the results are very encouraging.</td></tr>
<tr><td colspan="2"><a href="../pdf/p277_4D-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="4K"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 4K</b>&nbsp; <font size=+1><b>Keynote Session IV</b></font><br>
Time: 11:30 - 12:10 Wednesday, January 15, 2020<br>
Location: Room 311<br>
<p></p>
<a name="4K-1"></a>
4K-1
<font size=-1>(Time: 11:30 - 12:10)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Keynote Address)</font> <font color="navy">Huge Development of RISC-V Arising from IOT Spurt</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Yingwu Zhang (GigaDevice, China)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>With the huge demand of IoT, wearable device, AI, automotive, intelligent manufacturing and new emerging applications, which offers MCU greater opportunities as well as more challenges. We should find the optimized solutions and technologies for these obstacles in different scenarios, such as larger data processing and faster processing speed in automotive, ultra-low power in wearable and IoT, interconnection and data reliability and post Moore Era.

As a leading company in 32-bit general MCU market, GigaDevice provided the low power, connectivity, security design in both ARM and RISC-V MCUs. In this speech, we will unveil our RISC-V core solutions and advantage design techniques, like modular design, user extension instructions and ecological development and active community, and the security design focus on code protection, data encryption, safe downloading, security boot and reliability design.</td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="5A"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 5A</b>&nbsp; <font size=+1><b>Architecture and Algorithm for Deep Neural Networks</b></font><br>
Time: 13:50 - 15:30 Wednesday, January 15, 2020<br>
Location: Room 310<br>
Chair: Deming Chen (UIUC)
<p></p>
<a name="5A-1"></a>
<font color="Maroon"><b>Best Paper Candidate</b></font><br>
5A-1
<font size=-1>(Time: 13:50 - 14:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Towards Design Methodology of Efficient Fast Algorithms for Accelerating Generative Adversarial Networks on FPGAs</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Jung-Woo Chang, <b><font color="Maroon" size=+1>*</font></b>Saehyun Ahn, Keon-Woo Kang, Suk-Ju Kang (Sogang University, Republic of Korea)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 283 - 288</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Deep learning, Generative adversarial networks, FPGA, CNN, Accelerator</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>In this paper, we propose an efficient Winograd DeConv accelerator that combines these two orthogonal approaches on FPGAs. Firstly, we introduce a new class of fast algorithm for DeConv layers using Winograd minimal filtering. Since there are regular sparse patterns in Winograd filters, we further amortize the computational complexity by skipping zero weights. Secondly, we propose a new dataflow to prevent resource underutilization by reorganizing the filter layout in Winograd DeConv. Finally, we propose an efficient architecture for Winograd DeConv by designing the line buffer and exploring the design space. Experimental results on various GANs show that our accelerator achieves up to 1.78× ~ 8.38× speedup over the state-of-the-art DeConv accelerators.</td></tr>
<tr><td colspan="2"><a href="../pdf/p283_5A-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="5A-2"></a>
5A-2
<font size=-1>(Time: 14:15 - 14:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Designing Efficient Shortcut Architecture for Improving the Accuracy of Fully Quantized Neural Networks Accelerator</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Baoting Li, Longjun Liu, Yanming Jin, Peng Gao, Hongbin Sun, Nanning Zheng (Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 289 - 294</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>DNN, Quantization, Shortcut, Hardware architecture, Accelerator</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Network quantization is an effective solution to compress Deep Neural Networks (DNN) that can be accelerated with custom circuit. However, existing quantization methods suffer from significant loss in accuracy. In this paper, we propose an efficient shortcut architecture to enhance the representational capability of DNN between different convolution layers. We further implement the shortcut hardware architecture to effectively improve the accuracy of fully quantized neural networks accelerator. The experimental results show that our shortcut architecture can obviously improve network accuracy while increasing very few hardware resources (0.11× and 0.17× for LUT and FF respectively) compared with the whole accelerator.</td></tr>
<tr><td colspan="2"><a href="../pdf/p289_5A-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="5A-3"></a>
5A-3
<font size=-1>(Time: 14:40 - 15:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">CRANIA: Unlocking Data and Value Reuse in Iterative Neural Network Architectures</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Maedeh Hemmat, <b><font color="Maroon" size=+1>*</font></b>Tejas Shah, Yuhua Chen, Joshua San Miguel (University of Wisconsin  Madison, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 295 - 300</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>iterative neural network architectures, temporal and spatial locality, input-dependent networks</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>A common inefficiency in traditional Convolutional Neural Network (CNN) architectures is that they do not adapt to variations in inputs.
Not all inputs require the same amount of computation to be correctly classified, and not all of the weights in the network contribute equally to generate the output.
Recent work introduces the concept of iterative inference, enabling per-input approximation.
Such an iterative CNN architecture clusters weights based on their importance and saves significant power by incrementally fetching weights from off-chip memory until the classification result is accurate enough.
Unfortunately, this comes at a cost of increased execution time since some inputs need to go through multiple rounds of inference, negating the savings in energy. 
We propose Cache Reuse Approximation for Neural Iterative Architectures (CRANIA) to overcome this inefficiency.
We recognize that the re-execution and clustering built into these iterative CNN architectures unlock significant temporal data reuse and spatial value reuse, respectively.
CRANIA introduces a lightweight cache+compression architecture customized to the iterative clustering algorithm, enabling up to 9x energy savings and speeding up inference by 5.8x with only 0.3% area overhead.</td></tr>
<tr><td colspan="2"><a href="../pdf/p295_5A-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="5A-4"></a>
5A-4
<font size=-1>(Time: 15:05 - 15:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Tiny but Accurate: A Pruned, Quantized and Optimized Memristor Crossbar Framework for Ultra Efficient DNN Implementation</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Xiaolong Ma, Geng Yuan, <b><font color="Maroon" size=+1>*</font></b>Sheng Lin (Northeastern University, USA), Caiwen Ding (University of Connecticut, USA), Fuxun Yu (George Mason University, USA), Tao Liu (Florida International University, USA), Wujie Wen (Lehigh University, USA), Xiang Chen (George Mason University, USA), Yanzhi Wang (Northeastern University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 301 - 306</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>DNN, Memristor, Pruning, Quantization</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>The memristor crossbar array has emerged as an intrinsically suitable matrix computation and low-power acceleration framework for DNN applications. Many techniques such as memristor-based weight pruning and memristor-based quantization have been studied. However, the high accuracy solution for the above techniques is still waiting for unraveling. In this paper, we propose a memristor-based DNN framework which combines both structured weight pruning and quantization by incorporating alternating direction method of multipliers (ADMM) algorithm for better pruning and quantization performance. We also discover the non-optimality of the ADMM solution in weight pruning and the unused data path in a structured pruned model. Motivated by these discoveries, we design a software-hardware co-optimization framework which contains the first proposed Network Purification and Unused Path Removal algorithms targeting on post-processing a structured pruned model after ADMM steps. By taking memristor hardware constraints into our whole framework, we achieve extreme high compression rate on the state-of-art neural network structures with minimum accuracy loss. For quantizing structured pruned model, our framework achieves nearly no accuracy loss after quantizing weights to 8-bit memristor weight representation. We share our models at anonymous link https://bit.ly/2VnMUy0.</td></tr>
<tr><td colspan="2"><a href="../pdf/p301_5A-4.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="5B"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 5B</b>&nbsp; <font size=+1><b>Advanced Memory Systems</b></font><br>
Time: 13:50 - 15:30 Wednesday, January 15, 2020<br>
Location: Room 308<br>
Chairs: Ing-Chao Lin (National Cheng Kung University), Guangyu Sun (Peking University)
<p></p>
<a name="5B-1"></a>
<font color="Maroon"><b>Best Paper Candidate</b></font><br>
5B-1
<font size=-1>(Time: 13:50 - 14:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Towards Read-Intensive Key-Value Stores with Tidal Structure Based on LSM-Tree</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Yi Wang, Shangyu Wu, Rui Mao (Shenzhen University, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 307 - 312</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Storage system, key-value store, LSM-tree, read amplifications, write amplifications</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Key-value store has played a critical role in many large-scale data storage applications. The log-structured merge-tree (LSM-tree) based key-value store achieves excellent performance on write-intensive workloads which is mainly benefited from the mechanism of converting a batch of random writes into sequential writes. However, LSM-tree doesn't improve a lot in read-intensive workloads which takes a higher latency. The main reason lies in the hierarchical search mechanism in LSM-tree structure. The key challenge is how to propose new strategies based on the existing LSM-tree structure to improve read efficiency and reduce read amplifications.

This paper proposes Tidal-tree, a novel data structure where data flows inside LSM-tree like Tidal waves. Tidal-tree targets at improving read efficiency in read-intensive workloads. Tidal-tree allows frequently accessed files at the bottom of LSM-tree to move to higher positions, thereby reducing read latency. Tidal-tree also makes LSM-tree into a variable shape to cater for different characteristic workloads. To evaluate the performance of Tidal-tree, we conduct a series of experiments using standard benchmarks from YCSB. The experimental results show that Tidal-tree can significantly improve read efficiency and reduce read amplifications compared with representative schemes.</td></tr>
<tr><td colspan="2"><a href="../pdf/p307_5B-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="5B-2"></a>
5B-2
<font size=-1>(Time: 14:15 - 14:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">A Flexible Processing-in-Memory Accelerator for Dynamic Channel-Adaptive Deep Neural Networks</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Li Yang (Arizona State University, USA), Shaahin Angizi (University of Central Florida, USA), <b><font color="Maroon" size=+1>*</font></b>Deliang Fan (Arizona State University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 313 - 318</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Deep neural network, Processing in memory</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>With the success of deep neural networks (DNN), many recent works have been focusing on developing hardware accelerator for power and resource-limited embedded system via model compression techniques, such as quantization, pruning, low-rank approximation, etc. However, almost all existing DNN structure is fixed after deployment, which lacks runtime adaptive DNN structure to adapt to its dynamic hardware resource, power budget, throughput requirement, as well as dynamic workload. Correspondingly, there is no runtime adaptive hardware platform to support dynamic DNN structure.To address this problem, we first propose a dynamic channel-adaptive deep neural network (CA-DNN) which can adjust the involved convolution channel (i.e. model size, computing load) at run-time (i.e. at inference stage without retraining) to dynamically trade off between power, speed, computing load and accuracy. Further, we utilize knowledge distillation method to optimize the model and quantize the model to 8-bits and 16-bits, respectively, for hardware friendly mapping. We test the proposed model on CIFAR-10 and ImageNet dataset by using ResNet. Comparing with the same model size of individual model, our CA-DNN achieves better accuracy. Moreover, as far as we know, we are the first to propose a Processing-in-Memory accelerator for such adaptive neural networks structure based on Spin Orbit Torque Magnetic Random Access Memory(SOT-MRAM) computational adaptive sub-arrays. Then, we comprehensively analyze the trade-off of the model with different channel-width between the accuracy and the hardware parameters, eg., energy, memory, and area overhead.</td></tr>
<tr><td colspan="2"><a href="../pdf/p313_5B-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="5B-3"></a>
5B-3
<font size=-1>(Time: 14:40 - 15:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Workload-aware Data-eviction Self-adjusting System of Multi-SCM Storage to Resolve Trade-off between SCM Data-retention Error and Storage System Performance</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Reika Kinoshita, Chihiro Matsui, Atsuya Suzuki, Shouhei Fukuyama, Ken Takeuchi (Chuo University, Japan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 319 - 324</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Storage Class Memory, ReRAM, Data-retention, Data management technique</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Workload-aware data-eviction self-adjusting system is proposed to resolve trade-off between data-retention reliability and system performance of Multi-SCM (storage class memory) storage that uses M-SCM (memory-type SCM) as NV (non-volatile) cache. M-SCM such as MRAM may cause data-retention errors at high temperatures. Therefore, data in M-SCM should be evicted to storage at short interval, but frequent data eviction severely degrades system performance. Proposals adjust data-eviction interval, and improve data-retention reliability and system performance by up to 79% and 5.9 times, respectively.</td></tr>
<tr><td colspan="2"><a href="../pdf/p319_5B-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="5B-4"></a>
5B-4
<font size=-1>(Time: 15:05 - 15:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">An Energy-Efficient Quantized and Regularized Training Framework For Processing-In-Memory Accelerators</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Hanbo Sun, Zhenhua Zhu, Yi Cai (Tsinghua University, China), Xiaoming Chen (Chinese Academy of Sciences, China), Yu Wang, Huazhong Yang (Tsinghua University, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 325 - 330</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Energy-Efficient, Quantized, Regularized, Processing-In-Memory Accelerators</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Convolutional Neural Networks (CNNs) have madebreakthroughs  in  various  fields,  while  the  energy  consumptionbecomes  enormous.  Processing-In-Memory  (PIM)  architecturesbased on emerging non-volatile memory (e.g., Resistive RandomAccess  Memory,  RRAM)  have  demonstrated  great  potential  inimproving  the  energy  efficiency  of  CNN  computing.  However,there is still much room for improvement in the energy efficiencyof  existing  PIM  architectures.  On  the  one  hand,  current  workshows that high resolution Analog-to-Digital Converters (ADCs)are   required   for   maintaining   computing   accuracy,   but   theydominate  more  than60%energy  consumption  of  the  entiresystem,  damaging  the  energy  efficiency  benefits  of  PIM.  On  theother hand, the characteristic of computing in the analog domainin PIM accelerators leads to the computing energy consumptionis influenced by the specific input and weight values. However, asfar as we know, there is no energy efficiency optimization methodbased  on  this  characteristic  in  existing  work.  To  solve  theseproblems, in this paper, we propose an energy-efficient quantizedand regularized training framework for PIM accelerators, whichconsists  of  a  PIM-based  non-uniform  activation  quantizationscheme and an energy-aware weight regularization method. Theproposed  framework  can  improve  the  energy  efficiency  of  PIMarchitectures by reducing the ADC resolution requirements andtraining low energy consumption CNN models for PIM, with littleaccuracy  loss.  The  experimental  results  show  that  the  proposedtraining framework can reduce the resolution of ADCs by2bitsand the computing energy consumption in the analog domain by35%. The energy efficiency, therefore, can be enhanced by3.4×in  our  proposed  training  framework.</td></tr>
<tr><td colspan="2"><a href="../pdf/p325_5B-4.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="5C"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 5C</b>&nbsp; <font size=+1><b>Advances in Physical Design</b></font><br>
Time: 13:50 - 15:30 Wednesday, January 15, 2020<br>
Location: Room 307A<br>
Chairs: Jiang Hu (TAMU), Jianli Chen (Fuzhou University)
<p></p>
<a name="5C-1"></a>
<font color="Maroon"><b>Best Paper Candidate</b></font><br>
5C-1
<font size=-1>(Time: 13:50 - 14:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Unified Redistribution Layer Routing for 2.5D IC Packages</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Chun-Han Chiang, <b><font color="Maroon" size=+1>*</font></b>Fu-Yu Chuang, Yao-Wen Chang (National Taiwan University, Taiwan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 331 - 337</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Redistribution Layer Routing, Package Routing, Bipartite Matching, Modulus-based Matrix Splitting Iteration Method</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>A 2.5-dimensional integrated circuit, which introduces an interposer as an interface between chips and a package, is one of the most popular integration technologies. Multiple chips can be mounted on an interposer, and inter-chip nets are routed on redistribution layers (RDLs). In traditional designs, the wire widths and spacings are uniform (i.e., grid-based). To improve circuit performance in modern designs, however, variable widths and spacings are also often adopted (i.e., gridless designs). In this paper, we propose the first unified routing framework that can handle both grid-based and gridless routing on RDLs based on the modulus-based matrix splitting iteration method (MMSIM) and bipartite matching. The MMSIM-based method assigns each wire a rough position while considering multiple design rules, and bipartite matching is applied to further refine those positions. We also prove the optimality of our RDL routing framework for grid-based designs and validate it empirically. Experimental results show that our framework can solve all the gridless and grid-based designs provided by industry effectively and efficiently. In particular, our framework is general and readily extends to other routing (and some quadratic optimization) problems.</td></tr>
<tr><td colspan="2"><a href="../pdf/p331_5C-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="5C-2"></a>
5C-2
<font size=-1>(Time: 14:15 - 14:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">AIR: A Fast but Lazy Timing-Driven FPGA Router</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Kevin E. Murray, Shen Zhong, Vaughn Betz (University of Toronto, Canada)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 338 - 344</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>FPGA, Routing</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Routing is a key step in the FPGA design process, which significantly impacts design implementation quality. Routing is also very time-consuming, and can scale poorly to very large designs. This paper describes the Adaptive Incremental Router (AIR), a high-performance timing-driven FPGA router. AIR dynamically adapts to the routing problem, which it solves ‘lazily’ to minimize work. Compared to the widely used VPR 7 router, AIR significantly reduces route-time (7.1x faster), while also improving quality (15% wirelength, and 18% critical path delay reductions). We also show how these techniques enable efficient incremental improvement of existing routing.</td></tr>
<tr><td colspan="2"><a href="../pdf/p338_5C-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="5C-3"></a>
5C-3
<font size=-1>(Time: 14:40 - 15:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">SP&amp;R: Simultaneous Placement and Routing Framework for Standard Cell Synthesis in Sub-7nm</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Dongwon Park, <b><font color="Maroon" size=+1>*</font></b>Daeyeal Lee (University of California, San Diego, USA), Ilgweon Kang (Cadence, USA), Sicun Gao, Bill Lin, Chung-Kuan Cheng (University of California, San Diego, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 345 - 350</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Standard Cell, Synthesis, SMT, Placement, Routing</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Standard cell synthesis requires careful engineering approaches to ensure routability across various digital IC designs since physical design for sub-7nm technology nodes demands holistic efforts to address urgent and nontrivial design challenges. Many conventional approaches have been suggested for improving transistor-level P&R and pin accessibility, nonetheless insufficient because of the heuristic/divide-and-conquer manners.
In this paper, we propose a novel framework, which simultaneously solves P&R for designing standard cell’s layout without deploying any sequential procedures by using dynamic pin allocation-based cell synthesis.The proposed SP&R utilizes the Optimization Modulo Theories (OMT), an extension of the Satisfiability modulo theories (SMT), to obtain optimal standard cell layout by virtue of SAT (Boolean Satisfiability)-based fast reasoning ability. We validate that our SP&R framework achieves 10.5% of reduction on average in terms of metal length compared to the sequential approach, through practical standard cell designs targeting sub-7nm technology nodes.</td></tr>
<tr><td colspan="2"><a href="../pdf/p345_5C-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="5C-4"></a>
5C-4
<font size=-1>(Time: 15:05 - 15:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Chiplet-Package Co-Design For 2.5D Systems Using Standard ASIC CAD Tools</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>MD Arafat Kabir, <b><font color="Maroon" size=+1>*</font></b>Yarui Peng (University of Arkansas, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 351 - 356</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>2.5D Design, Chip-Package co-design, Redistribution Layer Planning, Package Design</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Chiplet integration using 2.5D packaging is gaining popularity nowadays which enables several interesting features like heterogeneous integration and drop-in design method. In the traditional die-by-die approach of designing a 2.5D system, each chiplet is designed independently without any knowledge of the package RDLs. In this paper, we propose a Chip-Package Co-Design flow for implementing 2.5D systems using existing commercial chip design tools. Our flow encompasses 2.5D-aware partitioning suitable for SoC design, Chip-Package Floorplanning, and post-design analysis and verification of the entire 2.5D system. We also designed our own package planners to route RDL layers on top of chiplet layers. We use an ARM Cortex-M0 SoC system to illustrate our flow and compare analysis results with a monolithic 2D implementation of the same system. We also compare two different 2.5D implementations of the same SoC system following the drop-in approach. Alongside the traditional die-by-die approach, our holistic flow enables design efficiency and flexibility with accurate cross-boundary parasitic extraction and design verification.</td></tr>
<tr><td colspan="2"><a href="../pdf/p351_5C-4.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="5D"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 5D</b>&nbsp; <font size=+1><b>System Simulation and Exploration</b></font><br>
Time: 13:50 - 15:30 Wednesday, January 15, 2020<br>
Location: Room 307B<br>
Chairs: Weichen Liu (Nanyang Technological University, Singapore), Eric Liang (Peking University, China)
<p></p>
<a name="5D-1"></a>
5D-1
<font size=-1>(Time: 13:50 - 14:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Event Delivery using Prediction for Faster Parallel SystemC Simulation</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Zhongqi Cheng, Emad Arasteh, Rainer Dömer (University of California, Irvine, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 357 - 362</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>SystemC, PDES, Simulation, Event</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Out-of-order Parallel Discrete Event Simulation (OoO PDES) is an advanced simulation approach that efficiently verifies and validates SystemC models. To preserve the simulation semantics, OoO PDES performs a conservative event delivery strategy which often postpones the execution of waiting threads due to unknown future behaviors of the model. In this paper, based on predicted behaviors of threads, we introduce a novel event delivery strategy that allows waiting threads to resume execution earlier, resulting in significantly increased simulation speed. Experimental results show that the proposed approach increases the OoO PDES simulation speed by up to 4.9x compared to the original one on a 4-core machine.</td></tr>
<tr><td colspan="2"><a href="../pdf/p357_5D-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="5D-2"></a>
5D-2
<font size=-1>(Time: 14:15 - 14:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Standard-compliant Parallel SystemC simulation of Loosely-Timed Transaction Level Models</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Gabriel Busnot, Tanguy Sassolas, Nicolas Ventroux (CEA, LIST, Computing and Design Environment Laboratory, France), Matthieu Moy (Univ Lyon, EnsL, UCBL, CNRS, Inria, LIP, France)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 363 - 368</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Parallel SystemC, Simulation, TLM</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>To face the growing complexity of System-on-Chips (SoCs) and their tight time-tomarket constraints, Virtual Prototyping (VP) tools based on SystemC/TLM must get faster while keeping accuracy. However, the Accellera SystemC reference implementation remains sequential and cannot leverage the multiple cores of modern workstations. In this paper, we present a new implementation of a parallel and standard-compliant SystemC kernel, reaching unprecedented performances. By coupling a parallel SystemC kernel and memory access monitoring, we are able to keep SystemC atomic thread evaluation while leveraging the available host cores. Evaluations show a ×19 speed-up compared to the Accellera SystemC kernel using 33 host cores reaching speeds above 2000 Million simulated Instructions Per Second (MIPS).</td></tr>
<tr><td colspan="2"><a href="../pdf/p363_5D-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="5D-3"></a>
5D-3
<font size=-1>(Time: 14:40 - 15:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">JIT-Based Context-Sensitive Timing Simulation for Efficient Platform Exploration</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Alessandro Cornaglia, Md Shakib Hasan, Alexander Viehl (FZI Research Center for Information Technology, Germany), Oliver Bringmann, Wolfgang Rosenstiel (University of Tübingen, Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 369 - 374</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Software Timing Simulation, Embedded Systems, Hardware-Related Software, Early Design Exploration of Heterogeneous Platforms, Compiler optimizations effects</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Fast and accurate predictions of a program’s execution time are essential during the design space exploration of embedded systems. In this paper, we present a novel approach for efficient context-sensitive timing simulations based on the LLVM IR code representation. Our approach allows evaluating simultaneously multiple hardware platform configurations with only one simulation run. State-of-the-art solutions are improved by speeding up the simulation throughput relying on the fast LLVM IR JIT execution engine. Results show on average over 94% prediction accuracy and a speedup of 200 times compared to interpretive simulations. The simulation performance reaches up to 300 MIPS when one HW configuration is assessed and it grows up to 1 GIPS evaluating four configurations in parallel. Additionally, we show that our approach can be utilized for producing early timing estimations that support the designers in mapping a system to heterogeneous hardware platforms.</td></tr>
<tr><td colspan="2"><a href="../pdf/p369_5D-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="5D-4"></a>
5D-4
<font size=-1>(Time: 15:05 - 15:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Towards Automatic Hardware Synthesis from Formal Specification to Implementation</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Fritjof Bornebusch, Christoph Lüth (German Research Center for Artificial Intelligence (DFKI), Germany), Robert Wille (Johannes Kepler University Linz, Austria), Rolf Drechsler (University of Bremen, Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 375 - 380</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>hardware synthesis, formal verification, functional hardware description</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>In this work, we sketch an automated design flow for hardware
  synthesis based on a formal specification. Verification results are propagated from the FSL
  level through the proposed flow to generate an ESL model as well as an RTL implementation
  automatically. In contrast, the established design flow relies on manual implementations
  at the ESL and RTL level. The proposed design flow combines proof assistants with
  functional hardware description languages. This combination decreases the implementation
  effort significantly and the generation of testbenches is no longer needed.
  We illustrate our design flow by specifying and synthesizing a set of benchmarks that contain
  sequential and combinational hardware designs. We compare them with implementations required
  by the established hardware design flow.</td></tr>
<tr><td colspan="2"><a href="../pdf/p375_5D-4.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="6A"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 6A</b>&nbsp; <font size=+1><b>(SS-2): Computation-in-Memory based on emerging non-volatile memories: Technology, design, and test and reliability</b></font><br>
Time: 15:45 - 17:00 Wednesday, January 15, 2020<br>
Location: Room 310<br>
Chair: Mehdi Tahoori (Faculty of Informatik, Karlsruhe Institute of Technology (KIT), Germany)
<p></p>
<a name="6A-1"></a>
6A-1
<font size=-1>(Time: 15:45 - 16:10)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Emerging Non-Volatile Memories for Computation-in-Memory</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Bin Gao (Tsinghua University, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 381 - 384</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>NVM, CIM, RRAM</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>This talk will introduce the principles of different emerging NVM devices. The device structures, working mechanisms, as well as typical performance of these devices will be discussed. Then different approaches of CIM based on emerging NVM will be presented, specially focus on matrix-vector-multiplication. Later, the talk will summary the performance requirements and key challenges on the device level to realize the CIM. Finally, this work will provide some possible research directions in the future development on emerging NVM for CIM applications.</td></tr>
<tr><td colspan="2"><a href="../pdf/p381_6A-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="6A-2"></a>
6A-2
<font size=-1>(Time: 16:10 - 16:35)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">The Power of Computation-in-Memory Based on Memristive Devices</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Jintao Yu, Muath Abu Lebdeh, Hoang Anh Du Nguyen, Mottaqiallah Taouil, Said Hamdioui (Delft University of Technology, Netherlands)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 385 - 392</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Computation-in-Memory, Memristive Devices, Classification</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Conventional computing architectures and the CMOS technology that they are based on are facing major challenges such as the memory bottleneck making the memory access for data transfer a major killer of energy and performance. Computation-in-memory (CIM) paradigm is seen as a potential alternative that could alleviate such problems by adding computational resources to the memory, and significantly reducing the communication. Memristive devices are promising enablers of a such CIM paradigm, as they are able to support both storage and computing. This paper shows the power of memristive device based CIM paradigm in enabling new efficient application-specific architectures as well as efficient implementations of some known domain-specific architectures. In addition, the paper discusses the potential applications that could benefit from such paradigm and highlights the major challenges.</td></tr>
<tr><td colspan="2"><a href="../pdf/p385_6A-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="6A-3"></a>
6A-3
<font size=-1>(Time: 16:35 - 17:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Tolerating Retention Failures in Neuromorphic Fabric based on Emerging Resistive Memories</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Christopher Münch (Karlsruhe Institute of Technology, Germany), Rajendra Bishnoi (Delft University of Technology, Netherlands), <b><font color="Maroon" size=+1>*</font></b>Mehdi B. Tahoori (Karlsruhe Institute of Technology, Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 393 - 400</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>BNN, MTJ, retention</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>In this paper, we evaluate the retention
issues of emerging resistive memories used as non-volatile weight
storage for embedded NN. We exploit the asymmetric retention
behavior of Spintronic based Magnetic Tunneling Junctions
(MTJs), which is also present in other resistive memories like
Phase-Change memory (PCM) and ReRAM, to optimize the
retention of the NN accuracy over time. We propose mixed
retention cell arrays and an adapted training scheme to achieve a
trade-off between array size and the reliable long-term accuracy
of NNs. The results of our proposed method save up to 24% of
inference accuracy of an MNIST trained Multi-Layer-Perceptron
on MTJ-based crossbars.</td></tr>
<tr><td colspan="2"><a href="../pdf/p393_6A-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="6B"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 6B</b>&nbsp; <font size=+1><b>(SS-3): Emerging Memory Enabled Computing in The Post-Moore’s Era</b></font><br>
Time: 15:45 - 17:25 Wednesday, January 15, 2020<br>
Location: Room 308<br>
Chair: Xueqing Li (Tsinghua University, China)
<p></p>
<a name="6B-1"></a>
6B-1
<font size=-1>(Time: 15:45 - 16:10)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Ferroelectrics: From Memory to Computing</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Kai Ni (Rochester Institute of Technology, USA), Sourav Dutta, Suman Datta (University of Notre Dame, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 401 - 406</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Ferroelectric, Nonvolatile Memory, Synaptic Weight Cell, In-Memory Computing, Neuron</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Research discovery of ferroelectricity in HfO2 thin films has ignited tremendous activity in exploration of ferroelectric FETs for a range of applications from low-power logic to embedded non-volatile memory to in-memory compute kernels. In this paper, key milestones in the evolution of Ferroelectric Field Effect Transistors (FeFETs) and the emergence of a versatile ferroelectronic platform are presented. From all these developments, ferroelectric emerges as a highly promising platform for various exciting applications.</td></tr>
<tr><td colspan="2"><a href="../pdf/p401_6B-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="6B-2"></a>
6B-2
<font size=-1>(Time: 16:10 - 16:35)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Adaptive Circuit Approaches to Low-Power Multi-Level/Cell FeFET Memory</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Juejian Wu, Yixin Xu, Bowen Xue, Yu Wang, Yongpan Liu, Huazhong Yang, <b><font color="Maroon" size=+1>*</font></b>Xueqing Li (The Department of Electronic Engineering, Tsinghua University, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 407 - 413</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Nonvolatile Memory, Multi-Level-Cell, Ferroelectric FET, Adaptive MLC Approaches, Computing-in-Memory</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Ferroelectric FETs (FeFETs) have emerged as a promising multi-level/cell (MLC) nonvolatile memory (NVM) candidate for low-power applications. This originates from the advantages of both efficient memory access and intrinsic device-level in-memory computing flexibilities. However, there still exist challenges for FeFET MLC NVM: (i) high power consumption in read operations due to high-gain requirement for sense amplifiers during sensing, and (ii) high latency and energy consumption in write operations with conventional recursive program-and-verify. Targeting at lower power, less latency, and higher density, this work investigates and optimizes the read and write approaches to MLC FeFET NVM design: (i) Adaptive FeFET memory State Mapping (ASM) between the FeFET drain-source current and the digital states to increase the sensing margin; (ii) Adaptive FeFET Gate Biasing (AGB) read methods that adopt the optimized FeFET gate voltage to boost the sensible dynamic range and to store more levels of states per cell; (iii) Adaptive Prediction-based Direct (APD) write methods that minimize the program-and-verify activities. Evaluations show significant latency and energy improvement. Furthermore, the number of sensible levels of states per cell is also increased with an enhanced dynamic sensing range and an enhanced sensing margin.</td></tr>
<tr><td colspan="2"><a href="../pdf/p407_6B-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="6B-3"></a>
6B-3
<font size=-1>(Time: 16:35 - 17:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Emerging Memories as Enablers for In-Memory Layout Transformation Acceleration and Virtualization</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Minli Liao, <b><font color="Maroon" size=+1>*</font></b>John (Jack) Sampson (The Pennsylvania State University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 414 - 421</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Memory, In-cache layout transform</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Recent works have shown that certain emerging memory technologies can inherently support dense multi-orientation memory (MOM) access, such as row-column memories. However, with few exceptions, these works have only considered MOMs and MOM-caching techniques that provide multiple views of a single memory region. This work explores the potential of MOMs to present concurrent views of data organization as a means to offload data layout transformations. We demonstrate the potential of MOM-offloading to substantially reduce data movement for select computation patterns.</td></tr>
<tr><td colspan="2"><a href="../pdf/p414_6B-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="6B-4"></a>
6B-4
<font size=-1>(Time: 17:00 - 17:25)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Benchmark Non-volatile and Volatile Memory Based Hybrid Precision Synapses for In-situ Deep Neural Network Training</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Yandong Luo, <b><font color="Maroon" size=+1>*</font></b>Shimeng Yu (Georgia Institute of Technology, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 422 - 427</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>deep learning, non-volatile memory, hardware accelerator, training</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Compute-in-memory (CIM) with emerging non-volatile memories (eNVMs) is time and energy efficient for deep neural network (DNN) inference. However, challenges still remain for in-situ DNN training with eNVMs due to the asymmetric weight update behavior, high programming latency and energy consumption. To overcome these challenges, a hybrid precision synapse combining eNVMs with capacitor has been proposed. It leverages the symmetric and fast weight update in the volatile capacitor, as well as the non-volatility and large dynamic range of the eNVMs. In this paper, in-situ DNN training architecture with hybrid precision synapses is proposed and benchmarked with the modified NeuroSim simulator.</td></tr>
<tr><td colspan="2"><a href="../pdf/p422_6B-4.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="6C"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 6C</b>&nbsp; <font size=+1><b>(SS-4): AI Enhanced Simulation and Optimization in Back-End EDA Flow</b></font><br>
Time: 15:45 - 17:00 Wednesday, January 15, 2020<br>
Location: Room 307A<br>
Chair: Wenjian Yu (Tsinghua University, China)
<p></p>
<a name="6C-1"></a>
6C-1
<font size=-1>(Time: 15:45 - 16:10)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Capacitance Extraction and Power Grid Analysis Using Statistical and AI Methods</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Wenjian Yu, Ming Yang, Yao Feng, Ganqu Cui (Tsinghua University, China), Ben Gu (Cadence, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 428 - 433</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Capacitance extraction, Power grid simulation, Statistical method, Artificial intelligence, Classification problem</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Capacitance extraction and power grid (PG) analysis
for IC design involve large-scale numerical simulation
problems. As the process technology becomes more complicated
and design margin is shrinking, the capacitance field solver and
power-grid matrix solver with high accuracy and capability for
handing large and complex structure are highly demanded. In
this invited paper, we present recent application of statistical and
AI methods in these two fields. The Markov-chain model and relevant
analysis are presented for developing an efficient technique
for handling conformal dielectrics in the floating random walk
based capacitance extraction. Then, two approaches reducing the
computational cost of a domain decomposition based power-grid
solver are presented. One employs supervised machine learning
while the other is inspired by the A*-search algorithm.</td></tr>
<tr><td colspan="2"><a href="../pdf/p428_6C-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="6C-2"></a>
6C-2
<font size=-1>(Time: 16:10 - 16:35)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">VLSI Mask Optimization: From Shallow To Deep Learning</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Haoyu Yang (The Chinese University of Hong Kong, Hong Kong), Wei Zhong (Dalian University of Technology, China), Yuzhe Ma, Hao Geng, Ran Chen, Wanli Chen, Bei Yu (The Chinese University of Hong Kong, Hong Kong)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 434 - 439</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>OPC, Machine Learning</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>VLSI mask optimization is one of the most critical stages in manufacturability aware design,
which is costly due to the complicated mask optimization and lithography simulation.
Recent researches have shown prominent advantages of machine learning techniques dealing with complicated and big data problems,
which bring potential of dedicated machine learning solution for DFM problems and facilitate the VLSI design cycle.
In this paper, we focus on a heterogeneous OPC framework that assists mask layout optimization.
Preliminary results show the efficiency and effectiveness of proposed frameworks that have the potential to be alternatives to existing EDA solutions.</td></tr>
<tr><td colspan="2"><a href="../pdf/p434_6C-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="6C-3"></a>
6C-3
<font size=-1>(Time: 16:35 - 17:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Bayesian Methods for the Yield Optimization of Analog and SRAM Circuits</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Shuhan Zhang, <b><font color="Maroon" size=+1>*</font></b>Fan Yang (Fudan University, China), Dian Zhou (University of Texas at Dallas, USA), Xuan Zeng (Fudan University, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 440 - 445</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Yield Optimization, Bayeisan Optimization, Max-value Entropy Search</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>As the technology node shrinks to the nanometer scale, process variation become one of the most important issues in IC designs. The industry calls for designs with high yield under process variations. Yield optimization is computationally intensive because traditionally it relies on the Monte-Carlo yield estimation. In this paper, we will first review the Bayesian methods that reduce the computational cost of yield estimation and optimization. By applying Bayes’ theorem, maximizing the circuit yield is transformed to identify the design parameters with maximal probability density, conditioning on the event that the corresponding circuit is ”pass”. It can thus avoid repetitive yield estimations during optimization. The computational cost can also be reduced by using the Bayesian optimization strategy. By using the Gaussian process surrogate model and adaptive yield estimation, Bayesian optimization can significantly reduce the number of simulations while achieving even comparable yields for analog and SRAM circuits. We further propose a Bayesian optimization approach for yield optimization via max-value entropy search in this paper. The proposed max-value entropy search can better explore the state space, and thus reduce the number of circuit simulations while achieving competitive results.</td></tr>
<tr><td colspan="2"><a href="../pdf/p440_6C-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="6D"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 6D</b>&nbsp; <font size=+1><b>(DF-2): Emerging Design</b></font><br>
Time: 15:45 - 17:00 Wednesday, January 15, 2020<br>
Location: Room 307B<br>
Chair: Pingqiang Zhou (ShanghaiTech University)
<p></p>
<a name="6D-1"></a>
6D-1
<font size=-1>(Time: 15:45 - 16:10)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Designers' Forum)</font> <font color="navy">Recent Advances in Hardware Security and Testing Tools</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Junfeng Fan (Open Security Research, Inc, China)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>This talk will give an overview of design challenges about hardware security faced by the ICT industry today, and introduce three new research directions, instruction set extension for cryptography algorithms, hardware-assisted software security and system-level security modeling.  This talk will also discuss the increasing importance of security testing tools in the full life-cycle of silicon chips. Two new tools, namely, chip vulnerability scan at design phase, and protocol implementation security analysis, will be introduced.</td></tr>
</table>
<p></p>
<a name="6D-2"></a>
6D-2
<font size=-1>(Time: 16:10 - 16:35)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Designers' Forum)</font> <font color="navy">Design of Energy-Efficient Dynamic Reconfigurable Cryptographic Chip</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Jinjiang Yang (Tsinghua University, China)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>With the increasing security demand for network servers and cloud servers, high throughput cryptographic chip design becomes a hot research topic. However, the power consumption of current solutions is too high when the throughput exceeds 10 Gbps. Among current solutions, ASIC accelerators have higher energy efficiency. While the lack of flexibility makes them not suitable for servers which are supposed to implement a plenty of various cryptographic algorithms. General purpose processors (GPPs) are widely used because of their ease of use. Whereas, instruction fetching and decoding induce inevitable power overhead. Reconfigurable processors use configuration streams instead of instructions to reduce power overhead, while maintaining considerable flexibility due to their reconfiguration capability. We develop a coarse-grained dynamic reconfigurable cryptographic chip for high-throughput secure network processing and cloud computing. This chip implements international/national cryptographic algorithms (AES, 3DES, SHA256, SHA3, RSA, ECC, SM2, SM3, SM4, etc.) and supports new algorithms after the silicon implementation. It supports key management and virtualization (SR-IOV) and has considerable acceleration for security protocols such as IPsec and TLS. So, the chip can provide security for network and cloud computing with high performance and energy efficiency. For example, TLS handshake speed can reach 40KQps @ ECDHE-RSA-WITH-AES256-GCM-SHA384 based on a single chip.</td></tr>
</table>
<p></p>
<a name="6D-3"></a>
6D-3
<font size=-1>(Time: 16:35 - 17:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Designers' Forum)</font> <font color="navy">Cognitive SSD Controller: A Case for Agile Domain-Specific SoC Design</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Ying Wang (Chinese Academy of Sciences, China)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Large-scale data analysis systems have been suffering from the overhead of deep I/O stack, and the rocketing cost of data moving across the storage and memory hierarchy. Decades ago, In-storage processing has been proposed to address the issue of off-device bandwidth, latency and energy in conventional systems. However, due to the growth of unstructured and irregular data such as video, image and graphs, AI-driven data analysis is becoming prevalent in commercial data centers. To embrace AI-driven In-storage data processing, we propose Cognitive SSD, a flexible and energy-efficient solution to unstructured data analysis. In Cognitive SSD, the specialized deep learning and graph related hardware are abstracted and exposed to the users as library APIs via NVMe command extension, and it enable the free definition of data analysis functions inside the storage, such as the service of image retrieval, graph search and query. In this talk, we present the architecture of Cognitive SSD, and its programming interface, and we also showcase a prototyping data retrieval system, followed by the discussion of future directions in the Cognitive SSD project.</td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="5K"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 5K</b>&nbsp; <font size=+1><b>Keynote Session V</b></font><br>
Time: 17:30 - 18:10 Wednesday, January 15, 2020<br>
Location: Room 311<br>
<p></p>
<a name="5K-1"></a>
5K-1
<font size=-1>(Time: 17:30 - 18:10)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Keynote Address)</font> <font color="navy">Emulation View of Synopsys Verification Continuum Platform</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Michael Wang (Synopsys)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Increasing System-on-Chip (SoC) complexity and software content combined with rising time-to-market pressures are driving the need for a next-generation verification solution that spans pre-silicon verification, post-silicon validation and early software bring-up.
  Synopsys' Verification Continuum platform, developed in collaboration with market leaders, unites Synopsys' best-in-class verification solutions, facilitating a seamless transition between them and improving SoC time-to-market by months. Verification Continuum is architected with FPGA-based emulation and prototyping, delivering the speed and scalability required for software bring-up and SoC verification.
  By natively integrating the industry’s fastest emulator, ZeBu Server 4, with other Synopsys’ verification engines in the Verification Continuum Platform, like Virtualizer virtual prototyping, VCS simulation, HAPS prototyping, SpyGlass static and Verdi debug, many effective emulation solutions are created and help improve design verification and software bring-up productivity significantly. 
  In addition, on top of the Verification Continuum Platform, Synopsys develops domain specific solutions, to meet special technical requests from Networking, AI and 5G sectors.
  All above emulation technologies and solutions will be discussed in this presentation.</td></tr>
</table>
<p></p>
<hr>
<br>
<table border="2" cellspacing="0" cellpadding="5" bgcolor=#dddddd><tr><td>Thursday, January 16, 2020</table>
<br>
<div style="position: absolute; right: 20px"><a name="6K"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 6K</b>&nbsp; <font size=+1><b>Keynote Session VI</b></font><br>
Time: 9:00 - 10:00 Thursday, January 16, 2020<br>
Location: Room 311<br>
<p></p>
<a name="6K-1"></a>
6K-1
<font size=-1>(Time: 9:00 - 10:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Keynote Address)</font> <font color="navy">Explore the Next Tides of EDA</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Lifeng Wu (Empyrean Software)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>EDA, one of the most critical pillars of semiconductor industry, has been supporting Moore’s law for four decades. On the other hand, recent EDA growth in last two decades is mostly driven by applications rather than fundamental breakthrough in EDA research. What are the possible directions for future EDA tides? From our point of view, computing platform (heterogeneous computing, Cloud computing, ARM-based massive-threading architecture) and AI based algorithm will provide more dimensions for EDA research. 

We will demonstrate some solutions powered by heterogeneous computing platform and machine-learning algorithms.</td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="7A"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 7A</b>&nbsp; <font size=+1><b>Neuromorphic Computing</b></font><br>
Time: 10:15 - 11:30 Thursday, January 16, 2020<br>
Location: Room 310<br>
Chair: Shinya Takamaeda-Yamazaki (University of Tokyo)
<p></p>
<a name="7A-1"></a>
7A-1
<font size=-1>(Time: 10:15 - 10:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Programmable Neuromorphic Circuit based on Printed Electrolyte-Gated Transistors</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Dennis D. Weller, Michael Hefenbrock, Mehdi B. Tahoori (Karlsruhe Institute of Technology, Germany), Jasmin Aghassi-Hagmann (Offenburg University of Applied Sciences, Germany), Michael Beigl (Karlsruhe Institute of Technology, Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 446 - 451</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Neuromorphic Computing, Printed Electronics, Programmable, Electrolyte-gated transistors, Inkjet Printing</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Neuromorphic computing systems have demonstrated many advantages for popular classification problems with significantly less computational resources. We present in this paper the design, fabrication and training of a programmable neuromorphic circuit, which is based on printed electrolyte-gated field-effect transistor (EGFET). Based on printable neuron architecture involving several resistors and one transistor, the proposed circuit can realize multiply-add and activation functions. The functionality of the circuit, i.e. the weights of the neural network, can be set during a post-fabrication step in form of printing resistors to the crossbar. Besides the fabrication of a programmable neuron, we also provide a learning algorithm, tailored to the requirements of the technology and the proposed programmable neuron design, which is verified through simulations. The proposed neuromorphic circuit operates at 5V and occupies 385mm<sup>2</sup> of area.</td></tr>
<tr><td colspan="2"><a href="../pdf/p446_7A-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="7A-2"></a>
7A-2
<font size=-1>(Time: 10:40 - 11:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">HashHeat: An O(C) Complexity Hashing-based Filter for Dynamic Vision Sensor</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Shasha Guo, <b><font color="Maroon" size=+1>*</font></b>Ziyang Kang, Lei Wang, Shiming Li, Weixia Xu (National University of Defense Technology, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 452 - 457</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>DVS noise filtering, hash, memory</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Neuromorphic event-based dynamic vision sensors (DVS) have much faster sampling rates and a higher dynamic range than frame-based imagers. However, they are sensitive to background activity (BA) events which are unwanted.
We propose HashHeat, a hashing-based BA filter with O(C) complexity. It is the first spatiotemporal filter that doesn't scale with the DVS output size N and doesn't store the 32-bits timestamps. HashHeat consumes 100x less memory and increases the signal to noise ratio by 15x compared to previous designs.</td></tr>
<tr><td colspan="2"><a href="../pdf/p452_7A-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="7A-3"></a>
7A-3
<font size=-1>(Time: 11:05 - 11:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">A Tuning-Free Hardware Reservoir Based on MOSFET Crossbar Array for Practical Echo State Network Implementation</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Yuki Kume, Song Bian, Takashi Sato (Kyoto University, Japan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 458 - 463</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>hardware implementation, echo state network, reservoir computing, recurrent neural network, weight tuning</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Echo state network (ESN) is a class of recurrent neural network, and is known for drastically reducing the training time by the use of reservoir, a random and fixed network as the input and middle layers. In this paper, we propose a hardware implementation of ESN that uses practical MOSFET-based reservoir. As opposed to existing reservoirs that require additional tuning of network weights for improved stability, our ESN requires no post-training parameter tuning. To achieve this, we apply the circular law of random matrix to sparse reservoirs to determine a stable and fixed feedback gain. Through the evaluations using Mackey-Glass time-series dataset, the proposed ESN performs successful inference without post parameter tuning.</td></tr>
<tr><td colspan="2"><a href="../pdf/p458_7A-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="7B"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 7B</b>&nbsp; <font size=+1><b>Machine Learning for Embedded Systems</b></font><br>
Time: 10:15 - 11:30 Thursday, January 16, 2020<br>
Location: Room 308<br>
Chairs: Yongfu Li (Shanghai Jiao Tong University), Huiyuan Song (Beijing University of Technology)
<p></p>
<a name="7B-1"></a>
7B-1
<font size=-1>(Time: 10:15 - 10:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">MindReading: An Ultra-Low-Power Photonic Accelerator for EEG-based Human Intention Recognition</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Qian Lou (Indiana University Bloomington, USA), Wenyang Liu, Weichen Liu (Nanyang Technological University, Singapore), Feng Guo, Lei Jiang (Indiana University Bloomington, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 464 - 469</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>EGG, Photonic, Neural Network, Accelerator</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>A scalp-recording electroencephalography (EEG)-based brain-computer interface (BCI) system can greatly improve the quality of life for people who suffer from motor disabilities. Deep neural networks consisting of multiple convolutional, LSTM and fully-connected layers are created to decode EEG signals to maximize the human intention recognition accuracy. However, prior FPGA, ASIC, ReRAM and photonic accelerators cannot maintain sufficient battery lifetime when processing real-time intention recognition. In this paper, we propose an ultra-low-power photonic accelerator, MindReading, for human intention recognition by only low bit-width addition and shift operations. Compared to prior neural network accelerators, to maintain the real-time processing throughput, MindReading reduces the power consumption by 62.7% and improves the throughput per Watt by 168%.</td></tr>
<tr><td colspan="2"><a href="../pdf/p464_7B-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="7B-2"></a>
7B-2
<font size=-1>(Time: 10:40 - 11:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">LanCe: A Comprehensive and Lightweight CNN Defense Methodology against Physical Adversarial Attacks on Embedded Multimedia Applications</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Zirui Xu, Fuxun Yu, Xiang Chen (George Mason University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 470 - 475</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Convolutional Neural Network, Physical Adversarial Attack, Image Classification, Speech Recognition</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Recently, adversarial attacks can be applied to the physical world, causing practical issues to various Convolutional Neural Networks (CNNs) powered applications. Most existing physical adversarial attack defense works only focus on eliminating explicit perturbation patterns from inputs, ignoring interpretation to CNN’s intrinsic vulnerability. Therefore, they lack expected versatility to different attacks and thereby depend on considerable data processing costs. In this paper, we propose LanCe – a comprehensive and lightweight CNN defense
methodology against different physical adversarial attacks. By interpreting CNN’s vulnerability, we find that non-semantic adversarial perturbations can activate CNN with significantly abnormal activations and even overwhelm other semantic input patterns’ activations. We improve the CNN recognition process
by adding a self-verification stage to detect the potential adversarial input with only one CNN inference cost. Based on the detection result, we further propose a data recovery methodology to defend the physical adversarial attacks. We apply such defense methodology into both image and audio CNN recognition
scenarios and analyze the computational complexity for each scenario, respectively. Experiments show that our methodology can achieve an average 91% successful rate for attack detection and 89% accuracy recovery. Moreover, it is at most 3&times; faster compared with the state-of-the-art defense methods, making it feasible to resource-constrained embedded systems, such as
mobile devices.</td></tr>
<tr><td colspan="2"><a href="../pdf/p470_7B-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="7B-3"></a>
<font color="Maroon"><b>Best Paper Award</b></font><br>
7B-3
<font size=-1>(Time: 11:05 - 11:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Towards Area-Efficient Optical Neural Networks: An FFT-based Architecture</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Jiaqi Gu, Zheng Zhao, Chenghao Feng, Mingjie Liu, Ray T. Chen, David Z. Pan (University of Texas at Austin, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 476 - 481</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>FFT, Optical Neural Networks, Area-efficient</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>As a promising neuromorphic framework, the optical neural network (ONN) demonstrates ultra-high inference speed with low energy consumption. However, the previous ONN architectures have high area overhead which limits their practicality. In this paper, we propose an area-efficient ONN architecture based on structured neural networks, leveraging optical fast Fourier transform for efficient computation. A two-phase software training flow with structured pruning is proposed to further reduce the optical component utilization. Experimental results demonstrate that the proposed architecture can achieve 2.2~3.7x area cost improvement compared with the previous singular value decomposition-based architecture with comparable inference accuracy.</td></tr>
<tr><td colspan="2"><a href="../pdf/p476_7B-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="7C"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 7C</b>&nbsp; <font size=+1><b>Malicious Activities Generation and Detection</b></font><br>
Time: 10:15 - 11:30 Thursday, January 16, 2020<br>
Location: Room 307A<br>
Chairs: Xueyan Wang (Beihang University, China), Qiaoyan Yu (University of New Hampshire, USA)
<p></p>
<a name="7C-1"></a>
7C-1
<font size=-1>(Time: 10:15 - 10:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Automated Trigger Activation by Repeated Maximal Clique Sampling</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Yangdi Lyu, Prabhat Mishra (University of Florida, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 482 - 487</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Trigger Activation, Clique Coverage, Hardware Trojan, Satisfiability</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Hardware Trojans are serious threat to security and reliability of computing systems. It is hard to detect these malicious implants using traditional validation methods since an adversary is likely to hide them under rare trigger conditions. While existing statistical test generation methods are promising for Trojan detection, they are not suitable for activating extremely rare trigger conditions in stealthy Trojans. To address the fundamental challenge of activating rare triggers, we propose a new test generation paradigm by mapping trigger activation problem to clique cover problem. The basic idea is to utilize a satisfiability solver to construct a test corresponding to each maximal clique. This paper makes two fundamental contributions: 1) it proves that the trigger activation problem can be mapped to clique cover problem, 2) it proposes an efficient test generation algorithm to activate trigger conditions by repeated maximal clique sampling. Experimental results demonstrate that our approach is scalable and it outperforms state-of-the-art approaches by several orders-of-magnitude in detecting stealthy Trojans.</td></tr>
<tr><td colspan="2"><a href="../pdf/p482_7C-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="7C-2"></a>
7C-2
<font size=-1>(Time: 10:40 - 11:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Audio Adversarial Examples Generation with Recurrent Neural Networks</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Kuei-Huan Chang, <b><font color="Maroon" size=+1>*</font></b>Po-Hao Huang (National Tsing Hua University, Taiwan), Honggang Yu, Yier Jin (University of Florida, USA), Ting-Chi Wang (National Tsing Hua University, Taiwan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 488 - 493</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Neural network security, Adversarial attack</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Abstract—Previous methods of performing adversarial attacks against speech recognition systems often treat this problem as a solely optimization problem and require iterative updates to generate optimal solutions. Although they can achieve high success rate, the process is too computational heavy even with the help of GPU. In this paper, we introduce a new type of real-time adversarial attack methodology, which applies Recurrent Neural Networks (RNN) with a two-step training process to generate adversarial examples targeting a Keyword Spotting (KWS) system. We extend our attack to physical world by adding extra constraints in order to eliminate the distortions in real world.</td></tr>
<tr><td colspan="2"><a href="../pdf/p488_7C-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="7C-3"></a>
7C-3
<font size=-1>(Time: 11:05 - 11:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Database and Benchmark for Early-stage Malicious Activity Detection in 3D Printing</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Xiaolong Ma (Northeastern University, USA), Zhe Li (Syracuse University, USA), Hongjia Li (Northeastern University, USA), Qiyuan An (Virginia Polytechnic Institute and State University, USA), Qinru Qiu (Syracuse University, USA), Wenyao Xu (The State University of New York at Buffalo, USA), Yanzhi Wang (Northeastern University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 494 - 499</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>DNN, 3D printing, Detection, Dataset</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Increasing malicious users have sought practices to leverage 3D printing technology to produce unlawful tools in criminal activities. It is of vital importance to enable 3D printers to identify the objects to be printed and terminate at early stage if illegal objects are identified. Deep learning yields significant rises in performance in the object recognition tasks. However, the lack of large-scale databases in 3D printing domain stalls the advancement of automatic illegal weapon recognition. This paper presents a new 3D printing image database, namely C3PO, which compromises two subsets for the different system working scenarios.  We extract images from the numerical control programming code files of 22 3D models, and then categorize the images into 10 distinct labels. These two sets are designed for identifying: (i). printing knowledge source (G-code) at beginning of manufacturing, (ii). printing procedure during manufacturing. Importantly, we demonstrate that the weapons can be recognized in either scenario using deep learning based approaches using our proposed database. The quantitative results are promising, and the future exploration of the database and the crime prevention in 3D printing are demanding tasks.</td></tr>
<tr><td colspan="2"><a href="../pdf/p494_7C-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="7D"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 7D</b>&nbsp; <font size=+1><b>Embedded Software for Energy Optimization and Non-Volatile Memory</b></font><br>
Time: 10:15 - 11:30 Thursday, January 16, 2020<br>
Location: Room 307B<br>
Chairs: Hussam Amrouch (Karlsruhe Institute of Technology), Sarah Bing Li (Capital Normal University)
<p></p>
<a name="7D-1"></a>
7D-1
<font size=-1>(Time: 10:15 - 10:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">EA-HRT: An Energy-Aware scheduler for Heterogeneous Real-Time systems</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Sanjay Moulik, Rishabh Chaudhary, Zinea Das (IIIT Guwahati, India), Arnab Sarkar (IIT Guwahati, India)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 500 - 505</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Fair Scheduling, Multicore, Heterogeneous</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Developing energy-efficient schedulers for real-time heterogeneous platforms executing periodic tasks is an onerous as well as a computationally challenging issue. This research presents a heuristic strategy named, EA-HRT, for DVFS based energy-aware scheduling of a set of periodic tasks executing on a heterogeneous multicore platform.  Initially it calculates the execution demands of every task on each of the different type of cores. Then, it simultaneously allocates each task on available cores and selects operating frequencies for the concerned cores such that the summation of execution demands of all tasks are met as well as there is minimum change in energy consumption for the system. Experimental results show that our proposed strategy is not only able to achieve appreciable energy savings with respect to state-of-the-art (2% to 37% on average) but also enables significant
improvement in resource utilization (as high as 57%).</td></tr>
<tr><td colspan="2"><a href="../pdf/p500_7D-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="7D-2"></a>
7D-2
<font size=-1>(Time: 10:40 - 11:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Insights and Optimizations on IR-drop Induced Sneak-Path for RRAM Crossbar-based Convolutions</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Yujie Zhu, Xue Zhao, Keni Qiu (Capital Normal University, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 506 - 511</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Sneak-Path, IR-drop, RRAM crossbar</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>RRAM crossbar structure has been proposed to accelerate the convolution computation neural networks because its current-mode weighted summation operation intrinsically matches the dominant multiplication-and-accumulation (MAC) operations. However, there is an inevitable IR-drop problem with the RRAM crossbar, which may introduce sneak-path and thus reduce the accuracy of neural network algorithms and the system reliability. This work addresses the sneak-path problem caused by the IR-drop in a RRAM crossbar. We first present the characteristics of variation distribution of the sneak-path through numerous experiments, taking into account RRAM cell resistance, input voltage, and cell location in a crossbar. Then we propose optimization strategies from the hardware and software perspectives respectively to mitigate the variations resulting from sneak-path. The experimental results show that the proposed methods can compensate the accuracy of algorithms.</td></tr>
<tr><td colspan="2"><a href="../pdf/p506_7D-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="7D-3"></a>
7D-3
<font size=-1>(Time: 11:05 - 11:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Boosting the Profitability of NVRAM-based Storage Devices via the Concept of Dual-Chunking Data Deduplication</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Shuo-Han Chen (Academia Sinica, Taiwan), Yu-Pei Liang (National Tsing Hua University, Taiwan), Yuan-Hao Chang (Academia Sinica, Taiwan), Hsin-Wen Wei (Tamkang University, Taiwan), Wei-Kuan Shih (National Tsing Hua University, Taiwan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 512 - 517</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>deduplication, NVRAM, storage, profitability</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>With the latest advance in the non-volatile random-access memory (NVRAM), NVRAM is widely considered as the mainstream for the next-generation storage mediums. NVRAM has numerous attractive features, which include byte addressability, limited idle energy consumption, and great read/write access speed. However, owing to the high manufacturing cost of NVRAM, the incentive of deploying NVRAM in consumer electronics is lowered due to the consideration of profitability. To resolve the profitability issue and bring the benefits of NVRAM into the design of consumer electronics, avoiding storing duplicate data on NVRAM becomes a crucial task for lowering the demand and deployment cost of NVRAM. Such observation motivates us to propose a data deduplication extended file system design (DeEXT) to boost the profitability of NVRAM via the concept of dual-chunking data deduplication while considering the characteristics of NVRAM and duplicate data content. The proposed DeEXT was then evaluated by real-world data deduplication traces with encouraging results.</td></tr>
<tr><td colspan="2"><a href="../pdf/p512_7D-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="8A"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 8A</b>&nbsp; <font size=+1><b>Search and Optimization for Deep Neural Networks</b></font><br>
Time: 13:50 - 15:30 Thursday, January 16, 2020<br>
Location: Room 310<br>
Chair: Li Jiang (Shanghai Jiao Tong University)
<p></p>
<a name="8A-1"></a>
8A-1
<font size=-1>(Time: 13:50 - 14:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Black Box Search Space Profiling for Accelerator-Aware Neural Architecture Search</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Shulin Zeng, Hanbo Sun (Tsinghua University, China), Yu Xing (Tsinghua University, Xilinx inc., China), Xuefei Ning (Tsinghua University, China), Yi Shan (Xilinx inc., China), Xiaoming Chen (Chinese Academy of Sciences, China), Yu Wang, Huazhong Yang (Tsinghua University, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 518 - 523</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Search Space, AI, Accelerator, Neural Architecture Search</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Neural Architecture Search (NAS) is a promising approach to discover good neural network architectures for given applications. Among the three basic components in a NAS system (search space, search strategy, and evaluation), prior work mainly focused on the development of different search strategies and evaluation methods. As most of the previous hardware-aware search space designs aimed at CPUs and GPUs, it still remains a challenge to design a suitable search space for Deep Neural Network (DNN) accelerators. Besides, the architectures and compilers of DNN accelerators vary greatly, so it is quite difficult to get a unified and accurate evaluation of the latency of DNN across different platforms. To address these issues, we propose a black box profiling-based search space tuning method and further improve the latency evaluation by introducing a layer adaptive latency correction method. Used as the first stage in our general accelerator-aware NAS pipeline, our proposed methods could provide a smaller and dynamic search space with a controllable trade-off between accuracy and latency for DNN accelerators. Experimental results on CIFAR-10 and ImageNet demonstrate our search space is effective with up to 12.7\% improvement in accuracy and 2.2x reduction of latency, and also efficient by reducing the search time and GPU memory up to 4.35x and 6.25x, respectively.</td></tr>
<tr><td colspan="2"><a href="../pdf/p518_8A-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="8A-2"></a>
8A-2
<font size=-1>(Time: 14:15 - 14:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Search-free Accelerator for Sparse Convolutional Neural Networks</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Bosheng Liu, Xiaoming Chen, Yinhe Han, Ying Wang, Jiajun Li, Haobo Xu, Xiaowei Li (Institute of Computing Technology, Chinese Academy of Sciences, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 524 - 529</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>accelerator, sparse neural network, search-free, energy efficiency</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>We propose a sparsity-aware architecture, called Swan, which frees the search process for sparse CNNs under limited interconnect and bandwidth resources. The architecture comprises two parts: a MAC unit that can free the search operation for the sparsity-aware MAC calculation, and a systolic compressive dataflow that well suits the MAC architecture and greatly reuses inputs for interconnect and bandwidth saving.</td></tr>
<tr><td colspan="2"><a href="../pdf/p524_8A-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="8A-3"></a>
8A-3
<font size=-1>(Time: 14:40 - 15:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">NESTA: Hamming Weight Compression-Based Neural Proc. Engine</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Ali Mirzaeian, Houman Homayoun (George Mason University, USA), <b><font color="Maroon" size=+1>*</font></b>Avesta Sasan (Institute for Research in Fundamental Sciences, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 530 - 537</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Neural Network Accelerator, Convolutional Neural Network, Low Power Computation, MAC, Compressor</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>In this paper, we present NESTA, a specialized Neural engine that significantly accelerates the computation of convolution layers in a deep convolutional neural network, while reducing the computational energy. NESTA reformats Convolutions into 3 × 3 batches and uses a hierarchy of Hamming Weight Compressors to process each batch. Besides, when processing the convolution across multiple channels, NESTA, rather than computing the precise result of a convolution per channel, quickly computes an approximation of its partial sum, and a residual value such that if added to the approximate partial sum, generates the accurate output. Then, instead of immediately adding the residual, it uses (consumes) the residual when processing the next batch in the hamming weight compressors with available capacity. This mechanism shortens the critical path by avoiding the need to propagate carry signals during each round of computation and speeds up the convolution of each channel. In the last stage of computation, when the partial sum of the last channel is computed, NESTA terminates by adding the residual bits to the approximate output to generate a correct result.</td></tr>
<tr><td colspan="2"><a href="../pdf/p530_8A-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="8A-4"></a>
8A-4
<font size=-1>(Time: 15:05 - 15:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Representable Matrices: Enabling High Accuracy Analog Computation for Inference of DNNs using Memristors</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Baogang Zhang, Necati Uysal (University of Central Florida, USA), Deliang Fan (Arizona State University, USA), <b><font color="Maroon" size=+1>*</font></b>Rickard Ewetz (University of Central Florida, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 538 - 543</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>memristor, DNNs</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Analog computing based on memristor technology is a promising solution to accelerating the inference phase of deep neural networks (DNNs). A fundamental problem is to map an arbitrary matrix to a memristor crossbar array (MCA) while maximizing the resulting computational accuracy. The state-of-the-art mapping technique is based on a heuristic that only guarantees to produce the correct output for two input vectors. In this paper, a technique that aims to produce the correct output for every input vector is proposed, which involves specifying the memristor conductance values and a scaling factor realized by the peripheral circuitry. The key insight of the paper is that the conductance matrix realized by an MCA is only required to be proportional to the target matrix. The selection of the scaling factor between the two regulates the utilization of the programmable memristor conductance range and the representability of the target matrix. Consequently, the scaling factor is set to balance precision and value range errors. Moreover, a technique of converting conductance values into state variables and vice versa is proposed to handle memristors with non-ideal device characteristics. Compared with the state-of-the-art technique, the proposed mapping results in 4X-9X smaller errors. The improvements translate into that the classification accuracy of a seven-layer convolutional neural network (CNN) on CIFAR-10 is improved from 20.5% to 71.8%.</td></tr>
<tr><td colspan="2"><a href="../pdf/p538_8A-4.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="8B"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 8B</b>&nbsp; <font size=+1><b>FPGAs for Big Data Systems, Nonvolatile Computing, and Microfluidics</b></font><br>
Time: 13:50 - 15:30 Thursday, January 16, 2020<br>
Location: Room 308<br>
Chairs: Tsun-Ming Tseng (Technical University of Munich, Germany), Xueqing Li (Tsinghua University, China)
<p></p>
<a name="8B-1"></a>
<font color="Maroon"><b>Best Paper Candidate</b></font><br>
8B-1
<font size=-1>(Time: 13:50 - 14:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Reliability-Oriented IEEE Std. 1687 Network Design and Block-Aware High-Level Synthesis for MEDA Biochips</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Zhanwei Zhong, Tung-Che Liang, <b><font color="Maroon" size=+1>*</font></b>Krishnendu Chakrabarty (Duke University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 544 - 549</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Biochip, MEDA, Reliability, Synthesis, IJTAG</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>A digital microfluidic biochip (DMFB) enables miniaturization of immunoassays, point-of-care clinical diagnostics, DNA sequencing, and other laboratory procedures in biochemistry. A recent generation of biochips uses a micro-electrode-dot-array (MEDA) architecture, which provides fine-grained control of droplets and seamlessly integrates microelectronics and microfluidics using CMOS technology. To ensure that bioassays are carried out on MEDA biochips efficiently, high-level synthesis algorithms have recently been proposed. However, as in the case of conventional DMFBs, microelectrodes are likely to fail when they are heavily utilized, and previous methods fail to consider reliability issues. In this paper, we present the design of an IEEE Std. 1687 (IJTAG) network and a block-aware high-level synthesis method that can effectively alleviate reliability problems in MEDA biochips. A comprehensive set of simulation results demonstrate the effectiveness of the proposed method.</td></tr>
<tr><td colspan="2"><a href="../pdf/p544_8B-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="8B-2"></a>
8B-2
<font size=-1>(Time: 14:15 - 14:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Optimization of Fluid Loading on Programmable Microfluidic Devices for Bio-protocol Execution</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Satoru Maruyama (Ritsumeikan University, Japan), Debraj Kundu (Indian Institute of Technology Roorkee, India), <b><font color="Maroon" size=+1>*</font></b>Shigeru Yamashita (Ritsumeikan University, Japan), Sudip Roy (Indian Institute of Technology Roorkee, India)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 550 - 555</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Programmable Microfluidic Device, Fluid Loading</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Recently, Programmable Microfluidic Device (PMD) has got an attention of the design automation communities as a new type of microfluidic biochips. For the design of PMD chips, one of the important tasks is to minimize the number of flows for loading the reactant fluids into specific cells (by creating some flows of the fluids) before the bio-protocol is executed. Nevertheless of the importance of the problem, there has been almost no work to study this problem. Thus, in this paper, we intensively study this fluid loading problem in PMD chips. First, we successfully formulate the problem as a constraint satisfaction problem (CSP) to solve the problem optimally for the  first time. Then, we also propose an efficient heuristic called Determining Flows from the Last (DFL) method for larger problem instances. DFL is based on a novel idea that it is better to determine the flows from the last flow unlike the state-of-the-art method Fluid Loading Algorithm for PMD (FLAP) [Gupta et al., TODAES, 2019]. Simulation results confirm that the exact method can find the optimal solutions for practical test cases, whereas our heuristic can find near-optimal solutions, which are better than those obtained by FLAP.</td></tr>
<tr><td colspan="2"><a href="../pdf/p550_8B-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="8B-3"></a>
8B-3
<font size=-1>(Time: 14:40 - 15:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">An FPGA based Network Interface Card with Query Filter for Storage Nodes of Big Data Systems</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Ying Li, <b><font color="Maroon" size=+1>*</font></b>Jinyu Zhan, Wei Jiang, Junting Wu (University of Electronic Science and Technology of China, China), Jianping Zhu (Tencent Technology Shenzhen Co., Ltd, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 556 - 561</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Storage and computing separated big data systems, Query filter, Network Interface Card, FPGA</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>In this paper, we are interested in improving the data processing of storage and computing separated Big Data systems. We propose an Field Programmable Gate Array (FPGA) based Network Interface Card with Query Filter (NIC-QF) to accelerate the data query efficiency of storage nodes and reduce the workloads of computing nodes and the communication overheads between them. NIC-QF designed with PCIe core, query filter and NIC communication can filter the original data on storage nodes as an implicit coprocessor and directly send the filtered data to computing nodes of Big Data systems. Filter units in query filter can perform multiple SQL tasks in parallel, and each filter unit is internally pipelined, which can further speed up the data processing. Filter units can be designed to support general SQL queries on different data formats and we implement two schemes for TextFile and RCFile separately. Based on TPC-H benchmark and Tencent data set, we conduct extensive experiments to evaluate our design, which can achieve averagely up to 46.91\% faster than the traditional approach.</td></tr>
<tr><td colspan="2"><a href="../pdf/p556_8B-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="8B-4"></a>
8B-4
<font size=-1>(Time: 15:05 - 15:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Nonvolatile and Energy-Efficient FeFET-Based Multiplier for Energy-Harvesting Devices</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Mengyuan Li (University of Notre Dame, USA), Xunzhao Yin (Zhejiang University, China), Xiaobo Sharon Hu (University of Notre Dame, USA), Cheng Zhuo (Zhejiang University, China)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 562 - 567</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>FeFET, Multiplier, Nonvolatile</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Energy-harvesting internet-of-things devices must
deal with unstable power input. Nonvolatile processors (NVPs)
can offer an effective solution. Compact and low-energy arithmetic
circuits that can efficiently switch between computation
and backup operations are highly desirable for NVP design. This paper introduces a nonvolatile FeFET-based multiplier with the ability to do continued calculation after a power outage. Simulation results show the proposed design saves up to 21% and 19% area than a conventional CMOS-based sequential multiplier of 4-bits and 8-bits, respectively.</td></tr>
<tr><td colspan="2"><a href="../pdf/p562_8B-4.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="8C"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 8C</b>&nbsp; <font size=+1><b>Advances in Logic/High-Level Synthesis</b></font><br>
Time: 13:50 - 15:30 Thursday, January 16, 2020<br>
Location: Room 307A<br>
Chair: Bing Li (Technische Universität München)
<p></p>
<a name="8C-1"></a>
<font color="Maroon"><b>Best Paper Candidate</b></font><br>
8C-1
<font size=-1>(Time: 13:50 - 14:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Modulo Scheduling with Rational Initiation Intervals in Custom Hardware Design</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Patrick Sittel (University of Kassel, Germany), John Wickerson (Imperial College London, UK), Martin Kumm (University of Applied Sciences Fulda, Germany), Peter Zipf (University of Kassel, Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 568 - 573</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Modulo Scheduling, High-level Synthesis, Design Space Exploration, Computer-aided Design</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>In modulo scheduling, the number of clock cycles between successive inputs (the initiation interval, II) is traditionally an integer, but in this paper, we explore the benefits of allowing it to be a rational number. This rational II can be interpreted as the average number of clock cycles between successive inputs.
As the minimum rational II can be less than the minimum integer II, this translates to higher throughput. 
We formulate rational-II modulo scheduling as an integer linear programming (ILP) problem that is able to find latency-optimal schedules for a fixed rational II. 
We have applied our scheduler to a standard benchmark of hardware designs, and our results demonstrate a significant speedup compared to state-of-the-art integer-II and rational-II formulations.</td></tr>
<tr><td colspan="2"><a href="../pdf/p568_8C-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="8C-2"></a>
8C-2
<font size=-1>(Time: 14:15 - 14:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">HL-Pow: A Learning-Based Power Modeling Framework for High-Level Synthesis</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Zhe Lin, Jieru Zhao (Hong Kong University of Science and Technology, Hong Kong), Sharad Sinha (Indian Institute of Technology Goa, India), Wei Zhang (Hong Kong University of Science and Technology, Hong Kong)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 574 - 580</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>power modeling, design space exploration, machine learning, high-level synthesis</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>High-level synthesis (HLS) enables designers to customize hardware designs efficiently. However, it is still challenging to foresee the correlation between power consumption and HLS-based applications at an early design stage. To overcome this problem, we introduce HL-Pow, a power modeling framework for FPGA HLS based on state-of-the-art machine learning techniques. HL-Pow incorporates an automated feature construction flow to efficiently identify and extract features that exert a major influence on power consumption, simply based upon HLS results, and a modeling flow that can build an accurate and generic power model applicable to a variety of designs with HLS. By using HL-Pow, the power evaluation process for FPGA designs can be significantly expedited because the power inference of HL-Pow is established on HLS instead of the time-consuming register-transfer level (RTL) implementation flow. Experimental results demonstrate that HL-Pow can achieve accurate power modeling that is only 4.67% (24.02 mW) away from onboard power measurement. To further facilitate power-oriented optimizations, we describe a novel design space exploration (DSE) algorithm built on top of HL-Pow to trade off between latency and power consumption. This algorithm can reach a close approximation of the real Pareto frontier while only requiring running HLS flow for 20% of design points in the entire design space.</td></tr>
<tr><td colspan="2"><a href="../pdf/p574_8C-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="8C-3"></a>
8C-3
<font size=-1>(Time: 14:40 - 15:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">DRiLLS: Deep Reinforcement Learning for Logic Synthesis</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Abdelrahman Hosny, Soheil Hashemi (Brown University, USA), Mohamed Shalan (The American University in Cairo, Egypt), Sherief Reda (Brown University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 581 - 586</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>reinforcement learning, logic synthesis, parameter tuning, optimization</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Logic synthesis requires extensive tuning of the synthesis optimization flow where the quality of results (QoR) depends on the sequence of optimizations used. Efficient design space exploration is challenging due to the exponential number of possible optimization permutations. Therefore, automating the optimization process is necessary. In this work, we propose a novel reinforcement learning-based methodology that navigates the optimization space without human intervention. We demonstrate the training of an Advantage Actor Critic (A2C) agent that seeks to minimize area subject to a timing constraint. Using the proposed methodology, designs can be optimized autonomously with no-humans in-loop. Evaluation on the comprehensive EPFL benchmark suite shows that the agent outperforms existing exploration methodologies and improves QoRs by an average of 13%.</td></tr>
<tr><td colspan="2"><a href="../pdf/p581_8C-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="8C-4"></a>
8C-4
<font size=-1>(Time: 15:05 - 15:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Lightening Asynchronous Pipeline Controller Through Resynthesis and Optimization</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Jeongwoo Heo, Taewhan Kim (Seoul National University, Republic of Korea)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 587 - 592</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Asynchronous, Resource, Synthesis, Optimization, Timing</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>A bundled-data asynchronous circuit is a promising alternative to a synchronous circuit for implementing high performance low power systems, but it requires to deploy special circuitry to support the asynchronous communication between every pair of consecutive pipeline stages. This work addresses the problem of reducing the size of asynchronous pipeline controller. Lightening the pipeline controller directly impacts two critical domains: (1) it mitigates the increase of controller area caused by high process-voltage-temperature variation on circuit; (2) it contributes to proportionally reducing the leakage power. (Note that a long delay in circuit between pipeline stages requires a long chain of delay elements in the controller.) Precisely, we analyze the setup timing paths on the conventional asynchronous pipeline controller, and (i) resynthesize new setup timing paths, which allows to share some of the expensive delay elements among the paths while assuring the communication correctness. Then, we (ii) optimally solve the problem of minimizing the number of delay elements by formulating it into a linear programming. For a set of test circuits with a 45nm standard cell library, it is shown that our synthesis and optimization method reduces the total area of delay elements and the leakage power of pipeline controller by 46.4% and 43.6% on average, respectively, while maintaining the same level of performance and dynamic power consumption.</td></tr>
<tr><td colspan="2"><a href="../pdf/p587_8C-4.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="8D"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 8D</b>&nbsp; <font size=+1><b>Scalable and Reconfigurable Approximate Arithmetic Units</b></font><br>
Time: 13:50 - 15:30 Thursday, January 16, 2020<br>
Location: Room 307B<br>
Chairs: Jie Han (University of Alberta, Canada), Weikang Qian (Shanghai Jiao Tong University)
<p></p>
<a name="8D-1"></a>
<font color="Maroon"><b>Best Paper Candidate</b></font><br>
8D-1
<font size=-1>(Time: 13:50 - 14:15)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">WEID: Worst-case Error Improvement in Approximate Dividers</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Hassaan Saadat (University of New South Wales, Sydney, Australia), Haris Javaid (Xilinx, Singapore), Aleksandar Ignjatovic, Sri Parameswaran (University of New South Wales, Sydney, Australia)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 593 - 598</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Approximate, Divider, Worst-case, Error</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Approximate integer dividers suffer from unreasonably high worst-case relative errors (such as 50% or 100%), which can adversely affect the application-level output. In this paper, we propose WEID, which is a novel lightweight method to improve the worst-case relative errors in approximate integer dividers. We first present an in-depth analysis to gain insights into the cause of the high worst-case relative error. Based on our insights, we propose a novel method to detect when an error occurs in an approximate divider, and modify the output to reduce the error. Further, we present the hardware realization of WEID method and demonstrate that it can be generically coupled with several state-of-the-art approximate dividers. Our results show that for 32-by-16 dividers, WEID reduces worst-case relative errors from 100% to ~20%, while still achieving ~80% and ~70% reduction in delay and energy compared to an accurate array divider.</td></tr>
<tr><td colspan="2"><a href="../pdf/p593_8D-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="8D-2"></a>
8D-2
<font size=-1>(Time: 14:15 - 14:40)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Small-Area and Low-Power FPGA-Based Multipliers using Approximate Elementary Modules</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Yi Guo, Heming Sun, Shinji Kimura (Waseda University, Japan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 599 - 604</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Approximate computing, Multiplier, FPGA-based, Low power, Small area</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>This paper presents a novel methodology for designing approximate multipliers by employing the FPGA-based fabrics. The area and latency are significantly reduced by cutting the carry propagation path in the multiplier. Moreover, we explore higher-order multipliers on architectural space by using our proposed small-size approximate multipliers as elementary modules. For different accuracy requirements, eight configurations on approximate 8×8 multiplier are discussed. In terms of mean relative error distance (MRED), the accuracy loss of the proposed 8×8 multiplier is low as 0.17%. Compared with the exact multiplier, our proposed design can reduce area by 43.66% and power by 20.36%. The critical path latency reduc-tion is up to 27.66%. The proposed multiplier design has a bet-ter accuracy-hardware tradeoff than other designs with comparable accuracy.</td></tr>
<tr><td colspan="2"><a href="../pdf/p599_8D-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="8D-3"></a>
8D-3
<font size=-1>(Time: 14:40 - 15:05)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">LeAp: Leading-one Detection-based Softcore Approximate Multipliers with Tunable Accuracy</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Zahra Ebrahimi, Salim Ullah, Akash Kumar (Technische Universität Dresden, Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 605 - 610</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Field-Programmable Gate Arrays, Approximate Multiplier, Mitchell’s Algorithm, Energy-Efficiency, Area-Optimization</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Approximate multipliers are ubiquitous in ASIC platform used by diverse application domains. However, comparable source gains is not gained when directly applying these techniques on FPGA platforms. We propose LeAp, an area-, throughput-, and energy-efficient  approximate multiplier for FPGAs which efficiently utilizes 6-LUTs and fast carry chains to implement Mitchell’s algorithm. Moreover, through three novel light-weight error-refinement, we have boosted accuracy to>99%. Experimental results from Vivado, ANN and image processing applications indicate 69.7%, 14.7%, 42.1%,and 37.1% improvement in area, throughput, power, and energy, respectively.</td></tr>
<tr><td colspan="2"><a href="../pdf/p605_8D-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="8D-4"></a>
8D-4
<font size=-1>(Time: 15:05 - 15:30)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="navy">Scaled Population Arithmetic for Efficient Stochastic Computing</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>He Zhou, Sunil P. Khatri, Jiang Hu (Texas A&amp;M University, USA), Frank Liu (IBM Research - Austin, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 611 - 616</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>scaled population, approximate computation</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>We propose a new Scaled Population (SP) based arithmetic computation approach that achieves considerable improvements over existing stochastic computing (SC) techniques. First, SP arithmetic introduces scaling operations that significantly reduce the numerical errors as compared to SC. Experiments show accuracy improvements of a single multiplication and addition operation by 6.3× and 4.0×, respectively. Secondly, SP arithmetic erases the inherent serialization associated with stochastic computing, thereby significantly improves the computational delays. We design each of the operations of SP arithmetic to take O(1) gate delays, and eliminate the need of serially iterating over the bits of the population vector. Our SP approach improves the area, delay and power compared with conventional stochastic computing on an FPGA-based implementation. We also apply our SP scheme on a handwritten digit recognition application (MNIST), improving the recognition accuracy by 32.79% compared to SC.</td></tr>
<tr><td colspan="2"><a href="../pdf/p611_8D-4.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="9A"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 9A</b>&nbsp; <font size=+1><b>(SS-5): Resilience in Integrated Systems</b></font><br>
Time: 15:45 - 17:00 Thursday, January 16, 2020<br>
Location: Room 310<br>
Chair: Masanori Hashimoto (Osaka University, Japan)
<p></p>
<a name="9A-1"></a>
9A-1
<font size=-1>(Time: 15:45 - 16:10)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Soft Error and Its Countermeasures in Terrestrial Environment</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Masanori Hashimoto (Osaka University, Japan), Wang Liao (Kochi University of Technology, Japan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 617 - 622</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>soft error, SRAM, ECC, processor, GPU</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>This paper discusses soft errors in digital chips consisting of SRAM, flip-flops, and combinational logic in the terrestrial environment. We review the effectiveness of error-correction coding (ECC) in processor systems and point out the importance of radiation-hardened flip-flops for further error mitigation. The discussion includes the difference between planar and FD-SOI transistors, and the type of secondary cosmic rays including neutron and muon, using irradiation test results. Also, the difficulty in characterizing SER of a commercial GPU chip is exemplified.</td></tr>
<tr><td colspan="2"><a href="../pdf/p617_9A-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="9A-2"></a>
9A-2
<font size=-1>(Time: 16:10 - 16:35)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Timing Resilience for Efficient and Secure Circuits</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Grace Li Zhang, Michaela Brunner, <b><font color="Maroon" size=+1>*</font></b>Bing Li, Georg Sigl, Ulf Schlichtmann (Technical University of Munich, Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 623 - 628</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>timing, process variations, circuit resilience, anti-counterfeiting, netlist security</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>In this paper, we will cover several techniques that can enhance the resilience of timing of digital circuits. Using post-silicon tuning components, the clock arrival times at flip- flops can be modified after manufacturing to balance delays between flip-flops. The actual delay properties of flip-flops will be examined to exploit the natural flexibility of such components. Wave-pipelining paths spanning several flip-flop stages can be integrated into a synchronous design to improve the circuit performance and to reduce area. In addition, with this technique, it cannot be taken for granted anymore that all the combinational paths in a circuit work with respect to one clock period. There- fore, a netlist alone does not represent all the design information. This feature enables the potential to embed wave-pipelining paths into a circuit to increase the complexity of reverse engineering. In order to replicate a design, attackers therefore have to identify the locations of the wave-pipelining paths, in addition to the netlist extracted from reverse engineering. Therefore, the security of the circuit against counterfeiting can be improved.</td></tr>
<tr><td colspan="2"><a href="../pdf/p623_9A-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="9A-3"></a>
9A-3
<font size=-1>(Time: 16:35 - 17:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Run-Time Enforcement of Non-Functional Application Requirements in Heterogeneous Many-Core Systems</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Jürgen Teich, Behnaz Pourmohseni, <b><font color="Maroon" size=+1>*</font></b>Oliver Keszocze, Jan Spieck, Stefan Wildermann (Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 629 - 636</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>run-time enforcement, many-core systems, reliability, realtime</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>For many embedded applications, non-functional requirements such as safety, reliability, and execution time must be guaranteed in tight bounds on a given multi-core platform. Here, jitter in non-functional program execution qualities is caused either by outer influences such as faults injected by the environment, but can be induced also from the system management software itself, including thread-to-core mapping, scheduling and power management. 
A second huge source of variability typically stems from data-dependent workloads. In this paper, we classify and present techniques to enforce non-functional execution properties on multi-core platforms. Based on a static design space exploration and analysis of influences of variability of non-functional properties, enforcement strategies are generated to guide the execution of periodically executed applications in given requirement corridors. 
Using the case study of a complex image streaming application, we show that by controlling DVFS settings of cores proactively, not only tight execution times, but also reliability requirements may be enforced dynamically while trying to minimize energy consumption.</td></tr>
<tr><td colspan="2"><a href="../pdf/p629_9A-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="9B"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 9B</b>&nbsp; <font size=+1><b>(SS-6): Emerging Technologies across the Abstraction Layers</b></font><br>
Time: 15:45 - 17:00 Thursday, January 16, 2020<br>
Location: Room 308<br>
Chair: Hussam Amrouch (Karlsruhe Institute of Technology (KIT), Germany)
<p></p>
<a name="9B-1"></a>
9B-1
<font size=-1>(Time: 15:45 - 16:10)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">NCFET to Rescue Technology Scaling: Opportunities and Challenges</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Hussam Amrouch, Victor M. van Santen (Karlsruhe Institute of Technology, Germany), Girish Pahwa (Indian Institute of Technology Kanpur, India), Yogesh Chauhan (Indian Institute of Technology Kanpur, Germany), Jörg Henkel (Karlsruhe Institute of Technology (KIT), Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 637 - 644</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Negative Capacitance, NCFET, Emerging technology, Beyond CMOS, FinFET</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Negative Capacitance Field Effect Transistor (NCFET) is one of the promising emerging technologies that may overcome the fundamental limits of conventional CMOS technology. Since NCFET features a ferroelectric (FE) layer within the transistor’s gate, which internally amplifies the voltage, NCFET can operate at a lower voltage while sustaining performance at considerable energy savings. In this work, we raise awareness that n- and p-NCFET transistors are asymmetrically affected by the FE layer and show, for the first time, how this asymmetry results in unbalanced circuit performance (e.g., longer fall than rise propagation delay, reduced noise margins).</td></tr>
<tr><td colspan="2"><a href="../pdf/p637_9B-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="9B-2"></a>
9B-2
<font size=-1>(Time: 16:10 - 16:35)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Parallelism in Deep Learning Accelerators</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Linghao Song, Fan Chen, Yiran Chen, Hai (Helen) Li (Duke University, USA)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 645 - 650</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Parallelism, Deep Learning Accelerators</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Deep learning is the core of artificial intelligence and it achieves state-of-the-art in a wide range of applications. The intensity of computation and data in deep learning processing poses significant challenges to the conventional computing platforms. Thus, specialized accelerator architectures are proposed for the acceleration of deep learning. In this paper, we classify the design space of current deep learning accelerators into three levels, (1) processing engine, (2) memory and (3) accelerator, and present a constructive view from a perspective of parallelism in the three levels.</td></tr>
<tr><td colspan="2"><a href="../pdf/p645_9B-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="9B-3"></a>
9B-3
<font size=-1>(Time: 16:35 - 17:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Software-Based Memory Analysis Environments for In-Memory Wear-Leveling</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Christian Hakert, Kuan-Hsun Chen, Mikail Yayla, Georg von der Brüggen, Sebastian Blömeke, Jian-Jia Chen (TU Dortmund, Germany)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 651 - 658</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>non-volatile memory, wear-leveling, system simulation</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Emerging non-volatile memory (NVM) architectures are considered as a replacement for DRAM and storage in the near future, since NVMs provide low power consumption, fast access speed, and low unit cost. Due to the lower write-endurance of NVMs, several in-memory wear-leveling techniques have been studied over the last years. Since most approaches propose or rely on specialized hardware, the techniques are
often evaluated based on assumptions and in-house simulations rather than on real systems. To address this issue, we develop a setup consisting of a gem5 instance and an NVMain2.0 instance, which simulates an entire system (CPU, peripherals, etc.) together with an NVM plugged into the system. Taking a recorded memory access pattern from a low-level simulation into consideration to design and optimize wear-leveling techniques as operating system services allows a cross-layer design of wear-leveling techniques. With the insights gathered by analyzing the recorded memory access patterns, we develop a software-only wear-leveling solution, which does not require special hardware at all. This algorithm is evaluated afterwards by the full system simulation.</td></tr>
<tr><td colspan="2"><a href="../pdf/p651_9B-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="9C"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 9C</b>&nbsp; <font size=+1><b>(SS-7): CMOS Annealing Hardware: Pursuing Efficiency for Solving Combinatorial Optimization Problems</b></font><br>
Time: 15:45 - 17:00 Thursday, January 16, 2020<br>
Location: Room 307A<br>
Chair: Shu Tanaka (Waseda University, Japan)
<p></p>
<a name="9C-1"></a>
9C-1
<font size=-1>(Time: 15:45 - 16:10)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Theory of Ising Machines and a Common Software Platform for Ising Machines</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Shu Tanaka (Waseda University, Japan), Yoshiki Matsuda (Fixstars, Japan), Nozomu Togawa (Waseda University, Japan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 659 - 666</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Ising machine, Combinatorial Optimization Problem, Quantum annealing, Ising Model</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Ising machines are a new type of non-Neumann computer that specializes in solving combinatorial optimization problems efficiently. The input form of Ising machines is the energy function of the Ising model or quadratic unconstrained binary optimization form, and Ising machines operate to search for a condition to minimize the energy function. We describe the theory of Ising machines and the present status of the Ising machines, software for Ising machines, and applications using Ising machines.</td></tr>
<tr><td colspan="2"><a href="../pdf/p659_9C-1.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="9C-2"></a>
9C-2
<font size=-1>(Time: 16:10 - 16:35)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">Digital Annealer for High-Speed Solving of Combinatorial Optimization Problems and Its Applications</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Satoshi Matsubara, Motomu Takatsu, Toshiyuki Miyazawa, Takayuki Shibasaki, Yasuhiro Watanabe, Kazuya Takemoto, Hirotaka Tamura (Fujitsu Laboratories LTD., Japan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 667 - 672</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>combinatorial optimization problem, Ising model, Markov Chain Monte Carlo, Digital Annealer, benchmark</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Digital Annealer is a dedicated architecture for high-speed solving of combinatorial optimization problems mapped to an Ising model. Digital Annealer uses Markov Chain Monte Carlo as a basic search mechanism, accelerated by the hardware implementation of multiple speed-enhancement techniques. It is currently being offered as a cloud service using a second-generation chip operating on a scale of 8,192 bits. This paper presents an overview of Digital Annealer, its performance against benchmarks, and application examples.</td></tr>
<tr><td colspan="2"><a href="../pdf/p667_9C-2.pdf">PDF file</a></td></tr>
</table>
<p></p>
<a name="9C-3"></a>
9C-3
<font size=-1>(Time: 16:35 - 17:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Invited Paper)</font> <font color="navy">CMOS Annealing Machine: A Domain-Specific Architecture for Combinatorial Optimization Problem</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td><b><font color="Maroon" size=+1>*</font></b>Chihiro Yoshimura, Masato Hayashi, Takashi Takemoto, Masanao Yamaoka (Hitachi, Ltd., Japan)</td></tr>
<tr><td><font size=-2 color=green>Page</font></td><td>pp. 673 - 678</td></tr>
<tr><td><font size=-2 color=green>Keyword</font></td><td>Domain-specific architecture, Combinatorial optimization problem, In-memory computing, Ising model, FPGA</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Domain-specific architectures are being studied to improve computer performance beyond the end of Moore's Law. Here, we propose a new computing architecture, the CMOS annealing machine, which provides a fast means of solving combinatorial optimization problems. Our architecture is based on in-memory computing architecture through utilizing the locality of interactions in the Ising model. The prototype presented in 2019 has two processors on a business-card-sized board and solves problems 55 times faster than conventional computers.</td></tr>
<tr><td colspan="2"><a href="../pdf/p673_9C-3.pdf">PDF file</a></td></tr>
</table>
<p></p>
<hr>
<div style="position: absolute; right: 20px"><a name="9D"></a><a href="#" style="text-decoration:none;" title="Jump to Session Table">[To Session Table]</a></div><br>
<b>Session 9D</b>&nbsp; <font size=+1><b>(DF-3): AI Accelerators</b></font><br>
Time: 15:45 - 17:00 Thursday, January 16, 2020<br>
Location: Room 307B<br>
Chair: Xiaoming Chen (Institute of Computing Technology, Chinese Academy of Sciences)
<p></p>
<a name="9D-1"></a>
9D-1
<font size=-1>(Time: 15:45 - 16:10)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Designers' Forum)</font> <font color="navy">AI Chips, What's Next: Architecture, Tools, and Methodology</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Shan Tang (AI chip expert, China)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>In recent years, AI chips are developed by IC vendors, tech giants, and startups to fulfill the huge requirements of AI applications. To provide computation power more efficiently for the AI domain, different types of hardware architectures are explored and optimized. At the same time, the software technology is also evolving to make the best use of these monsters.  As the first generation of AI chips is getting mature, it is a good time to discuss what may happen in the coming years.</td></tr>
</table>
<p></p>
<a name="9D-2"></a>
9D-2
<font size=-1>(Time: 16:10 - 16:35)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Designers' Forum)</font> <font color="navy">Computing-in-Memory SoC Chip for Neural Network Inference</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Shaodi Wang (Witin Tech, China)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>Neural Networks (NNs) have been widely employed in modern artificial intelligence (AI) systems due to their unprecedented capability in classification, recognition and detection. However, the massive data communication between the processing units and the memory has been proven to be the main bottleneck to improve the efficiency of NNs based hardware. Furthermore, the significant power demand for massive addition and multiplication limits its adoption at the edge devices. In addition, the cost is another major concern for an edge device. WITIN Tech has developed edge neural processing chips with analog computing-in-memory technology simultaneous achieving low-power, high-performance, and low-cost. First two products: MemCore001 and MemCore101 are releasing to customers in Nov. 2019. It achieves 8-bit 10Gops performance with 1mW power, boosting state-of-the-art AI voice chip in market by 50X. It satisfies the urgent need for the fast-growing IoT market.</td></tr>
</table>
<p></p>
<a name="9D-3"></a>
9D-3
<font size=-1>(Time: 16:35 - 17:00)</font>
<table class="tbl1" border="1">
<tr><td><font size=-2 color=green>Title</font></td><td><font color="maroon">(Designers' Forum)</font> <font color="navy">Enabling Data Center-Wide Accelerator Resource Pools for AI Applications</font></td></tr>
<tr><td><font size=-2 color=green>Author</font></td><td>Kun Wang (VirtAI Tech, China)</td></tr>
<tr><td><font size=-2 color=green>Abstract</font></td><td>As AI technologies evolve fast, the amount of AI compute has grown by more than 300,000x since 2012. Today the major providers of AI compute are accelerators like GPUs, FPGAs and ASICs. However, most users are using those accelerators exclusively, it results in low accelerator utilization and high costs. By VirtAI Tech’s innovative accelerator virtualization technologies, OrionX Computing Platform (OXCP) helps customers build data center-wide accelerator resource pools, and enables customer applications to run on and share any accelerators on any servers in a data center. OXCP not only significantly increases accelerator utilization and reduces costs, but also makes application deployment much easier.</td></tr>
</table>
<p></p>
<hr>


</body>
</html>
